{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "# mosek only needed if we don't use MW\n",
    "#import mosek\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cProfile\n",
    "#from baselines import *\n",
    "from scipy.linalg import sqrtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of corruptions\n",
      "100\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "flip label\n",
      "[[ 0.06924975  0.12317111  0.20561801  0.1065409  -0.10849591 -0.01709377\n",
      "   0.00795007 -0.08738141  0.0018057  -0.05379144]]\n",
      "[[-0.09974922  0.09969709  0.62297387  0.17453633  0.07187714 -0.10079325\n",
      "  -0.18231323 -0.16432845 -0.02962017  0.06212968]\n",
      " [-0.13053178  0.38277593  0.35283591  0.04610321 -0.21945292 -0.01498158\n",
      "   0.07472629  0.27294191  0.05530672 -0.24402333]]\n",
      "score\n",
      "0.55\n"
     ]
    }
   ],
   "source": [
    "#synthetic example with N datapoints, in d dimensions, with k actions, random regressors\n",
    "#returns a dictionary of covariates x, labels y, regressors ell.  \n",
    "def synthetic_example(N,d,k):\n",
    "    #covariates\n",
    "    x = np.random.normal(0,1,(N,d))\n",
    "    #regressors\n",
    "    ell = np.random.normal(0,1,(k,d))\n",
    "    #labels\n",
    "    y = np.zeros((N,k))\n",
    "    for i in range(N):\n",
    "        for j in range(k):\n",
    "            feature = x[i,:]\n",
    "            regressor = ell[j,:]\n",
    "            y[i,j] = np.inner(feature,regressor) + np.random.normal(0,1)\n",
    "    data = {'cov': x, 'label': y, 'reg': ell}\n",
    "    return data\n",
    "\n",
    "from scipy.special import logit, expit\n",
    "\n",
    "def logistic_synthetic_example(N,d,k,corrupt=False):\n",
    "    #covariates, scaling the covariates to be of large norm amplifies the effect of corruptions\n",
    "    x = np.random.normal(0,1,(N,d))\n",
    "    #regressors\n",
    "    ell = np.random.normal(0,1,(k,d))\n",
    "    ell = ell/np.linalg.norm(ell)\n",
    "    #labels\n",
    "    y = np.zeros((N,k))\n",
    "    prob_list = np.zeros((N,k))\n",
    "    for i in range(N):\n",
    "        for j in range(k):\n",
    "            feature = x[i,:]\n",
    "            regressor = ell[j,:]\n",
    "            prob = expit(np.inner(feature,regressor))\n",
    "            prob_list[i,j] = prob\n",
    "            y[i,j] = np.random.binomial(1,prob)\n",
    "            #if prob > 0.5:\n",
    "            #    y[i,j] = 1\n",
    "            #else:\n",
    "            #    y[i,j] = 0\n",
    "    corr_frac = 0.1\n",
    "    corr = int(corr_frac*N)\n",
    "    print('number of corruptions')\n",
    "    print(corr)\n",
    "    if corrupt:\n",
    "        select = np.zeros((corr,k))\n",
    "        for j in range(k):\n",
    "            order = np.argsort(prob_list[:,j])\n",
    "            select[:,j] = order[:corr]\n",
    "        for i in range(corr):\n",
    "            for j in range(k):\n",
    "                print('flip label')\n",
    "                #print(select[i,j])\n",
    "                index = int(select[i,j])\n",
    "                y[index,j] = 1 - y[index,j]\n",
    "    data = {'cov': x, 'label': y, 'reg': ell}\n",
    "    return data\n",
    "\n",
    "#data = synthetic_example(1000,100,10)    \n",
    "#print(data)\n",
    "\n",
    "import pandas as pd, numpy as np, re\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "def parse_data(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        infoline = f.readline()\n",
    "        infoline = re.sub(r\"^b'\", \"\", str(infoline))\n",
    "        n_features = int(re.sub(r\"^\\d+\\s(\\d+)\\s\\d+.*$\", r\"\\1\", infoline))\n",
    "        features, labels = load_svmlight_file(f, n_features=n_features, multilabel=True)\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    labels = mlb.fit_transform(labels)\n",
    "    features = np.array(features.todense())\n",
    "    features = np.ascontiguousarray(features)\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "data_mode = 'logistic_synth'\n",
    "#data_mode = 'synthetic'\n",
    "#data_mode = 'real'\n",
    "N = 1000\n",
    "d = 10\n",
    "k = 2\n",
    "\n",
    "if data_mode == 'logistic_synth':\n",
    "    data = logistic_synthetic_example(N,d,k,corrupt=True)\n",
    "    #data = logistic_synthetic_example(N,d,k,corrupt=False)\n",
    "if data_mode == 'synthetic':\n",
    "    data = synthetic_example(1000,10,10)    \n",
    "elif data_mode == 'real': \n",
    "    x, y = parse_data(\"Bibtex_data.txt\")\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    data = {'cov': x, 'label': y}\n",
    "\n",
    "x = data['cov']\n",
    "y = data['label']\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', random_state=0, fit_intercept ='False')\n",
    "#a = np.zeros((2,3)).reshape(-1,1)\n",
    "#b = np.ones(2)\n",
    "\n",
    "#a = np.zeros(10,2).reshape(-1, 1)\n",
    "#b = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
    "lab = y[:,0]\n",
    "model.fit(x, lab)\n",
    "print(model.coef_)\n",
    "print(data['reg'])\n",
    "print('score')\n",
    "print(model.score(x,lab))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mw2 import MW_no_alt_min, get_weights, altmin_step\n",
    "\n",
    "def isotropic(Xs,fake=False):\n",
    "    if fake:\n",
    "        return Xs, np.eye(Xs.shape[1])\n",
    "    Sig = np.matmul(Xs.T,Xs)\n",
    "    Sig_sqrt = np.linalg.inv(sqrtm(Sig))\n",
    "    new_Xs = np.matmul(Xs,Sig_sqrt)\n",
    "    return new_Xs, Sig_sqrt\n",
    "\n",
    "def scram(x,y,params):\n",
    "    AM_steps = params[0]\n",
    "    altmin_params = params[1:]\n",
    "    N,d = x.shape\n",
    "    w = [0.]*d\n",
    "    a = [1.]*N\n",
    "    #iso_x, Sig_sqrt = isotropic(x)\n",
    "    iso_x = x\n",
    "    Sig_sqrt = np.eye(d)\n",
    "    AM_steps = 1\n",
    "    for i in range(AM_steps):\n",
    "        #print('AM step: ',i)\n",
    "        w,a = altmin_step(iso_x,y,a,altmin_params,init=False)\n",
    "    final_w = np.matmul(Sig_sqrt,w)    \n",
    "    return final_w\n",
    "\n",
    "#regression oracle \n",
    "def regression_oracle(x,y,mode='ols'):\n",
    "    if mode == 'ols':\n",
    "        model = LinearRegression()\n",
    "        model.fit(x,y)\n",
    "        regressor = model.coef_\n",
    "    if mode == 'scram':\n",
    "        lr = 0.5\n",
    "        lam = 0.2\n",
    "        MW_steps = 10\n",
    "        eta = 0.1\n",
    "        AM_steps = 10\n",
    "        params = (AM_steps,lr,lam,MW_steps,eta)\n",
    "        regressor = scram(x,y,params)\n",
    "    return regressor\n",
    "\n",
    "\n",
    "reg = regression_oracle(x,y[:,0])\n",
    "\n",
    "def optimal_reward(y):\n",
    "    a,b = y.shape\n",
    "    cumsum = 0\n",
    "    for i in range(a):\n",
    "        cumsum = cumsum + np.amax(y[i,:])\n",
    "    return cumsum/a\n",
    "\n",
    "max_reward = optimal_reward(y)\n",
    "print('Optimal Reward')\n",
    "print(max_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contextual bandits takes covariates and labels\n",
    "def contextual_bandit(cov_label):\n",
    "    cov = cov_label['cov']\n",
    "    labels = cov_label['label']\n",
    "    (N,d) = cov.shape\n",
    "    (N,k) = labels.shape\n",
    "    estimators = np.zeros((k,d))\n",
    "    action_list = []\n",
    "    mu = k\n",
    "    delta = 0.1\n",
    "    gamma = np.sqrt(k*N/(d*np.log(N/d) + 1./(2*delta)))\n",
    "    params = (mu,gamma)\n",
    "    rewards = []\n",
    "    mean_reward = []\n",
    "    for i in range(N):\n",
    "        print('iteration: ',i)\n",
    "        covariate = cov[i,:]\n",
    "        values = np.zeros(k)\n",
    "        for j in range(k):\n",
    "            est = estimators[j,:]\n",
    "            values[j] = np.inner(est,covariate)\n",
    "        action = select_action(values,params)\n",
    "        action_list.append(action)\n",
    "        bandit_feedback = labels[i,action]\n",
    "        rewards.append(bandit_feedback)\n",
    "        (data_x,data_y) = get_data(cov_label,action_list,action) \n",
    "        \n",
    "        #bug, ols can run on one datapoint but scram can't\n",
    "        #estimators[action,:] = regression_oracle(data_x,data_y,mode='ols')\n",
    "        estimators[action,:] = regression_oracle(data_x,data_y,mode='scram')\n",
    "        print('action')\n",
    "        print(action)\n",
    "        print('average reward')\n",
    "        #print(rewards)\n",
    "        avg_reward = sum(rewards)/len(rewards)\n",
    "        mean_reward.append(avg_reward)\n",
    "        print(avg_reward)\n",
    "    return mean_reward\n",
    "\n",
    "def get_data(cov_label,action_list,action):\n",
    "    cov = cov_label['cov']\n",
    "    labels = cov_label['label']\n",
    "    (N,d) = cov.shape\n",
    "    (N,k) = labels.shape\n",
    "    length = len(action_list)\n",
    "    count = 0\n",
    "    for i in range(length):\n",
    "        if action_list[i] == action:\n",
    "            count = count + 1\n",
    "    \n",
    "    data_x = np.zeros((count,d))\n",
    "    data_y = np.zeros(count)\n",
    "    counter = 0\n",
    "    for i in range(len(action_list)):\n",
    "        if action_list[i] == action:\n",
    "            data_x[counter] = cov[i,:]\n",
    "            data_y[counter] = labels[i,action]\n",
    "            counter = counter + 1\n",
    "    return (data_x,data_y) \n",
    "\n",
    "\n",
    "def select_action(values,params):\n",
    "    (mu,gamma) = params\n",
    "    k = mu\n",
    "    max_value = np.amax(values)\n",
    "    max_index = np.where(values == max_value)[0][0]\n",
    "    prob = np.zeros(len(values))\n",
    "    for i in range(k): \n",
    "        if i == max_index:\n",
    "            next\n",
    "        else: \n",
    "            prob[i] = 1./(mu + gamma*(max_value - values[i]))\n",
    "    prob[max_index] = 1 - np.sum(prob)\n",
    "    prob = prob/np.sum(prob)\n",
    "    #print('probability')\n",
    "    #print(prob)\n",
    "    #TODO roulette wheel\n",
    "    draw = np.random.rand()\n",
    "    sums = 0\n",
    "    action = 0\n",
    "    for i in range(k):\n",
    "        sums = sums + prob[i]\n",
    "        if sums >= draw:\n",
    "            action = i\n",
    "            break\n",
    "    return action\n",
    "\n",
    "mean_reward = contextual_bandit(data)\n",
    "#print('ground truth')\n",
    "#print(ell)\n",
    "#print('estimate')\n",
    "#print(est)\n",
    "#print('frobenius norm')\n",
    "#print(np.linalg.norm(ell - est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "domain = range(len(mean_reward))\n",
    "plt.scatter(domain, mean_reward)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[2,3],[1,4]])\n",
    "b = np.sort(a,axis=0)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([3,2,1])\n",
    "order = a.argsort()\n",
    "print(order)\n",
    "b = a[order]\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
