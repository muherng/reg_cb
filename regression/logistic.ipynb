{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "# mosek only needed if we don't use MW\n",
    "#import mosek\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cProfile\n",
    "#from baselines import *\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "from scipy.special import expit,logit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of corruptions\n",
      "100\n",
      "(1000, 3)\n",
      "[[ 0.0029023  -0.00537385 -0.01188337]]\n",
      "[ 0.2719751  -0.52660966 -0.80542647]\n",
      "score\n",
      "0.765\n"
     ]
    }
   ],
   "source": [
    "#synthetic example with N datapoints, in d dimensions, with k actions, random regressors\n",
    "#returns a dictionary of covariates x, labels y, regressors ell.  \n",
    "def synthetic_example(N,d,k):\n",
    "    #covariates\n",
    "    x = np.random.normal(0,1,(N,d,k))\n",
    "    #regressors\n",
    "    ell = np.random.normal(0,1,d)\n",
    "    #labels\n",
    "    y = np.zeros((N,k))\n",
    "    for i in range(N):\n",
    "        for j in range(k):\n",
    "            feature = x[i,:]\n",
    "            regressor = ell[j,:]\n",
    "            y[i,j] = np.inner(feature,regressor) + np.random.normal(0,1)\n",
    "    data = {'cov': x, 'label': y, 'reg': ell}\n",
    "    return data\n",
    "\n",
    "from scipy.special import logit, expit\n",
    "\n",
    "def logistic_synthetic_example(N,d,k,eta,corrupt=False):\n",
    "    #covariates, scaling the covariates to be of large norm amplifies the effect of corruptions\n",
    "    #good parameters: scale x by 100, d = 100, N = 1000\n",
    "    #scaling x produces the altmin beating logistic regression phenomenon\n",
    "    x = np.random.normal(0,1,(N,d,k))*100\n",
    "    #regressors\n",
    "    ell = np.random.normal(0,1,d)\n",
    "    ell = ell/np.linalg.norm(ell)\n",
    "    #labels\n",
    "    y = np.zeros((N,k))\n",
    "    prob_list = np.zeros((N,k))\n",
    "    for i in range(N):\n",
    "        for j in range(k):\n",
    "            feature = x[i,:,j]\n",
    "            prob = expit(np.inner(feature,ell))\n",
    "            prob_list[i,j] = prob\n",
    "            y[i,j] = np.random.binomial(1,prob)\n",
    "            #deterministic labels\n",
    "            #if prob > 0.5:\n",
    "            #    y[i,j] = 1\n",
    "            #else:\n",
    "            #    y[i,j] = 0\n",
    "    if corrupt:\n",
    "        corr = int(eta*N)\n",
    "        print('number of corruptions')\n",
    "        print(corr)\n",
    "        poison = False\n",
    "        if poison:\n",
    "            print('TODO: poisoning')\n",
    "            for i in range(corr):\n",
    "                for j in range(k): \n",
    "                    x[i,:,j] = ell*100\n",
    "                    y[i,j] = -1\n",
    "        else: \n",
    "            select = np.zeros((corr,k))\n",
    "            for j in range(k):\n",
    "                order = np.argsort(prob_list[:,j])\n",
    "                select[:,j] = order[:corr]\n",
    "            for i in range(corr):\n",
    "                for j in range(k):\n",
    "                    index = int(select[i,j])\n",
    "                    y[index,j] = 1 - y[index,j]\n",
    "    data = {'cov': x, 'label': y, 'reg': ell}\n",
    "    return data\n",
    "\n",
    "#data = synthetic_example(1000,100,10)    \n",
    "#print(data)\n",
    "\n",
    "import pandas as pd, numpy as np, re\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "def parse_data(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        infoline = f.readline()\n",
    "        infoline = re.sub(r\"^b'\", \"\", str(infoline))\n",
    "        n_features = int(re.sub(r\"^\\d+\\s(\\d+)\\s\\d+.*$\", r\"\\1\", infoline))\n",
    "        features, labels = load_svmlight_file(f, n_features=n_features, multilabel=True)\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    labels = mlb.fit_transform(labels)\n",
    "    features = np.array(features.todense())\n",
    "    features = np.ascontiguousarray(features)\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "data_mode = 'logistic_synth'\n",
    "#data_mode = 'synthetic'\n",
    "#data_mode = 'real'\n",
    "N = 1000\n",
    "d = 3\n",
    "k = 1000\n",
    "eta = 0.1\n",
    "\n",
    "#good settings\n",
    "#N= 1000, d = 50, k = 50, eta = 0.1\n",
    "if data_mode == 'logistic_synth':\n",
    "    data = logistic_synthetic_example(N,d,k,eta,corrupt=True)\n",
    "    #data = logistic_synthetic_example(N,d,k,eta,corrupt=False)\n",
    "if data_mode == 'synthetic':\n",
    "    data = synthetic_example(N,d,k)    \n",
    "elif data_mode == 'real': \n",
    "    x, y = parse_data(\"Bibtex_data.txt\")\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    data = {'cov': x, 'label': y}\n",
    "\n",
    "x = data['cov']\n",
    "y = data['label']\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', random_state=0, fit_intercept ='False')\n",
    "lab = y[:,0]\n",
    "#error on this line TODO\n",
    "cov = x[:,:,0]\n",
    "print(cov.shape)\n",
    "model.fit(cov, lab)\n",
    "print(model.coef_)\n",
    "print(data['reg'])\n",
    "print('score')\n",
    "print(model.score(x[:,:,0],lab))\n",
    "\n",
    "vanilla = model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression version of scram\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "def logistic_reg_oracle(x,y,mode='robust-logistic'):\n",
    "    if mode == 'robust-logistic':\n",
    "        lr = 0.1\n",
    "        lam = 0.0\n",
    "        MW_steps = 30\n",
    "        #eta = 0.1\n",
    "        AM_steps = 30\n",
    "        params = (AM_steps,lr,lam,MW_steps,eta)\n",
    "        regressor = logistic_scram(x,y,params)\n",
    "    if mode == 'vanilla':\n",
    "        (x_train,y_train) = hack(x,y)\n",
    "        model = LogisticRegression(solver='liblinear', random_state=0, fit_intercept ='False')\n",
    "        model.fit(x_train, y_train)\n",
    "        regressor = model.coef_[0]\n",
    "    return regressor\n",
    "\n",
    "#ensures two classes  \n",
    "def hack(x,y):\n",
    "    (N,d) = x.shape\n",
    "    x_train = np.zeros((N+2,d))\n",
    "    y_train = np.zeros(N+2)\n",
    "    x_train[:N,:] = x\n",
    "    y_train[:N] = y\n",
    "    x_train[N:N+2,:] = np.zeros((2,d))\n",
    "    y_train[N:N+2] = np.array([0,1])\n",
    "    return (x_train,y_train)\n",
    "\n",
    "def logistic_scram(x,y,params):\n",
    "    AM_steps = params[0]\n",
    "    altmin_params = params[1:]\n",
    "    N,d = x.shape\n",
    "    w = [0.]*d\n",
    "    a = [1.]*N\n",
    "    #print('a logistic scram first: ', a)\n",
    "    #print('first length of a:', len(a))\n",
    "    #TODO: fix isotropic step, for now identity covariance\n",
    "    #iso_x, Sig_sqrt = isotropic(x)\n",
    "    iso_x = x\n",
    "    Sig_sqrt = np.eye(d)\n",
    "    for i in range(AM_steps):\n",
    "        #print('a logistic scram: ', a)\n",
    "        w,a = logistic_altmin_step(iso_x,y,a,altmin_params)\n",
    "    final_w = np.matmul(Sig_sqrt,w)    \n",
    "    return final_w\n",
    "\n",
    "def logistic_altmin_step(Xs,Ys,a,params):\n",
    "    N,d = Xs.shape\n",
    "    #print('a logistic altmin step: ', a)\n",
    "    w = weighted_logistic_reg(Xs,Ys,a)\n",
    "    a = logistic_get_weights(Xs,Ys,w,params)\n",
    "    return w, a\n",
    "\n",
    "def weighted_logistic_reg(x,y,a):\n",
    "    n,d = x.shape\n",
    "    hard_weights = np.zeros(n)\n",
    "    m = min(int(n*(1 - eta))+1,n) \n",
    "    prob = a*m\n",
    "    for i in range(len(a)):\n",
    "        if prob[i] > 1: \n",
    "            prob[i] = 1\n",
    "        if prob[i] < 0:\n",
    "            prob[i] = 0\n",
    "        ind = np.random.binomial(1,prob[i])\n",
    "        hard_weights[i] = ind\n",
    "    \n",
    "    N_train = int(np.sum(hard_weights))\n",
    "    #hack to ensure two classes\n",
    "    x_train = np.zeros((N_train+2,d)) \n",
    "    y_train = np.zeros(N_train+2)\n",
    "    x_train[N_train:N_train+2,:] = np.zeros((2,d))\n",
    "    y_train[N_train:N_train+2] =  np.array([0,1])\n",
    "    \n",
    "    hold = 0\n",
    "    for i in range(len(a)):\n",
    "        if hard_weights[i] == 1:\n",
    "            x_train[hold,:] = x[i,:]\n",
    "            y_train[hold] = y[i]\n",
    "            hold = hold + 1\n",
    "    \n",
    "    model = LogisticRegression(solver='liblinear', random_state=0, fit_intercept ='False')\n",
    "    #lab = y[:,0]\n",
    "    model.fit(x_train, y_train)\n",
    "    regressor = model.coef_[0,:]\n",
    "    return regressor\n",
    "\n",
    "def logistic_get_weights(X,y,w,params):\n",
    "    n,d = X.shape\n",
    "    lr,lam,steps,eta = params\n",
    "    a = np.ones(n)/float(n)\n",
    "    Sig = np.matmul(X.T,X)\n",
    "    Xw = np.matmul(X,w)\n",
    "    pred = expit(Xw)\n",
    "    resids = np.absolute(y - pred)\n",
    "    for j in range(steps):\n",
    "        if lam > 0:\n",
    "            v = v_step(a,X,Sig,eta)\n",
    "        else:\n",
    "            v = np.zeros(d)\n",
    "        a = a_step(a,X,resids,v,lr=lr,lam=lam,eta=eta,n=n)\n",
    "    return a\n",
    "\n",
    "def outerprod(a,X):\n",
    "    \"\"\" Compute X^T diag(a) X \"\"\"\n",
    "    left = np.multiply(X.T,a)\n",
    "    return np.dot(left,X)\n",
    "\n",
    "def cap(a,m):\n",
    "    if np.max(a) <= 1./m:\n",
    "        return a\n",
    "    #sorted_a = np.sort(a)\n",
    "    ## BUG FIX: use -a to get descending order\n",
    "    sort_ids = np.argsort(-a)\n",
    "    # Faster code\n",
    "    Z = np.sum(a)\n",
    "    aprime = np.copy(a)\n",
    "    for i in range(1,min(m,len(a))):\n",
    "        Z -= a[sort_ids[i - 1]]\n",
    "        aprime_next = (1-i/m)*a[sort_ids[i]]/float(Z)\n",
    "        aprime[sort_ids[i-1]] = 1./m\n",
    "        #aprime_next = (m - i) * a[sort_ids[i]]/float(m * Z)\n",
    "        #this chunk of code sometimes does not execute \n",
    "        if aprime_next <= 1.0/m:\n",
    "            aprime[sort_ids[i:]] *= (1-i/m)/Z\n",
    "            #aprime[sort_ids[i:]] *= (m - i)/float(m * Z)\n",
    "            break\n",
    "    return aprime   \n",
    "        \n",
    "\n",
    "def v_step(a,X,Sig,eta,tol=0):\n",
    "    \"\"\" Compute top eigenvector of X^T diag(1/n-a) X\"\"\"\n",
    "    # Bug fix: this was formerly 1 and not 1/n\n",
    "    n = a.shape[0]\n",
    "    #m = int(n*(1 - eta)) \n",
    "    M = outerprod(1./n-a,X)\n",
    "\n",
    "    # this method is slower sometimes and faster sometimes vs other one, depending on d?\n",
    "    d = M.shape[0]\n",
    "\n",
    "    # Want top eigenvalue algebraically\n",
    "    eigenvalue, v = eigh(M, eigvals=(d-1,d-1)) \n",
    "    #eigenvalue, v = largest_eigsh(M, 1, which='LA',tol=tol)\n",
    "    \n",
    "    ## Don't regularize if constraint is satisfied\n",
    "    if eigenvalue > 0:\n",
    "        return v[:,0]\n",
    "    else:\n",
    "        return np.zeros(shape=v[:,0].shape)\n",
    "    \n",
    "# @jit(nopython=True)\n",
    "def a_step(a,X,resids_sq,v,lr,lam,eta,n):\n",
    "    \"\"\" Step to minimize \\sum_i a_i resids_sq[i]^2 + \\lambda sigma_{max}(X^T diag(1/n - a) X)\"\"\"\n",
    "    m = min(int(n*(1 - eta))+1,n) \n",
    "    \n",
    "    Xv_squared = np.dot(X,v)**2\n",
    "    penalties = resids_sq - lam * Xv_squared\n",
    "\n",
    "    # multiplicative update\n",
    "    a *= np.exp(-lr * penalties)\n",
    "    a /= np.sum(a)\n",
    "    a = cap(a,m)\n",
    "    return a\n",
    "\n",
    "def logistic_eval(x,y,reg):\n",
    "    n,d = x.shape\n",
    "    error = 0\n",
    "    for i in range(n):\n",
    "        error = error + np.absolute(y[i] - expit(np.inner(reg,x[i,:])))\n",
    "        \n",
    "    error = error/n\n",
    "    return error \n",
    "    \n",
    "#reg = logistic_reg_oracle(x,y[:,0])\n",
    "#print('non robust performance: ', logistic_eval(x,y,vanilla))\n",
    "#print('robust performance: ',logistic_eval(x,y,reg))\n",
    "#print('vanilla: ', vanilla)\n",
    "#print('reg: ', reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0\n",
      "iteration:  1\n",
      "iteration:  2\n",
      "iteration:  3\n",
      "iteration:  4\n",
      "iteration:  5\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "71\n",
      "average reward\n",
      "1.0\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.1\n",
      "iteration:  6\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "57\n",
      "average reward\n",
      "1.0\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.16666666666666666\n",
      "iteration:  7\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "691\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.21428571428571427\n",
      "iteration:  8\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "420\n",
      "average reward\n",
      "0.75\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.25\n",
      "iteration:  9\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "83\n",
      "average reward\n",
      "0.8\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.2777777777777778\n",
      "iteration:  10\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "993\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.3\n",
      "iteration:  11\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "725\n",
      "average reward\n",
      "0.7142857142857143\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.3181818181818182\n",
      "iteration:  12\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "100\n",
      "average reward\n",
      "0.75\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.3333333333333333\n",
      "iteration:  13\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "298\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.34615384615384615\n",
      "iteration:  14\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "481\n",
      "average reward\n",
      "0.7\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.35714285714285715\n",
      "iteration:  15\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "722\n",
      "average reward\n",
      "0.7272727272727273\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.36666666666666664\n",
      "iteration:  16\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "362\n",
      "average reward\n",
      "0.75\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.375\n",
      "iteration:  17\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "876\n",
      "average reward\n",
      "0.6923076923076923\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.38235294117647056\n",
      "iteration:  18\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "515\n",
      "average reward\n",
      "0.6428571428571429\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.3888888888888889\n",
      "iteration:  19\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "948\n",
      "average reward\n",
      "0.6\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.39473684210526316\n",
      "iteration:  20\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "890\n",
      "average reward\n",
      "0.5625\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4\n",
      "iteration:  21\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "453\n",
      "average reward\n",
      "0.5882352941176471\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.40476190476190477\n",
      "iteration:  22\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "833\n",
      "average reward\n",
      "0.6111111111111112\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4090909090909091\n",
      "iteration:  23\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "535\n",
      "average reward\n",
      "0.5789473684210527\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.41304347826086957\n",
      "iteration:  24\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "210\n",
      "average reward\n",
      "0.55\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4166666666666667\n",
      "iteration:  25\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "753\n",
      "average reward\n",
      "0.5238095238095238\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.42\n",
      "iteration:  26\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "784\n",
      "average reward\n",
      "0.5454545454545454\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4230769230769231\n",
      "iteration:  27\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "262\n",
      "average reward\n",
      "0.5217391304347826\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.42592592592592593\n",
      "iteration:  28\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "31\n",
      "average reward\n",
      "0.5416666666666666\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.42857142857142855\n",
      "iteration:  29\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "971\n",
      "average reward\n",
      "0.52\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.43103448275862066\n",
      "iteration:  30\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "42\n",
      "average reward\n",
      "0.5\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.43333333333333335\n",
      "iteration:  31\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "544\n",
      "average reward\n",
      "0.48148148148148145\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.43548387096774194\n",
      "iteration:  32\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "255\n",
      "average reward\n",
      "0.4642857142857143\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4375\n",
      "iteration:  33\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "922\n",
      "average reward\n",
      "0.4482758620689655\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4393939393939394\n",
      "iteration:  34\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "587\n",
      "average reward\n",
      "0.43333333333333335\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4411764705882353\n",
      "iteration:  35\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "337\n",
      "average reward\n",
      "0.45161290322580644\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.44285714285714284\n",
      "iteration:  36\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "676\n",
      "average reward\n",
      "0.46875\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4444444444444444\n",
      "iteration:  37\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "305\n",
      "average reward\n",
      "0.45454545454545453\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.44594594594594594\n",
      "iteration:  38\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "972\n",
      "average reward\n",
      "0.47058823529411764\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4473684210526316\n",
      "iteration:  39\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "142\n",
      "average reward\n",
      "0.45714285714285713\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.44871794871794873\n",
      "iteration:  40\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "988\n",
      "average reward\n",
      "0.4722222222222222\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.45\n",
      "iteration:  41\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "869\n",
      "average reward\n",
      "0.4864864864864865\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.45121951219512196\n",
      "iteration:  42\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "373\n",
      "average reward\n",
      "0.47368421052631576\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4523809523809524\n",
      "iteration:  43\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "213\n",
      "average reward\n",
      "0.46153846153846156\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.45348837209302323\n",
      "iteration:  44\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "964\n",
      "average reward\n",
      "0.475\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.45454545454545453\n",
      "iteration:  45\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "838\n",
      "average reward\n",
      "0.4634146341463415\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.45555555555555555\n",
      "iteration:  46\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "123\n",
      "average reward\n",
      "0.4523809523809524\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.45652173913043476\n",
      "iteration:  47\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "791\n",
      "average reward\n",
      "0.46511627906976744\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4574468085106383\n",
      "iteration:  48\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "25\n",
      "average reward\n",
      "0.45454545454545453\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4583333333333333\n",
      "iteration:  49\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "704\n",
      "average reward\n",
      "0.4666666666666667\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.45918367346938777\n",
      "iteration:  50\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "758\n",
      "average reward\n",
      "0.4782608695652174\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.46\n",
      "iteration:  51\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "928\n",
      "average reward\n",
      "0.48936170212765956\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.46078431372549017\n",
      "iteration:  52\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "113\n",
      "average reward\n",
      "0.5\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.46153846153846156\n",
      "iteration:  53\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "471\n",
      "average reward\n",
      "0.4897959183673469\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.46226415094339623\n",
      "iteration:  54\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "622\n",
      "average reward\n",
      "0.5\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.46296296296296297\n",
      "iteration:  55\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "206\n",
      "average reward\n",
      "0.49019607843137253\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4636363636363636\n",
      "iteration:  56\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "960\n",
      "average reward\n",
      "0.5\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4642857142857143\n",
      "iteration:  57\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "949\n",
      "average reward\n",
      "0.49056603773584906\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4649122807017544\n",
      "iteration:  58\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "653\n",
      "average reward\n",
      "0.48148148148148145\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.46551724137931033\n",
      "iteration:  59\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "381\n",
      "average reward\n",
      "0.4727272727272727\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4661016949152542\n",
      "iteration:  60\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "886\n",
      "average reward\n",
      "0.48214285714285715\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4666666666666667\n",
      "iteration:  61\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "211\n",
      "average reward\n",
      "0.49122807017543857\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4672131147540984\n",
      "iteration:  62\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "921\n",
      "average reward\n",
      "0.5\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.46774193548387094\n",
      "iteration:  63\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "377\n",
      "average reward\n",
      "0.4915254237288136\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.46825396825396826\n",
      "iteration:  64\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "850\n",
      "average reward\n",
      "0.5\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.46875\n",
      "iteration:  65\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "497\n",
      "average reward\n",
      "0.4918032786885246\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.46923076923076923\n",
      "iteration:  66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "501\n",
      "average reward\n",
      "0.5\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4696969696969697\n",
      "iteration:  67\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "23\n",
      "average reward\n",
      "0.5079365079365079\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4701492537313433\n",
      "iteration:  68\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "128\n",
      "average reward\n",
      "0.5\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47058823529411764\n",
      "iteration:  69\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "705\n",
      "average reward\n",
      "0.5076923076923077\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47101449275362317\n",
      "iteration:  70\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "425\n",
      "average reward\n",
      "0.5151515151515151\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4714285714285714\n",
      "iteration:  71\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "96\n",
      "average reward\n",
      "0.5223880597014925\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47183098591549294\n",
      "iteration:  72\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "369\n",
      "average reward\n",
      "0.5294117647058824\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4722222222222222\n",
      "iteration:  73\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "241\n",
      "average reward\n",
      "0.5217391304347826\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4726027397260274\n",
      "iteration:  74\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "861\n",
      "average reward\n",
      "0.5285714285714286\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47297297297297297\n",
      "iteration:  75\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "885\n",
      "average reward\n",
      "0.5352112676056338\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47333333333333333\n",
      "iteration:  76\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "280\n",
      "average reward\n",
      "0.5277777777777778\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47368421052631576\n",
      "iteration:  77\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "60\n",
      "average reward\n",
      "0.5342465753424658\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.474025974025974\n",
      "iteration:  78\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "90\n",
      "average reward\n",
      "0.5405405405405406\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47435897435897434\n",
      "iteration:  79\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "699\n",
      "average reward\n",
      "0.5466666666666666\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47468354430379744\n",
      "iteration:  80\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "918\n",
      "average reward\n",
      "0.5526315789473685\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.475\n",
      "iteration:  81\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "766\n",
      "average reward\n",
      "0.5454545454545454\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47530864197530864\n",
      "iteration:  82\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "849\n",
      "average reward\n",
      "0.5384615384615384\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47560975609756095\n",
      "iteration:  83\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "716\n",
      "average reward\n",
      "0.5316455696202531\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4759036144578313\n",
      "iteration:  84\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "810\n",
      "average reward\n",
      "0.5375\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47619047619047616\n",
      "iteration:  85\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "344\n",
      "average reward\n",
      "0.5432098765432098\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4764705882352941\n",
      "iteration:  86\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "908\n",
      "average reward\n",
      "0.5487804878048781\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47674418604651164\n",
      "iteration:  87\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "742\n",
      "average reward\n",
      "0.5542168674698795\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47701149425287354\n",
      "iteration:  88\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "860\n",
      "average reward\n",
      "0.5476190476190477\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4772727272727273\n",
      "iteration:  89\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "3\n",
      "average reward\n",
      "0.5411764705882353\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47752808988764045\n",
      "iteration:  90\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "644\n",
      "average reward\n",
      "0.5465116279069767\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4777777777777778\n",
      "iteration:  91\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "879\n",
      "average reward\n",
      "0.5402298850574713\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47802197802197804\n",
      "iteration:  92\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "417\n",
      "average reward\n",
      "0.5454545454545454\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4782608695652174\n",
      "iteration:  93\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "7\n",
      "average reward\n",
      "0.550561797752809\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.478494623655914\n",
      "iteration:  94\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "489\n",
      "average reward\n",
      "0.5444444444444444\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4787234042553192\n",
      "iteration:  95\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "437\n",
      "average reward\n",
      "0.5384615384615384\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4789473684210526\n",
      "iteration:  96\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "152\n",
      "average reward\n",
      "0.532608695652174\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4791666666666667\n",
      "iteration:  97\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "493\n",
      "average reward\n",
      "0.5376344086021505\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4793814432989691\n",
      "iteration:  98\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "549\n",
      "average reward\n",
      "0.5425531914893617\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47959183673469385\n",
      "iteration:  99\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "413\n",
      "average reward\n",
      "0.5368421052631579\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4797979797979798\n",
      "iteration:  100\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "885\n",
      "average reward\n",
      "0.53125\n",
      "logistic evaluation:  0.3233918911160042\n",
      "average error per step:  0.47596844795408044\n",
      "iteration:  101\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "75\n",
      "average reward\n",
      "0.5360824742268041\n",
      "logistic evaluation:  0.32158782127998164\n",
      "average error per step:  0.4726358570618787\n",
      "iteration:  102\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "928\n",
      "average reward\n",
      "0.5408163265306123\n",
      "logistic evaluation:  0.3184788858585922\n",
      "average error per step:  0.4680155787855551\n",
      "iteration:  103\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "434\n",
      "average reward\n",
      "0.5454545454545454\n",
      "logistic evaluation:  0.31546945178994384\n",
      "average error per step:  0.4635251143577261\n",
      "iteration:  104\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "936\n",
      "average reward\n",
      "0.54\n",
      "logistic evaluation:  0.3131223366091518\n",
      "average error per step:  0.45973181862165924\n",
      "iteration:  105\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "289\n",
      "average reward\n",
      "0.5346534653465347\n",
      "logistic evaluation:  0.31230615978097254\n",
      "average error per step:  0.4575115878997592\n",
      "iteration:  106\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "811\n",
      "average reward\n",
      "0.5392156862745098\n",
      "logistic evaluation:  0.3181269803010038\n",
      "average error per step:  0.46201745929150023\n",
      "iteration:  107\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "297\n",
      "average reward\n",
      "0.5436893203883495\n",
      "logistic evaluation:  0.3193516474543665\n",
      "average error per step:  0.46190880110059074\n",
      "iteration:  108\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "228\n",
      "average reward\n",
      "0.5480769230769231\n",
      "logistic evaluation:  0.3178181924995757\n",
      "average error per step:  0.45904117384393867\n",
      "iteration:  109\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "2\n",
      "average reward\n",
      "0.5428571428571428\n",
      "logistic evaluation:  0.31819909106100414\n",
      "average error per step:  0.4581299432055237\n",
      "iteration:  110\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "400\n",
      "average reward\n",
      "0.5471698113207547\n",
      "logistic evaluation:  0.316109869926075\n",
      "average error per step:  0.4547496304953268\n",
      "iteration:  111\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "969\n",
      "average reward\n",
      "0.5420560747663551\n",
      "logistic evaluation:  0.31521385242061684\n",
      "average error per step:  0.4525965339081145\n",
      "iteration:  112\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "735\n",
      "average reward\n",
      "0.5462962962962963\n",
      "logistic evaluation:  0.31309008706044983\n",
      "average error per step:  0.44922717527252193\n",
      "iteration:  113\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "921\n",
      "average reward\n",
      "0.5504587155963303\n",
      "logistic evaluation:  0.31258144973470076\n",
      "average error per step:  0.44750928373847354\n",
      "iteration:  114\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "980\n",
      "average reward\n",
      "0.5545454545454546\n",
      "logistic evaluation:  0.3136001067084414\n",
      "average error per step:  0.44735329880844193\n",
      "iteration:  115\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "588\n",
      "average reward\n",
      "0.5585585585585585\n",
      "logistic evaluation:  0.3118241069777937\n",
      "average error per step:  0.44439878436622343\n",
      "iteration:  116\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "797\n",
      "average reward\n",
      "0.5535714285714286\n",
      "logistic evaluation:  0.3142250722315946\n",
      "average error per step:  0.44567756244644996\n",
      "iteration:  117\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "258\n",
      "average reward\n",
      "0.5486725663716814\n",
      "logistic evaluation:  0.31653615259693474\n",
      "average error per step:  0.44688487007803357\n",
      "iteration:  118\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "117\n",
      "average reward\n",
      "0.543859649122807\n",
      "logistic evaluation:  0.31601474452990524\n",
      "average error per step:  0.4452543931504267\n",
      "iteration:  119\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "900\n",
      "average reward\n",
      "0.5391304347826087\n",
      "logistic evaluation:  0.31477705284841434\n",
      "average error per step:  0.4429202532311038\n",
      "iteration:  120\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "708\n",
      "average reward\n",
      "0.5344827586206896\n",
      "logistic evaluation:  0.3171674440563644\n",
      "average error per step:  0.4442627043625976\n",
      "iteration:  121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "315\n",
      "average reward\n",
      "0.5384615384615384\n",
      "logistic evaluation:  0.31798013695207983\n",
      "average error per step:  0.4440317396764079\n",
      "iteration:  122\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "105\n",
      "average reward\n",
      "0.5423728813559322\n",
      "logistic evaluation:  0.3154002204190382\n",
      "average error per step:  0.44039746642814204\n",
      "iteration:  123\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "88\n",
      "average reward\n",
      "0.5462184873949579\n",
      "logistic evaluation:  0.320599428440939\n",
      "average error per step:  0.444622706661529\n",
      "iteration:  124\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "841\n",
      "average reward\n",
      "0.55\n",
      "logistic evaluation:  0.3193970047104414\n",
      "average error per step:  0.4424103982378774\n",
      "iteration:  125\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "98\n",
      "average reward\n",
      "0.5454545454545454\n",
      "logistic evaluation:  0.321407001451645\n",
      "average error per step:  0.44345236780479114\n",
      "iteration:  126\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "681\n",
      "average reward\n",
      "0.5491803278688525\n",
      "logistic evaluation:  0.31895521504236407\n",
      "average error per step:  0.44001250875453857\n",
      "iteration:  127\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "967\n",
      "average reward\n",
      "0.5447154471544715\n",
      "logistic evaluation:  0.31750571375267894\n",
      "average error per step:  0.43759838703176795\n",
      "iteration:  128\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "124\n",
      "average reward\n",
      "0.5403225806451613\n",
      "logistic evaluation:  0.31868517712361316\n",
      "average error per step:  0.4378488409502947\n",
      "iteration:  129\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "0\n",
      "average reward\n",
      "0.536\n",
      "logistic evaluation:  0.31752225318488625\n",
      "average error per step:  0.43575315276532434\n",
      "iteration:  130\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "564\n",
      "average reward\n",
      "0.5317460317460317\n",
      "logistic evaluation:  0.3176500486712556\n",
      "average error per step:  0.4349724628355855\n",
      "iteration:  131\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "499\n",
      "average reward\n",
      "0.5354330708661418\n",
      "logistic evaluation:  0.3190039557523535\n",
      "average error per step:  0.4354411141374221\n",
      "iteration:  132\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "965\n",
      "average reward\n",
      "0.53125\n",
      "logistic evaluation:  0.3204179863005923\n",
      "average error per step:  0.43598375735356365\n",
      "iteration:  133\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "51\n",
      "average reward\n",
      "0.5271317829457365\n",
      "logistic evaluation:  0.321160663289674\n",
      "average error per step:  0.4358631028083304\n",
      "iteration:  134\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "350\n",
      "average reward\n",
      "0.5230769230769231\n",
      "logistic evaluation:  0.32231647385064743\n",
      "average error per step:  0.43617155046663453\n",
      "iteration:  135\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "150\n",
      "average reward\n",
      "0.5267175572519084\n",
      "logistic evaluation:  0.3230747891485158\n",
      "average error per step:  0.43609211197696124\n",
      "iteration:  136\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "114\n",
      "average reward\n",
      "0.5303030303030303\n",
      "logistic evaluation:  0.3222547578219808\n",
      "average error per step:  0.4344350412816397\n",
      "iteration:  137\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "131\n",
      "average reward\n",
      "0.5338345864661654\n",
      "logistic evaluation:  0.3268739085629558\n",
      "average error per step:  0.43826907426554396\n",
      "iteration:  138\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "498\n",
      "average reward\n",
      "0.5373134328358209\n",
      "logistic evaluation:  0.3316045834109267\n",
      "average error per step:  0.4422268180203655\n",
      "iteration:  139\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "165\n",
      "average reward\n",
      "0.5407407407407407\n",
      "logistic evaluation:  0.3337549260245567\n",
      "average error per step:  0.4435967873102846\n",
      "iteration:  140\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "757\n",
      "average reward\n",
      "0.5441176470588235\n",
      "logistic evaluation:  0.3380854353313517\n",
      "average error per step:  0.44717364410294436\n",
      "iteration:  141\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "540\n",
      "average reward\n",
      "0.5401459854014599\n",
      "logistic evaluation:  0.3372052472669648\n",
      "average error per step:  0.4455135383305009\n",
      "iteration:  142\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "871\n",
      "average reward\n",
      "0.5434782608695652\n",
      "logistic evaluation:  0.3384386781698385\n",
      "average error per step:  0.4459929209223841\n",
      "iteration:  143\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "361\n",
      "average reward\n",
      "0.539568345323741\n",
      "logistic evaluation:  0.3364883871797895\n",
      "average error per step:  0.44327686396210714\n",
      "iteration:  144\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "961\n",
      "average reward\n",
      "0.5428571428571428\n",
      "logistic evaluation:  0.33420738512415976\n",
      "average error per step:  0.44023843497010273\n",
      "iteration:  145\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "185\n",
      "average reward\n",
      "0.5390070921985816\n",
      "logistic evaluation:  0.3348881577254259\n",
      "average error per step:  0.4401926539351987\n",
      "iteration:  146\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "849\n",
      "average reward\n",
      "0.5352112676056338\n",
      "logistic evaluation:  0.3331668969157706\n",
      "average error per step:  0.43773833999527334\n",
      "iteration:  147\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "864\n",
      "average reward\n",
      "0.5384615384615384\n",
      "logistic evaluation:  0.33219013890640886\n",
      "average error per step:  0.43604356701251795\n",
      "iteration:  148\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "526\n",
      "average reward\n",
      "0.5416666666666666\n",
      "logistic evaluation:  0.33033414537342765\n",
      "average error per step:  0.43347332063062405\n",
      "iteration:  149\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "531\n",
      "average reward\n",
      "0.5379310344827586\n",
      "logistic evaluation:  0.3301092077435049\n",
      "average error per step:  0.43255466412226423\n",
      "iteration:  150\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "591\n",
      "average reward\n",
      "0.541095890410959\n",
      "logistic evaluation:  0.33082322366564487\n",
      "average error per step:  0.43259047044136006\n",
      "iteration:  151\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "973\n",
      "average reward\n",
      "0.54421768707483\n",
      "logistic evaluation:  0.3330074288371364\n",
      "average error per step:  0.43411518527110177\n",
      "iteration:  152\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "355\n",
      "average reward\n",
      "0.5405405405405406\n",
      "logistic evaluation:  0.33255586631013123\n",
      "average error per step:  0.4329954693298797\n",
      "iteration:  153\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "646\n",
      "average reward\n",
      "0.5436241610738255\n",
      "logistic evaluation:  0.33148560116057874\n",
      "average error per step:  0.4312617409896781\n",
      "iteration:  154\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "86\n",
      "average reward\n",
      "0.54\n",
      "logistic evaluation:  0.33109751332134163\n",
      "average error per step:  0.43022323608765967\n",
      "iteration:  155\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "287\n",
      "average reward\n",
      "0.543046357615894\n",
      "logistic evaluation:  0.3352687094776646\n",
      "average error per step:  0.4337818223948859\n",
      "iteration:  156\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "87\n",
      "average reward\n",
      "0.5460526315789473\n",
      "logistic evaluation:  0.3333141059013864\n",
      "average error per step:  0.4311831949949315\n",
      "iteration:  157\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "283\n",
      "average reward\n",
      "0.5424836601307189\n",
      "logistic evaluation:  0.33203784980146483\n",
      "average error per step:  0.4292754398810389\n",
      "iteration:  158\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "259\n",
      "average reward\n",
      "0.5454545454545454\n",
      "logistic evaluation:  0.32995712980539527\n",
      "average error per step:  0.4265661229857563\n",
      "iteration:  159\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "94\n",
      "average reward\n",
      "0.5483870967741935\n",
      "logistic evaluation:  0.32931063900943525\n",
      "average error per step:  0.4253079624792534\n",
      "iteration:  160\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "344\n",
      "average reward\n",
      "0.5512820512820513\n",
      "logistic evaluation:  0.33328888405736057\n",
      "average error per step:  0.42871108828704185\n",
      "iteration:  161\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "406\n",
      "average reward\n",
      "0.5477707006369427\n",
      "logistic evaluation:  0.33315566993980494\n",
      "average error per step:  0.4279843622542861\n",
      "iteration:  162\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "74\n",
      "average reward\n",
      "0.5506329113924051\n",
      "logistic evaluation:  0.3332617310958001\n",
      "average error per step:  0.4275057158105375\n",
      "iteration:  163\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "485\n",
      "average reward\n",
      "0.5471698113207547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic evaluation:  0.33151323978881725\n",
      "average error per step:  0.4251683136077159\n",
      "iteration:  164\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "675\n",
      "average reward\n",
      "0.55\n",
      "logistic evaluation:  0.33492455926403497\n",
      "average error per step:  0.4280293662881551\n",
      "iteration:  165\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "693\n",
      "average reward\n",
      "0.5527950310559007\n",
      "logistic evaluation:  0.33468389948148203\n",
      "average error per step:  0.42722297640374346\n",
      "iteration:  166\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "884\n",
      "average reward\n",
      "0.5555555555555556\n",
      "logistic evaluation:  0.3340443048386693\n",
      "average error per step:  0.42602206446234603\n",
      "iteration:  167\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "772\n",
      "average reward\n",
      "0.5521472392638037\n",
      "logistic evaluation:  0.33345636745757223\n",
      "average error per step:  0.42487984147044183\n",
      "iteration:  168\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "391\n",
      "average reward\n",
      "0.5548780487804879\n",
      "logistic evaluation:  0.33230003797169194\n",
      "average error per step:  0.42317244172564045\n",
      "iteration:  169\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "503\n",
      "average reward\n",
      "0.5575757575757576\n",
      "logistic evaluation:  0.33174695860309855\n",
      "average error per step:  0.42207838316697277\n",
      "iteration:  170\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "296\n",
      "average reward\n",
      "0.5602409638554217\n",
      "logistic evaluation:  0.3323761729095446\n",
      "average error per step:  0.4221799374130811\n",
      "iteration:  171\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "430\n",
      "average reward\n",
      "0.562874251497006\n",
      "logistic evaluation:  0.33218026897759223\n",
      "average error per step:  0.4214577196306288\n",
      "iteration:  172\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "264\n",
      "average reward\n",
      "0.5654761904761905\n",
      "logistic evaluation:  0.330951939444569\n",
      "average error per step:  0.4197031937011749\n",
      "iteration:  173\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "459\n",
      "average reward\n",
      "0.5680473372781065\n",
      "logistic evaluation:  0.32978269710561586\n",
      "average error per step:  0.41801417970560006\n",
      "iteration:  174\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "849\n",
      "average reward\n",
      "0.5705882352941176\n",
      "logistic evaluation:  0.32802822071568444\n",
      "average error per step:  0.4157425426318186\n",
      "iteration:  175\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "498\n",
      "average reward\n",
      "0.5672514619883041\n",
      "logistic evaluation:  0.32703806703768995\n",
      "average error per step:  0.41424550623614337\n",
      "iteration:  176\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "625\n",
      "average reward\n",
      "0.5697674418604651\n",
      "logistic evaluation:  0.3254452332378413\n",
      "average error per step:  0.4121481254306225\n",
      "iteration:  177\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "598\n",
      "average reward\n",
      "0.5664739884393064\n",
      "logistic evaluation:  0.3246618423719384\n",
      "average error per step:  0.4108704617790774\n",
      "iteration:  178\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "461\n",
      "average reward\n",
      "0.5689655172413793\n",
      "logistic evaluation:  0.3258594720117845\n",
      "average error per step:  0.41159050158877014\n",
      "iteration:  179\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "655\n",
      "average reward\n",
      "0.5657142857142857\n",
      "logistic evaluation:  0.32549128690620055\n",
      "average error per step:  0.4107413152838422\n",
      "iteration:  180\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "11\n",
      "average reward\n",
      "0.5681818181818182\n",
      "logistic evaluation:  0.325545433243652\n",
      "average error per step:  0.41032215116551485\n",
      "iteration:  181\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "344\n",
      "average reward\n",
      "0.5706214689265536\n",
      "logistic evaluation:  0.3261721228491105\n",
      "average error per step:  0.4104839234874574\n",
      "iteration:  182\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "295\n",
      "average reward\n",
      "0.5730337078651685\n",
      "logistic evaluation:  0.3267980921988943\n",
      "average error per step:  0.41065008057741387\n",
      "iteration:  183\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "535\n",
      "average reward\n",
      "0.5754189944134078\n",
      "logistic evaluation:  0.32539044296388214\n",
      "average error per step:  0.40877653168331135\n",
      "iteration:  184\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "433\n",
      "average reward\n",
      "0.5777777777777777\n",
      "logistic evaluation:  0.32407744359767704\n",
      "average error per step:  0.4070032111862061\n",
      "iteration:  185\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "842\n",
      "average reward\n",
      "0.580110497237569\n",
      "logistic evaluation:  0.32671373627951356\n",
      "average error per step:  0.4092055067063848\n",
      "iteration:  186\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "841\n",
      "average reward\n",
      "0.5769230769230769\n",
      "logistic evaluation:  0.3261362736353081\n",
      "average error per step:  0.4081814352822274\n",
      "iteration:  187\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "994\n",
      "average reward\n",
      "0.5792349726775956\n",
      "logistic evaluation:  0.32441606694272335\n",
      "average error per step:  0.40601328544344206\n",
      "iteration:  188\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "412\n",
      "average reward\n",
      "0.5760869565217391\n",
      "logistic evaluation:  0.32401083586297696\n",
      "average error per step:  0.4051718711212464\n",
      "iteration:  189\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "819\n",
      "average reward\n",
      "0.572972972972973\n",
      "logistic evaluation:  0.3234669186803829\n",
      "average error per step:  0.40419565260298645\n",
      "iteration:  190\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "628\n",
      "average reward\n",
      "0.5752688172043011\n",
      "logistic evaluation:  0.32684882974485624\n",
      "average error per step:  0.4071704751261012\n",
      "iteration:  191\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "916\n",
      "average reward\n",
      "0.5721925133689839\n",
      "logistic evaluation:  0.326178559876451\n",
      "average error per step:  0.40607616381659833\n",
      "iteration:  192\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "919\n",
      "average reward\n",
      "0.574468085106383\n",
      "logistic evaluation:  0.32712023318024647\n",
      "average error per step:  0.4066066083149961\n",
      "iteration:  193\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "973\n",
      "average reward\n",
      "0.5767195767195767\n",
      "logistic evaluation:  0.32970964966057187\n",
      "average error per step:  0.4087975949577339\n",
      "iteration:  194\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "713\n",
      "average reward\n",
      "0.5789473684210527\n",
      "logistic evaluation:  0.3327566488567596\n",
      "average error per step:  0.41145263051422587\n",
      "iteration:  195\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "627\n",
      "average reward\n",
      "0.5759162303664922\n",
      "logistic evaluation:  0.3320271675499085\n",
      "average error per step:  0.4103158391408911\n",
      "iteration:  196\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "93\n",
      "average reward\n",
      "0.5729166666666666\n",
      "logistic evaluation:  0.331263481729618\n",
      "average error per step:  0.40914882496646143\n",
      "iteration:  197\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "690\n",
      "average reward\n",
      "0.5699481865284974\n",
      "logistic evaluation:  0.3308997918602161\n",
      "average error per step:  0.4083879318833223\n",
      "iteration:  198\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "604\n",
      "average reward\n",
      "0.5670103092783505\n",
      "logistic evaluation:  0.3309686362464872\n",
      "average error per step:  0.40806576972597297\n",
      "iteration:  199\n",
      "estimator:  [ 0.00810757 -0.00453581 -0.01507658]\n",
      "action\n",
      "218\n",
      "average reward\n",
      "0.5692307692307692\n",
      "logistic evaluation:  0.33126881646581824\n",
      "average error per step:  0.4079800356073133\n",
      "iteration:  200\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "583\n",
      "average reward\n",
      "0.5663265306122449\n",
      "logistic evaluation:  0.3587575387670147\n",
      "average error per step:  0.40802827809663056\n",
      "iteration:  201\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "14\n",
      "average reward\n",
      "0.5685279187817259\n",
      "logistic evaluation:  0.35838389516703206\n",
      "average error per step:  0.4074076475168988\n",
      "iteration:  202\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "420\n",
      "average reward\n",
      "0.5707070707070707\n",
      "logistic evaluation:  0.3589209133327013\n",
      "average error per step:  0.40770463234502247\n",
      "iteration:  203\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "866\n",
      "average reward\n",
      "0.5728643216080402\n",
      "logistic evaluation:  0.35719321009051197\n",
      "average error per step:  0.40572810436266316\n",
      "iteration:  204\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "58\n",
      "average reward\n",
      "0.57\n",
      "logistic evaluation:  0.3572895110960079\n",
      "average error per step:  0.40558696128351857\n",
      "iteration:  205\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "38\n",
      "average reward\n",
      "0.572139303482587\n",
      "logistic evaluation:  0.356567000086802\n",
      "average error per step:  0.4046253285123775\n",
      "iteration:  206\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "707\n",
      "average reward\n",
      "0.5742574257425742\n",
      "logistic evaluation:  0.3563537763882361\n",
      "average error per step:  0.4041777768908789\n",
      "iteration:  207\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "53\n",
      "average reward\n",
      "0.5714285714285714\n",
      "logistic evaluation:  0.35642351916452325\n",
      "average error per step:  0.4040168227699372\n",
      "iteration:  208\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "969\n",
      "average reward\n",
      "0.5735294117647058\n",
      "logistic evaluation:  0.3560162354880351\n",
      "average error per step:  0.40337876703920916\n",
      "iteration:  209\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "115\n",
      "average reward\n",
      "0.5707317073170731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic evaluation:  0.3552186046237082\n",
      "average error per step:  0.402350704775765\n",
      "iteration:  210\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "277\n",
      "average reward\n",
      "0.5679611650485437\n",
      "logistic evaluation:  0.3555479545129973\n",
      "average error per step:  0.40245718442570766\n",
      "iteration:  211\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "88\n",
      "average reward\n",
      "0.5700483091787439\n",
      "logistic evaluation:  0.3539838787371877\n",
      "average error per step:  0.40066337734331736\n",
      "iteration:  212\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "344\n",
      "average reward\n",
      "0.5721153846153846\n",
      "logistic evaluation:  0.3532495093353636\n",
      "average error per step:  0.39970535762070103\n",
      "iteration:  213\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "341\n",
      "average reward\n",
      "0.5741626794258373\n",
      "logistic evaluation:  0.35245171850741563\n",
      "average error per step:  0.39868571872179864\n",
      "iteration:  214\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "684\n",
      "average reward\n",
      "0.5761904761904761\n",
      "logistic evaluation:  0.35525692720399527\n",
      "average error per step:  0.4012879891402577\n",
      "iteration:  215\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "169\n",
      "average reward\n",
      "0.5781990521327014\n",
      "logistic evaluation:  0.3536645712903487\n",
      "average error per step:  0.3994741289575418\n",
      "iteration:  216\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "694\n",
      "average reward\n",
      "0.5754716981132075\n",
      "logistic evaluation:  0.35381206351694156\n",
      "average error per step:  0.39941022273302074\n",
      "iteration:  217\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "668\n",
      "average reward\n",
      "0.5774647887323944\n",
      "logistic evaluation:  0.35352940462135896\n",
      "average error per step:  0.3989161314959098\n",
      "iteration:  218\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "240\n",
      "average reward\n",
      "0.5794392523364486\n",
      "logistic evaluation:  0.3558229969457641\n",
      "average error per step:  0.4010120488911858\n",
      "iteration:  219\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "783\n",
      "average reward\n",
      "0.5813953488372093\n",
      "logistic evaluation:  0.3542529309096173\n",
      "average error per step:  0.39922847090078534\n",
      "iteration:  220\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "940\n",
      "average reward\n",
      "0.5787037037037037\n",
      "logistic evaluation:  0.3544528125289178\n",
      "average error per step:  0.39922482680021365\n",
      "iteration:  221\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "550\n",
      "average reward\n",
      "0.5806451612903226\n",
      "logistic evaluation:  0.3542014266677668\n",
      "average error per step:  0.3987697151466082\n",
      "iteration:  222\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "639\n",
      "average reward\n",
      "0.5779816513761468\n",
      "logistic evaluation:  0.3535973592668062\n",
      "average error per step:  0.3979621686651079\n",
      "iteration:  223\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "109\n",
      "average reward\n",
      "0.5753424657534246\n",
      "logistic evaluation:  0.3532273649163619\n",
      "average error per step:  0.3973915698135482\n",
      "iteration:  224\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "679\n",
      "average reward\n",
      "0.5727272727272728\n",
      "logistic evaluation:  0.35260667516151767\n",
      "average error per step:  0.3965709474932931\n",
      "iteration:  225\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "327\n",
      "average reward\n",
      "0.5701357466063348\n",
      "logistic evaluation:  0.353973555231086\n",
      "average error per step:  0.3977485058194738\n",
      "iteration:  226\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "822\n",
      "average reward\n",
      "0.5720720720720721\n",
      "logistic evaluation:  0.3548053671902709\n",
      "average error per step:  0.3983903038909189\n",
      "iteration:  227\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "450\n",
      "average reward\n",
      "0.5739910313901345\n",
      "logistic evaluation:  0.354816856956487\n",
      "average error per step:  0.39820984014641064\n",
      "iteration:  228\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "738\n",
      "average reward\n",
      "0.5714285714285714\n",
      "logistic evaluation:  0.35517689534970054\n",
      "average error per step:  0.3983811375536737\n",
      "iteration:  229\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "521\n",
      "average reward\n",
      "0.5688888888888889\n",
      "logistic evaluation:  0.35571362606157403\n",
      "average error per step:  0.3987315472546646\n",
      "iteration:  230\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "290\n",
      "average reward\n",
      "0.5707964601769911\n",
      "logistic evaluation:  0.3551108900125642\n",
      "average error per step:  0.39793915617416736\n",
      "iteration:  231\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "622\n",
      "average reward\n",
      "0.5682819383259912\n",
      "logistic evaluation:  0.35452517150626267\n",
      "average error per step:  0.3971654983402992\n",
      "iteration:  232\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "675\n",
      "average reward\n",
      "0.5701754385964912\n",
      "logistic evaluation:  0.353089571219707\n",
      "average error per step:  0.3955399156092582\n",
      "iteration:  233\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "211\n",
      "average reward\n",
      "0.5720524017467249\n",
      "logistic evaluation:  0.35162229553781205\n",
      "average error per step:  0.3938841522875716\n",
      "iteration:  234\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "828\n",
      "average reward\n",
      "0.5739130434782609\n",
      "logistic evaluation:  0.350236145465926\n",
      "average error per step:  0.39231147227200336\n",
      "iteration:  235\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "286\n",
      "average reward\n",
      "0.5757575757575758\n",
      "logistic evaluation:  0.3523957303173186\n",
      "average error per step:  0.3943012029023122\n",
      "iteration:  236\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "321\n",
      "average reward\n",
      "0.5775862068965517\n",
      "logistic evaluation:  0.35165393503243236\n",
      "average error per step:  0.39337869885526544\n",
      "iteration:  237\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "583\n",
      "average reward\n",
      "0.5793991416309013\n",
      "logistic evaluation:  0.35129353862483803\n",
      "average error per step:  0.3928407279319309\n",
      "iteration:  238\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "475\n",
      "average reward\n",
      "0.5811965811965812\n",
      "logistic evaluation:  0.3513981393741322\n",
      "average error per step:  0.39277120015787303\n",
      "iteration:  239\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "65\n",
      "average reward\n",
      "0.5829787234042553\n",
      "logistic evaluation:  0.3522005634608622\n",
      "average error per step:  0.3934038726266239\n",
      "iteration:  240\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "433\n",
      "average reward\n",
      "0.5847457627118644\n",
      "logistic evaluation:  0.351945079668432\n",
      "average error per step:  0.39297564386353456\n",
      "iteration:  241\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "237\n",
      "average reward\n",
      "0.5864978902953587\n",
      "logistic evaluation:  0.3525151491815821\n",
      "average error per step:  0.3933778275066351\n",
      "iteration:  242\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "525\n",
      "average reward\n",
      "0.5840336134453782\n",
      "logistic evaluation:  0.3532818634388455\n",
      "average error per step:  0.3939788559619654\n",
      "iteration:  243\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "911\n",
      "average reward\n",
      "0.5857740585774058\n",
      "logistic evaluation:  0.3518889923593538\n",
      "average error per step:  0.3924127755672366\n",
      "iteration:  244\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "160\n",
      "average reward\n",
      "0.5833333333333334\n",
      "logistic evaluation:  0.35145528061404674\n",
      "average error per step:  0.39181120523605584\n",
      "iteration:  245\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "69\n",
      "average reward\n",
      "0.5809128630705395\n",
      "logistic evaluation:  0.3517008265444472\n",
      "average error per step:  0.3918930353350619\n",
      "iteration:  246\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "944\n",
      "average reward\n",
      "0.5826446280991735\n",
      "logistic evaluation:  0.3516458515064312\n",
      "average error per step:  0.3916744538587182\n",
      "iteration:  247\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "172\n",
      "average reward\n",
      "0.5843621399176955\n",
      "logistic evaluation:  0.3502926712472179\n",
      "average error per step:  0.39015373601808184\n",
      "iteration:  248\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "628\n",
      "average reward\n",
      "0.5860655737704918\n",
      "logistic evaluation:  0.3489832027567144\n",
      "average error per step:  0.38867825731281475\n",
      "iteration:  249\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "633\n",
      "average reward\n",
      "0.5877551020408164\n",
      "logistic evaluation:  0.3485925407975017\n",
      "average error per step:  0.3881266085402875\n",
      "iteration:  250\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "181\n",
      "average reward\n",
      "0.5894308943089431\n",
      "logistic evaluation:  0.34803193001437394\n",
      "average error per step:  0.3874056190430561\n",
      "iteration:  251\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "420\n",
      "average reward\n",
      "0.5870445344129555\n",
      "logistic evaluation:  0.3481558844838851\n",
      "average error per step:  0.3873732000681085\n",
      "iteration:  252\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "506\n",
      "average reward\n",
      "0.5846774193548387\n",
      "logistic evaluation:  0.3478769156938338\n",
      "average error per step:  0.3869374999908576\n",
      "iteration:  253\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "535\n",
      "average reward\n",
      "0.5823293172690763\n",
      "logistic evaluation:  0.34718733398413515\n",
      "average error per step:  0.38609080300049997\n",
      "iteration:  254\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "799\n",
      "average reward\n",
      "0.584\n",
      "logistic evaluation:  0.34713189311118176\n",
      "average error per step:  0.3858819805925493\n",
      "iteration:  255\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "604\n",
      "average reward\n",
      "0.5816733067729084\n",
      "logistic evaluation:  0.3472004644618654\n",
      "average error per step:  0.3857988597231126\n",
      "iteration:  256\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "165\n",
      "average reward\n",
      "0.5793650793650794\n",
      "logistic evaluation:  0.34728424644984546\n",
      "average error per step:  0.38573219400299397\n",
      "iteration:  257\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "191\n",
      "average reward\n",
      "0.5810276679841897\n",
      "logistic evaluation:  0.34638093322496144\n",
      "average error per step:  0.38467576303189194\n",
      "iteration:  258\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "608\n",
      "average reward\n",
      "0.5826771653543307\n",
      "logistic evaluation:  0.34570252237506943\n",
      "average error per step:  0.38384629310968665\n",
      "iteration:  259\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "316\n",
      "average reward\n",
      "0.5803921568627451\n",
      "logistic evaluation:  0.3454984204183441\n",
      "average error per step:  0.3834941298684388\n",
      "iteration:  260\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "460\n",
      "average reward\n",
      "0.578125\n",
      "logistic evaluation:  0.34514551129730264\n",
      "average error per step:  0.38299372606058524\n",
      "iteration:  261\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "308\n",
      "average reward\n",
      "0.5797665369649806\n",
      "logistic evaluation:  0.34502654944425176\n",
      "average error per step:  0.38272929609789325\n",
      "iteration:  262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "252\n",
      "average reward\n",
      "0.5775193798449613\n",
      "logistic evaluation:  0.3447079431215305\n",
      "average error per step:  0.38226557010732326\n",
      "iteration:  263\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "181\n",
      "average reward\n",
      "0.5752895752895753\n",
      "logistic evaluation:  0.34483522300319597\n",
      "average error per step:  0.3822505292775662\n",
      "iteration:  264\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "147\n",
      "average reward\n",
      "0.573076923076923\n",
      "logistic evaluation:  0.3445559337697919\n",
      "average error per step:  0.38182845748542055\n",
      "iteration:  265\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "285\n",
      "average reward\n",
      "0.5747126436781609\n",
      "logistic evaluation:  0.3434671546320444\n",
      "average error per step:  0.3805949187142641\n",
      "iteration:  266\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "113\n",
      "average reward\n",
      "0.5725190839694656\n",
      "logistic evaluation:  0.3441434784005213\n",
      "average error per step:  0.3811342069928397\n",
      "iteration:  267\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "672\n",
      "average reward\n",
      "0.5741444866920152\n",
      "logistic evaluation:  0.3428848784771874\n",
      "average error per step:  0.3797323511574621\n",
      "iteration:  268\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "90\n",
      "average reward\n",
      "0.5757575757575758\n",
      "logistic evaluation:  0.34168068800662915\n",
      "average error per step:  0.3783861768691769\n",
      "iteration:  269\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "637\n",
      "average reward\n",
      "0.5773584905660377\n",
      "logistic evaluation:  0.342128526901024\n",
      "average error per step:  0.3786992289607162\n",
      "iteration:  270\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "115\n",
      "average reward\n",
      "0.5789473684210527\n",
      "logistic evaluation:  0.34153312790625756\n",
      "average error per step:  0.37796617773982216\n",
      "iteration:  271\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "701\n",
      "average reward\n",
      "0.5805243445692884\n",
      "logistic evaluation:  0.34117132466433764\n",
      "average error per step:  0.37746860013231\n",
      "iteration:  272\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "202\n",
      "average reward\n",
      "0.582089552238806\n",
      "logistic evaluation:  0.3408901012353398\n",
      "average error per step:  0.3770528969279556\n",
      "iteration:  273\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "587\n",
      "average reward\n",
      "0.5836431226765799\n",
      "logistic evaluation:  0.34141360367558393\n",
      "average error per step:  0.3774458525064695\n",
      "iteration:  274\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "838\n",
      "average reward\n",
      "0.5851851851851851\n",
      "logistic evaluation:  0.3412954719400593\n",
      "average error per step:  0.37719578507544704\n",
      "iteration:  275\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "357\n",
      "average reward\n",
      "0.5830258302583026\n",
      "logistic evaluation:  0.34111792366325233\n",
      "average error per step:  0.37688704457532296\n",
      "iteration:  276\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "424\n",
      "average reward\n",
      "0.5845588235294118\n",
      "logistic evaluation:  0.3402118909422032\n",
      "average error per step:  0.3758481308628495\n",
      "iteration:  277\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "649\n",
      "average reward\n",
      "0.5860805860805861\n",
      "logistic evaluation:  0.34243983840381315\n",
      "average error per step:  0.3779554707704557\n",
      "iteration:  278\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "104\n",
      "average reward\n",
      "0.583941605839416\n",
      "logistic evaluation:  0.34279746476698153\n",
      "average error per step:  0.3781866294861296\n",
      "iteration:  279\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "885\n",
      "average reward\n",
      "0.5818181818181818\n",
      "logistic evaluation:  0.342963697747425\n",
      "average error per step:  0.3782266153994092\n",
      "iteration:  280\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "9\n",
      "average reward\n",
      "0.5833333333333334\n",
      "logistic evaluation:  0.34510312234423635\n",
      "average error per step:  0.3802477418067378\n",
      "iteration:  281\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "163\n",
      "average reward\n",
      "0.5848375451263538\n",
      "logistic evaluation:  0.34455514798971665\n",
      "average error per step:  0.379572747545396\n",
      "iteration:  282\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "326\n",
      "average reward\n",
      "0.5863309352517986\n",
      "logistic evaluation:  0.34494520007243745\n",
      "average error per step:  0.3798400069065815\n",
      "iteration:  283\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "496\n",
      "average reward\n",
      "0.5842293906810035\n",
      "logistic evaluation:  0.3458482361190658\n",
      "average error per step:  0.380622930688943\n",
      "iteration:  284\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "538\n",
      "average reward\n",
      "0.5821428571428572\n",
      "logistic evaluation:  0.34531836050652215\n",
      "average error per step:  0.3799687432095598\n",
      "iteration:  285\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "278\n",
      "average reward\n",
      "0.5836298932384342\n",
      "logistic evaluation:  0.3446537435802213\n",
      "average error per step:  0.37918021400385776\n",
      "iteration:  286\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "481\n",
      "average reward\n",
      "0.5851063829787234\n",
      "logistic evaluation:  0.3443446838551826\n",
      "average error per step:  0.37874935172585167\n",
      "iteration:  287\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "845\n",
      "average reward\n",
      "0.5830388692579506\n",
      "logistic evaluation:  0.3444400352343483\n",
      "average error per step:  0.37872515844825255\n",
      "iteration:  288\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "737\n",
      "average reward\n",
      "0.5809859154929577\n",
      "logistic evaluation:  0.34378650202653616\n",
      "average error per step:  0.3779503104611983\n",
      "iteration:  289\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "221\n",
      "average reward\n",
      "0.5789473684210527\n",
      "logistic evaluation:  0.34388291893056305\n",
      "average error per step:  0.3779288471177144\n",
      "iteration:  290\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "22\n",
      "average reward\n",
      "0.5804195804195804\n",
      "logistic evaluation:  0.34350832060493963\n",
      "average error per step:  0.37743555732135725\n",
      "iteration:  291\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "29\n",
      "average reward\n",
      "0.578397212543554\n",
      "logistic evaluation:  0.34309744476331966\n",
      "average error per step:  0.3769066810929399\n",
      "iteration:  292\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "132\n",
      "average reward\n",
      "0.5798611111111112\n",
      "logistic evaluation:  0.34264313311875827\n",
      "average error per step:  0.3763350285306587\n",
      "iteration:  293\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "225\n",
      "average reward\n",
      "0.5778546712802768\n",
      "logistic evaluation:  0.34306280954100815\n",
      "average error per step:  0.3766411478915105\n",
      "iteration:  294\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "496\n",
      "average reward\n",
      "0.5758620689655173\n",
      "logistic evaluation:  0.3429259968167928\n",
      "average error per step:  0.37638965778268724\n",
      "iteration:  295\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "285\n",
      "average reward\n",
      "0.5738831615120275\n",
      "logistic evaluation:  0.34250309899942605\n",
      "average error per step:  0.3758518902745298\n",
      "iteration:  296\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "126\n",
      "average reward\n",
      "0.5753424657534246\n",
      "logistic evaluation:  0.3414145433344706\n",
      "average error per step:  0.3746469922212633\n",
      "iteration:  297\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "583\n",
      "average reward\n",
      "0.5767918088737202\n",
      "logistic evaluation:  0.3433294831011084\n",
      "average error per step:  0.37645648582924734\n",
      "iteration:  298\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "631\n",
      "average reward\n",
      "0.5782312925170068\n",
      "logistic evaluation:  0.3437566346523959\n",
      "average error per step:  0.3767739063363173\n",
      "iteration:  299\n",
      "estimator:  [ 0.00261652 -0.00298828 -0.01192176]\n",
      "action\n",
      "411\n",
      "average reward\n",
      "0.576271186440678\n",
      "logistic evaluation:  0.34331952893768586\n",
      "average error per step:  0.376224913071779\n",
      "iteration:  300\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "635\n",
      "average reward\n",
      "0.5743243243243243\n",
      "logistic evaluation:  0.3377954091180054\n",
      "average error per step:  0.37689141304242296\n",
      "iteration:  301\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "200\n",
      "average reward\n",
      "0.5757575757575758\n",
      "logistic evaluation:  0.33821599923764856\n",
      "average error per step:  0.3771835134152064\n",
      "iteration:  302\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "657\n",
      "average reward\n",
      "0.5771812080536913\n",
      "logistic evaluation:  0.33842420707892146\n",
      "average error per step:  0.37726337918251807\n",
      "iteration:  303\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "293\n",
      "average reward\n",
      "0.5785953177257525\n",
      "logistic evaluation:  0.3403633384020965\n",
      "average error per step:  0.37908072819288646\n",
      "iteration:  304\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "733\n",
      "average reward\n",
      "0.5766666666666667\n",
      "logistic evaluation:  0.3402265927885882\n",
      "average error per step:  0.378816172923443\n",
      "iteration:  305\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "33\n",
      "average reward\n",
      "0.574750830564784\n",
      "logistic evaluation:  0.34049114838307304\n",
      "average error per step:  0.3789550726997627\n",
      "iteration:  306\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "455\n",
      "average reward\n",
      "0.5761589403973509\n",
      "logistic evaluation:  0.3402196353198825\n",
      "average error per step:  0.37855697323990584\n",
      "iteration:  307\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "156\n",
      "average reward\n",
      "0.5775577557755776\n",
      "logistic evaluation:  0.34053897154504686\n",
      "average error per step:  0.378752472325999\n",
      "iteration:  308\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "929\n",
      "average reward\n",
      "0.5789473684210527\n",
      "logistic evaluation:  0.3400555226790439\n",
      "average error per step:  0.37814338401309033\n",
      "iteration:  309\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "460\n",
      "average reward\n",
      "0.5770491803278689\n",
      "logistic evaluation:  0.3398646878210226\n",
      "average error per step:  0.3778286698793666\n",
      "iteration:  310\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "509\n",
      "average reward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5784313725490197\n",
      "logistic evaluation:  0.34040980670014265\n",
      "average error per step:  0.37825308274823105\n",
      "iteration:  311\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "294\n",
      "average reward\n",
      "0.5765472312703583\n",
      "logistic evaluation:  0.3397822124540298\n",
      "average error per step:  0.3775017879545484\n",
      "iteration:  312\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "775\n",
      "average reward\n",
      "0.577922077922078\n",
      "logistic evaluation:  0.33949840943171783\n",
      "average error per step:  0.3770961792318428\n",
      "iteration:  313\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "564\n",
      "average reward\n",
      "0.5792880258899676\n",
      "logistic evaluation:  0.3395170343599455\n",
      "average error per step:  0.37699474299434554\n",
      "iteration:  314\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "150\n",
      "average reward\n",
      "0.5806451612903226\n",
      "logistic evaluation:  0.33846821552924405\n",
      "average error per step:  0.375823228216303\n",
      "iteration:  315\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "690\n",
      "average reward\n",
      "0.5819935691318328\n",
      "logistic evaluation:  0.3377945263033621\n",
      "average error per step:  0.3750288129526022\n",
      "iteration:  316\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "922\n",
      "average reward\n",
      "0.5801282051282052\n",
      "logistic evaluation:  0.33825070269038787\n",
      "average error per step:  0.3753686029147475\n",
      "iteration:  317\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "33\n",
      "average reward\n",
      "0.5814696485623003\n",
      "logistic evaluation:  0.33852360491954014\n",
      "average error per step:  0.37552527486631243\n",
      "iteration:  318\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "611\n",
      "average reward\n",
      "0.5828025477707006\n",
      "logistic evaluation:  0.3381727450209146\n",
      "average error per step:  0.3750569541820095\n",
      "iteration:  319\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "437\n",
      "average reward\n",
      "0.580952380952381\n",
      "logistic evaluation:  0.33852879352426046\n",
      "average error per step:  0.37529849434473544\n",
      "iteration:  320\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "813\n",
      "average reward\n",
      "0.5822784810126582\n",
      "logistic evaluation:  0.33751136155668277\n",
      "average error per step:  0.3741629775871951\n",
      "iteration:  321\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "979\n",
      "average reward\n",
      "0.583596214511041\n",
      "logistic evaluation:  0.3366639493032653\n",
      "average error per step:  0.373198745931024\n",
      "iteration:  322\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "611\n",
      "average reward\n",
      "0.5849056603773585\n",
      "logistic evaluation:  0.33683355562021533\n",
      "average error per step:  0.37325541687433794\n",
      "iteration:  323\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "161\n",
      "average reward\n",
      "0.5862068965517241\n",
      "logistic evaluation:  0.3384942351475382\n",
      "average error per step:  0.3748084766439927\n",
      "iteration:  324\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "326\n",
      "average reward\n",
      "0.584375\n",
      "logistic evaluation:  0.33803162004143306\n",
      "average error per step:  0.374232352721213\n",
      "iteration:  325\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "716\n",
      "average reward\n",
      "0.5856697819314641\n",
      "logistic evaluation:  0.33969845457890907\n",
      "average error per step:  0.37579292911055884\n",
      "iteration:  326\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "70\n",
      "average reward\n",
      "0.5869565217391305\n",
      "logistic evaluation:  0.3391570021096423\n",
      "average error per step:  0.37513909649711746\n",
      "iteration:  327\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "459\n",
      "average reward\n",
      "0.5882352941176471\n",
      "logistic evaluation:  0.3391298512828079\n",
      "average error per step:  0.3750018256543372\n",
      "iteration:  328\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "138\n",
      "average reward\n",
      "0.5864197530864198\n",
      "logistic evaluation:  0.3390688857829043\n",
      "average error per step:  0.37483130850848406\n",
      "iteration:  329\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "718\n",
      "average reward\n",
      "0.5846153846153846\n",
      "logistic evaluation:  0.33905683418178867\n",
      "average error per step:  0.3747105199033359\n",
      "iteration:  330\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "61\n",
      "average reward\n",
      "0.5858895705521472\n",
      "logistic evaluation:  0.33831225269855575\n",
      "average error per step:  0.3738556406406946\n",
      "iteration:  331\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "27\n",
      "average reward\n",
      "0.5871559633027523\n",
      "logistic evaluation:  0.33802225104283784\n",
      "average error per step:  0.3734573810103608\n",
      "iteration:  332\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "362\n",
      "average reward\n",
      "0.5853658536585366\n",
      "logistic evaluation:  0.33859704255314954\n",
      "average error per step:  0.37392717150122307\n",
      "iteration:  333\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "555\n",
      "average reward\n",
      "0.5866261398176292\n",
      "logistic evaluation:  0.33760649066656334\n",
      "average error per step:  0.3728275485010193\n",
      "iteration:  334\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "721\n",
      "average reward\n",
      "0.5878787878787879\n",
      "logistic evaluation:  0.33668255520495627\n",
      "average error per step:  0.3717953944966096\n",
      "iteration:  335\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "217\n",
      "average reward\n",
      "0.5861027190332326\n",
      "logistic evaluation:  0.33638589529834195\n",
      "average error per step:  0.3713930345923886\n",
      "iteration:  336\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "550\n",
      "average reward\n",
      "0.5843373493975904\n",
      "logistic evaluation:  0.33608460217918634\n",
      "average error per step:  0.3709866568529555\n",
      "iteration:  337\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "576\n",
      "average reward\n",
      "0.5855855855855856\n",
      "logistic evaluation:  0.3357326199485079\n",
      "average error per step:  0.37053006323680393\n",
      "iteration:  338\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "555\n",
      "average reward\n",
      "0.5868263473053892\n",
      "logistic evaluation:  0.3356735771423348\n",
      "average error per step:  0.37036789473212656\n",
      "iteration:  339\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "328\n",
      "average reward\n",
      "0.5880597014925373\n",
      "logistic evaluation:  0.3354480327105927\n",
      "average error per step:  0.370039341857843\n",
      "iteration:  340\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "665\n",
      "average reward\n",
      "0.5892857142857143\n",
      "logistic evaluation:  0.3348135377550925\n",
      "average error per step:  0.36930124159615824\n",
      "iteration:  341\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "735\n",
      "average reward\n",
      "0.5905044510385756\n",
      "logistic evaluation:  0.3341072616337927\n",
      "average error per step:  0.36849175732247613\n",
      "iteration:  342\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "856\n",
      "average reward\n",
      "0.591715976331361\n",
      "logistic evaluation:  0.3341999007432735\n",
      "average error per step:  0.3684841278454681\n",
      "iteration:  343\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "218\n",
      "average reward\n",
      "0.5929203539823009\n",
      "logistic evaluation:  0.3345804439077313\n",
      "average error per step:  0.3687658264503406\n",
      "iteration:  344\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "91\n",
      "average reward\n",
      "0.5941176470588235\n",
      "logistic evaluation:  0.3342323509896693\n",
      "average error per step:  0.3683173455222185\n",
      "iteration:  345\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "746\n",
      "average reward\n",
      "0.5953079178885631\n",
      "logistic evaluation:  0.3333478865102134\n",
      "average error per step:  0.36733152029200317\n",
      "iteration:  346\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "262\n",
      "average reward\n",
      "0.5964912280701754\n",
      "logistic evaluation:  0.33494990284883785\n",
      "average error per step:  0.36883994814090754\n",
      "iteration:  347\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "246\n",
      "average reward\n",
      "0.597667638483965\n",
      "logistic evaluation:  0.3344632480808879\n",
      "average error per step:  0.36825422507307276\n",
      "iteration:  348\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "654\n",
      "average reward\n",
      "0.5988372093023255\n",
      "logistic evaluation:  0.3349686872947365\n",
      "average error per step:  0.3686640161898572\n",
      "iteration:  349\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "717\n",
      "average reward\n",
      "0.6\n",
      "logistic evaluation:  0.3340466512761112\n",
      "average error per step:  0.3676427900138859\n",
      "iteration:  350\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "187\n",
      "average reward\n",
      "0.6011560693641619\n",
      "logistic evaluation:  0.3331231376806104\n",
      "average error per step:  0.36662064884029005\n",
      "iteration:  351\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "265\n",
      "average reward\n",
      "0.5994236311239193\n",
      "logistic evaluation:  0.3325953767313439\n",
      "average error per step:  0.365995949793847\n",
      "iteration:  352\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "368\n",
      "average reward\n",
      "0.6005747126436781\n",
      "logistic evaluation:  0.33230933849666533\n",
      "average error per step:  0.3656142109588924\n",
      "iteration:  353\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "298\n",
      "average reward\n",
      "0.6017191977077364\n",
      "logistic evaluation:  0.33238107235818026\n",
      "average error per step:  0.36559179995185015\n",
      "iteration:  354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "793\n",
      "average reward\n",
      "0.6028571428571429\n",
      "logistic evaluation:  0.3314916724617547\n",
      "average error per step:  0.3646060720116672\n",
      "iteration:  355\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "275\n",
      "average reward\n",
      "0.603988603988604\n",
      "logistic evaluation:  0.3308255145550053\n",
      "average error per step:  0.3638447576050399\n",
      "iteration:  356\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "815\n",
      "average reward\n",
      "0.6051136363636364\n",
      "logistic evaluation:  0.3299378661898628\n",
      "average error per step:  0.3628618651628886\n",
      "iteration:  357\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "684\n",
      "average reward\n",
      "0.6062322946175638\n",
      "logistic evaluation:  0.3300852872364452\n",
      "average error per step:  0.3629174750668199\n",
      "iteration:  358\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "838\n",
      "average reward\n",
      "0.6073446327683616\n",
      "logistic evaluation:  0.3318386417916556\n",
      "average error per step:  0.36458401723858\n",
      "iteration:  359\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "81\n",
      "average reward\n",
      "0.6084507042253521\n",
      "logistic evaluation:  0.3317357732374325\n",
      "average error per step:  0.36438964939744567\n",
      "iteration:  360\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "903\n",
      "average reward\n",
      "0.6095505617977528\n",
      "logistic evaluation:  0.3333316450555197\n",
      "average error per step:  0.36589924898124976\n",
      "iteration:  361\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "292\n",
      "average reward\n",
      "0.6106442577030813\n",
      "logistic evaluation:  0.3335538238413857\n",
      "average error per step:  0.36603182825149283\n",
      "iteration:  362\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "786\n",
      "average reward\n",
      "0.611731843575419\n",
      "logistic evaluation:  0.33273503209487904\n",
      "average error per step:  0.365121056405106\n",
      "iteration:  363\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "216\n",
      "average reward\n",
      "0.6100278551532033\n",
      "logistic evaluation:  0.3327379183996339\n",
      "average error per step:  0.3650347329632893\n",
      "iteration:  364\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "438\n",
      "average reward\n",
      "0.6111111111111112\n",
      "logistic evaluation:  0.33183798276106374\n",
      "average error per step:  0.36404359746152615\n",
      "iteration:  365\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "721\n",
      "average reward\n",
      "0.6094182825484764\n",
      "logistic evaluation:  0.3325466060685002\n",
      "average error per step:  0.3646659276418585\n",
      "iteration:  366\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "827\n",
      "average reward\n",
      "0.6104972375690608\n",
      "logistic evaluation:  0.33175824540358173\n",
      "average error per step:  0.36378765527683543\n",
      "iteration:  367\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "107\n",
      "average reward\n",
      "0.6088154269972452\n",
      "logistic evaluation:  0.3318040252565915\n",
      "average error per step:  0.36374628627420413\n",
      "iteration:  368\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "276\n",
      "average reward\n",
      "0.6098901098901099\n",
      "logistic evaluation:  0.3316909952419978\n",
      "average error per step:  0.36354614949050124\n",
      "iteration:  369\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "973\n",
      "average reward\n",
      "0.6109589041095891\n",
      "logistic evaluation:  0.3312631310620668\n",
      "average error per step:  0.36303079745575056\n",
      "iteration:  370\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "539\n",
      "average reward\n",
      "0.6120218579234973\n",
      "logistic evaluation:  0.3328648826434889\n",
      "average error per step:  0.36455101953768015\n",
      "iteration:  371\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "515\n",
      "average reward\n",
      "0.6103542234332425\n",
      "logistic evaluation:  0.3328589263321121\n",
      "average error per step:  0.3644596397944824\n",
      "iteration:  372\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "682\n",
      "average reward\n",
      "0.6114130434782609\n",
      "logistic evaluation:  0.3324553748917885\n",
      "average error per step:  0.3639700553839903\n",
      "iteration:  373\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "642\n",
      "average reward\n",
      "0.6097560975609756\n",
      "logistic evaluation:  0.33214978964987174\n",
      "average error per step:  0.3635791611186576\n",
      "iteration:  374\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "315\n",
      "average reward\n",
      "0.6108108108108108\n",
      "logistic evaluation:  0.3325719952159846\n",
      "average error per step:  0.3639184598240681\n",
      "iteration:  375\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "359\n",
      "average reward\n",
      "0.6091644204851752\n",
      "logistic evaluation:  0.33235191886523285\n",
      "average error per step:  0.36361420603075945\n",
      "iteration:  376\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "250\n",
      "average reward\n",
      "0.6102150537634409\n",
      "logistic evaluation:  0.33191323505060233\n",
      "average error per step:  0.36309121112309656\n",
      "iteration:  377\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "517\n",
      "average reward\n",
      "0.6085790884718498\n",
      "logistic evaluation:  0.332410143352502\n",
      "average error per step:  0.36350673728236865\n",
      "iteration:  378\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "334\n",
      "average reward\n",
      "0.606951871657754\n",
      "logistic evaluation:  0.33202341393890517\n",
      "average error per step:  0.3630367186535775\n",
      "iteration:  379\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "802\n",
      "average reward\n",
      "0.608\n",
      "logistic evaluation:  0.33143448259412733\n",
      "average error per step:  0.3623644041001995\n",
      "iteration:  380\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "327\n",
      "average reward\n",
      "0.6090425531914894\n",
      "logistic evaluation:  0.3306323662156619\n",
      "average error per step:  0.36147878235888004\n",
      "iteration:  381\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "171\n",
      "average reward\n",
      "0.610079575596817\n",
      "logistic evaluation:  0.3309027631136357\n",
      "average error per step:  0.3616689272378374\n",
      "iteration:  382\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "938\n",
      "average reward\n",
      "0.6111111111111112\n",
      "logistic evaluation:  0.3302266528568441\n",
      "average error per step:  0.3609105073622474\n",
      "iteration:  383\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "795\n",
      "average reward\n",
      "0.6121372031662269\n",
      "logistic evaluation:  0.3303527442079922\n",
      "average error per step:  0.3609568134310084\n",
      "iteration:  384\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "179\n",
      "average reward\n",
      "0.6131578947368421\n",
      "logistic evaluation:  0.32954946475106495\n",
      "average error per step:  0.3600717440035604\n",
      "iteration:  385\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "426\n",
      "average reward\n",
      "0.6141732283464567\n",
      "logistic evaluation:  0.32883161613268475\n",
      "average error per step:  0.3592727521959052\n",
      "iteration:  386\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "297\n",
      "average reward\n",
      "0.6151832460732984\n",
      "logistic evaluation:  0.3283094313113617\n",
      "average error per step:  0.3586703515173683\n",
      "iteration:  387\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "642\n",
      "average reward\n",
      "0.6161879895561357\n",
      "logistic evaluation:  0.3285544739081698\n",
      "average error per step:  0.3588375753089847\n",
      "iteration:  388\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "186\n",
      "average reward\n",
      "0.6171875\n",
      "logistic evaluation:  0.328173824589765\n",
      "average error per step:  0.35837789570522116\n",
      "iteration:  389\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "567\n",
      "average reward\n",
      "0.6181818181818182\n",
      "logistic evaluation:  0.3277290975798272\n",
      "average error per step:  0.35785438001115644\n",
      "iteration:  390\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "631\n",
      "average reward\n",
      "0.616580310880829\n",
      "logistic evaluation:  0.3277367423199251\n",
      "average error per step:  0.3577848000392255\n",
      "iteration:  391\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "983\n",
      "average reward\n",
      "0.6175710594315246\n",
      "logistic evaluation:  0.3277560507457201\n",
      "average error per step:  0.3577273085947047\n",
      "iteration:  392\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "229\n",
      "average reward\n",
      "0.615979381443299\n",
      "logistic evaluation:  0.3276764478255598\n",
      "average error per step:  0.3575710453154394\n",
      "iteration:  393\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "646\n",
      "average reward\n",
      "0.6169665809768637\n",
      "logistic evaluation:  0.3277825625251487\n",
      "average error per step:  0.3576013623488952\n",
      "iteration:  394\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "49\n",
      "average reward\n",
      "0.617948717948718\n",
      "logistic evaluation:  0.32760487609711303\n",
      "average error per step:  0.3573475427070225\n",
      "iteration:  395\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "503\n",
      "average reward\n",
      "0.618925831202046\n",
      "logistic evaluation:  0.3273462985877619\n",
      "average error per step:  0.3570130126809138\n",
      "iteration:  396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "674\n",
      "average reward\n",
      "0.6198979591836735\n",
      "logistic evaluation:  0.32690125209810034\n",
      "average error per step:  0.35649192639180066\n",
      "iteration:  397\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "457\n",
      "average reward\n",
      "0.6208651399491094\n",
      "logistic evaluation:  0.3267810195281421\n",
      "average error per step:  0.3562968552655108\n",
      "iteration:  398\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "437\n",
      "average reward\n",
      "0.6218274111675127\n",
      "logistic evaluation:  0.32809863550608975\n",
      "average error per step:  0.35754362144506796\n",
      "iteration:  399\n",
      "estimator:  [ 0.00345074 -0.00430667 -0.01189801]\n",
      "action\n",
      "284\n",
      "average reward\n",
      "0.6227848101265823\n",
      "logistic evaluation:  0.3281392496800023\n",
      "average error per step:  0.3575105404516495\n",
      "iteration:  400\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "69\n",
      "average reward\n",
      "0.6237373737373737\n",
      "logistic evaluation:  0.3265272082347744\n",
      "average error per step:  0.35664805371747826\n",
      "iteration:  401\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "875\n",
      "average reward\n",
      "0.6221662468513854\n",
      "logistic evaluation:  0.3262441766977738\n",
      "average error per step:  0.35628920203828385\n",
      "iteration:  402\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "307\n",
      "average reward\n",
      "0.6231155778894473\n",
      "logistic evaluation:  0.3265066757578712\n",
      "average error per step:  0.3564776152121116\n",
      "iteration:  403\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "645\n",
      "average reward\n",
      "0.6240601503759399\n",
      "logistic evaluation:  0.3263514289331958\n",
      "average error per step:  0.35624761358277385\n",
      "iteration:  404\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "57\n",
      "average reward\n",
      "0.625\n",
      "logistic evaluation:  0.32560726167687615\n",
      "average error per step:  0.3554276038712416\n",
      "iteration:  405\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "436\n",
      "average reward\n",
      "0.6259351620947631\n",
      "logistic evaluation:  0.3255376995151749\n",
      "average error per step:  0.3552842394765624\n",
      "iteration:  406\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "531\n",
      "average reward\n",
      "0.6268656716417911\n",
      "logistic evaluation:  0.32476073169697184\n",
      "average error per step:  0.3544320906047151\n",
      "iteration:  407\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "818\n",
      "average reward\n",
      "0.6277915632754343\n",
      "logistic evaluation:  0.325398231196465\n",
      "average error per step:  0.35499825384030587\n",
      "iteration:  408\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "429\n",
      "average reward\n",
      "0.6262376237623762\n",
      "logistic evaluation:  0.32574786217093277\n",
      "average error per step:  0.3552761926783291\n",
      "iteration:  409\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "421\n",
      "average reward\n",
      "0.6271604938271605\n",
      "logistic evaluation:  0.32585560176158773\n",
      "average error per step:  0.3553119992838576\n",
      "iteration:  410\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "563\n",
      "average reward\n",
      "0.6280788177339901\n",
      "logistic evaluation:  0.3252457310752533\n",
      "average error per step:  0.3546287962360387\n",
      "iteration:  411\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "161\n",
      "average reward\n",
      "0.6265356265356266\n",
      "logistic evaluation:  0.32580171889874004\n",
      "average error per step:  0.35511464518522545\n",
      "iteration:  412\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "399\n",
      "average reward\n",
      "0.625\n",
      "logistic evaluation:  0.3254434816523383\n",
      "average error per step:  0.35468439055160794\n",
      "iteration:  413\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "634\n",
      "average reward\n",
      "0.6234718826405868\n",
      "logistic evaluation:  0.32589637473126765\n",
      "average error per step:  0.3550675789917472\n",
      "iteration:  414\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "158\n",
      "average reward\n",
      "0.6219512195121951\n",
      "logistic evaluation:  0.32593872595796\n",
      "average error per step:  0.35503957067004865\n",
      "iteration:  415\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "415\n",
      "average reward\n",
      "0.6228710462287105\n",
      "logistic evaluation:  0.32605591649084936\n",
      "average error per step:  0.3550869210723858\n",
      "iteration:  416\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "785\n",
      "average reward\n",
      "0.6237864077669902\n",
      "logistic evaluation:  0.3272413925371263\n",
      "average error per step:  0.35620546075199144\n",
      "iteration:  417\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "2\n",
      "average reward\n",
      "0.6246973365617433\n",
      "logistic evaluation:  0.32703997343975966\n",
      "average error per step:  0.35593410043804874\n",
      "iteration:  418\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "450\n",
      "average reward\n",
      "0.6231884057971014\n",
      "logistic evaluation:  0.32715884314466387\n",
      "average error per step:  0.35598412981449984\n",
      "iteration:  419\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "222\n",
      "average reward\n",
      "0.6240963855421687\n",
      "logistic evaluation:  0.32700171477617235\n",
      "average error per step:  0.3557578310043894\n",
      "iteration:  420\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "692\n",
      "average reward\n",
      "0.625\n",
      "logistic evaluation:  0.32725353916959177\n",
      "average error per step:  0.3559417880362974\n",
      "iteration:  421\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "794\n",
      "average reward\n",
      "0.6235011990407674\n",
      "logistic evaluation:  0.32705243838762665\n",
      "average error per step:  0.3556720664713188\n",
      "iteration:  422\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "213\n",
      "average reward\n",
      "0.6244019138755981\n",
      "logistic evaluation:  0.326876202505092\n",
      "average error per step:  0.3554275939443144\n",
      "iteration:  423\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "608\n",
      "average reward\n",
      "0.6252983293556086\n",
      "logistic evaluation:  0.3267001635955346\n",
      "average error per step:  0.35518364148783316\n",
      "iteration:  424\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "415\n",
      "average reward\n",
      "0.6261904761904762\n",
      "logistic evaluation:  0.3281927496236346\n",
      "average error per step:  0.35661256975210254\n",
      "iteration:  425\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "859\n",
      "average reward\n",
      "0.6247030878859857\n",
      "logistic evaluation:  0.3283113053288128\n",
      "average error per step:  0.356664534246873\n",
      "iteration:  426\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "135\n",
      "average reward\n",
      "0.6232227488151659\n",
      "logistic evaluation:  0.3286149098115958\n",
      "average error per step:  0.3569022945408408\n",
      "iteration:  427\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "360\n",
      "average reward\n",
      "0.624113475177305\n",
      "logistic evaluation:  0.32823233282535447\n",
      "average error per step:  0.3564525747871159\n",
      "iteration:  428\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "11\n",
      "average reward\n",
      "0.625\n",
      "logistic evaluation:  0.3279814483027062\n",
      "average error per step:  0.3561351689409059\n",
      "iteration:  429\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "611\n",
      "average reward\n",
      "0.6235294117647059\n",
      "logistic evaluation:  0.32765063177499193\n",
      "average error per step:  0.3557379548906604\n",
      "iteration:  430\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "413\n",
      "average reward\n",
      "0.6244131455399061\n",
      "logistic evaluation:  0.32771144850493267\n",
      "average error per step:  0.35573359369877383\n",
      "iteration:  431\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "14\n",
      "average reward\n",
      "0.6252927400468384\n",
      "logistic evaluation:  0.32808359303188467\n",
      "average error per step:  0.35604158509192796\n",
      "iteration:  432\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "774\n",
      "average reward\n",
      "0.6261682242990654\n",
      "logistic evaluation:  0.3274878947726482\n",
      "average error per step:  0.3553797903273228\n",
      "iteration:  433\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "705\n",
      "average reward\n",
      "0.627039627039627\n",
      "logistic evaluation:  0.3274661912298146\n",
      "average error per step:  0.3552936211976589\n",
      "iteration:  434\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "374\n",
      "average reward\n",
      "0.627906976744186\n",
      "logistic evaluation:  0.32715792546281\n",
      "average error per step:  0.3549205266386385\n",
      "iteration:  435\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "45\n",
      "average reward\n",
      "0.6264501160092807\n",
      "logistic evaluation:  0.3269437433599459\n",
      "average error per step:  0.3546420300914556\n",
      "iteration:  436\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "185\n",
      "average reward\n",
      "0.6273148148148148\n",
      "logistic evaluation:  0.32664649876817353\n",
      "average error per step:  0.3542805755654555\n",
      "iteration:  437\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "407\n",
      "average reward\n",
      "0.628175519630485\n",
      "logistic evaluation:  0.3264605245653221\n",
      "average error per step:  0.35403093991866785\n",
      "iteration:  438\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "41\n",
      "average reward\n",
      "0.6267281105990783\n",
      "logistic evaluation:  0.3261223618045294\n",
      "average error per step:  0.35362905894300267\n",
      "iteration:  439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "141\n",
      "average reward\n",
      "0.6275862068965518\n",
      "logistic evaluation:  0.32661172824754686\n",
      "average error per step:  0.35405688249149747\n",
      "iteration:  440\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "542\n",
      "average reward\n",
      "0.6284403669724771\n",
      "logistic evaluation:  0.32617721061860055\n",
      "average error per step:  0.3535590019719309\n",
      "iteration:  441\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "448\n",
      "average reward\n",
      "0.6292906178489702\n",
      "logistic evaluation:  0.32641575093794456\n",
      "average error per step:  0.3537359929692024\n",
      "iteration:  442\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "976\n",
      "average reward\n",
      "0.6301369863013698\n",
      "logistic evaluation:  0.3257123471904313\n",
      "average error per step:  0.3529691873081625\n",
      "iteration:  443\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "303\n",
      "average reward\n",
      "0.6309794988610479\n",
      "logistic evaluation:  0.3259510776432234\n",
      "average error per step:  0.3531469288000857\n",
      "iteration:  444\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "993\n",
      "average reward\n",
      "0.6318181818181818\n",
      "logistic evaluation:  0.3255581711781459\n",
      "average error per step:  0.3526918854935173\n",
      "iteration:  445\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "214\n",
      "average reward\n",
      "0.6326530612244898\n",
      "logistic evaluation:  0.32558488163764326\n",
      "average error per step:  0.3526576813376082\n",
      "iteration:  446\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "590\n",
      "average reward\n",
      "0.6334841628959276\n",
      "logistic evaluation:  0.32532240102597804\n",
      "average error per step:  0.35233391085977345\n",
      "iteration:  447\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "815\n",
      "average reward\n",
      "0.6343115124153499\n",
      "logistic evaluation:  0.3248299813628187\n",
      "average error per step:  0.35177996115299676\n",
      "iteration:  448\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "447\n",
      "average reward\n",
      "0.6351351351351351\n",
      "logistic evaluation:  0.3252731057588909\n",
      "average error per step:  0.35216391846113565\n",
      "iteration:  449\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "984\n",
      "average reward\n",
      "0.6359550561797753\n",
      "logistic evaluation:  0.3256293207254372\n",
      "average error per step:  0.35246103632804787\n",
      "iteration:  450\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "572\n",
      "average reward\n",
      "0.6345291479820628\n",
      "logistic evaluation:  0.325306061268204\n",
      "average error per step:  0.35207743248179285\n",
      "iteration:  451\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "121\n",
      "average reward\n",
      "0.6353467561521253\n",
      "logistic evaluation:  0.3255687542677325\n",
      "average error per step:  0.35228134792430565\n",
      "iteration:  452\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "442\n",
      "average reward\n",
      "0.6361607142857143\n",
      "logistic evaluation:  0.32548803371699303\n",
      "average error per step:  0.3521413501297447\n",
      "iteration:  453\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "411\n",
      "average reward\n",
      "0.6369710467706013\n",
      "logistic evaluation:  0.3267282558254833\n",
      "average error per step:  0.35332547269230946\n",
      "iteration:  454\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "452\n",
      "average reward\n",
      "0.6377777777777778\n",
      "logistic evaluation:  0.3268249281738573\n",
      "average error per step:  0.3533637737972507\n",
      "iteration:  455\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "735\n",
      "average reward\n",
      "0.6385809312638581\n",
      "logistic evaluation:  0.3268695817243323\n",
      "average error per step:  0.3533501983541589\n",
      "iteration:  456\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "506\n",
      "average reward\n",
      "0.6371681415929203\n",
      "logistic evaluation:  0.3271198466772127\n",
      "average error per step:  0.3535429406059934\n",
      "iteration:  457\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "703\n",
      "average reward\n",
      "0.6357615894039735\n",
      "logistic evaluation:  0.3272062525955099\n",
      "average error per step:  0.3535717170100444\n",
      "iteration:  458\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "370\n",
      "average reward\n",
      "0.6343612334801763\n",
      "logistic evaluation:  0.3271370048140313\n",
      "average error per step:  0.35344475151634747\n",
      "iteration:  459\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "584\n",
      "average reward\n",
      "0.6351648351648351\n",
      "logistic evaluation:  0.3268145910494703\n",
      "average error per step:  0.35306431997299154\n",
      "iteration:  460\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "3\n",
      "average reward\n",
      "0.6337719298245614\n",
      "logistic evaluation:  0.32644320163275214\n",
      "average error per step:  0.3526350585598816\n",
      "iteration:  461\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "429\n",
      "average reward\n",
      "0.6323851203501094\n",
      "logistic evaluation:  0.32624089445716625\n",
      "average error per step:  0.35237549723222905\n",
      "iteration:  462\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "446\n",
      "average reward\n",
      "0.6331877729257642\n",
      "logistic evaluation:  0.3265364794049398\n",
      "average error per step:  0.3526151535699868\n",
      "iteration:  463\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "758\n",
      "average reward\n",
      "0.6339869281045751\n",
      "logistic evaluation:  0.3260663232495529\n",
      "average error per step:  0.35208765652837865\n",
      "iteration:  464\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "895\n",
      "average reward\n",
      "0.6347826086956522\n",
      "logistic evaluation:  0.32636040899436874\n",
      "average error per step:  0.3523262956190264\n",
      "iteration:  465\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "956\n",
      "average reward\n",
      "0.6334056399132321\n",
      "logistic evaluation:  0.32633732078500227\n",
      "average error per step:  0.35224731714119967\n",
      "iteration:  466\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "368\n",
      "average reward\n",
      "0.6320346320346321\n",
      "logistic evaluation:  0.32593084303554953\n",
      "average error per step:  0.3517843662713485\n",
      "iteration:  467\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "742\n",
      "average reward\n",
      "0.6306695464362851\n",
      "logistic evaluation:  0.3261130093946213\n",
      "average error per step:  0.35191156184481703\n",
      "iteration:  468\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "649\n",
      "average reward\n",
      "0.6293103448275862\n",
      "logistic evaluation:  0.3265108560199248\n",
      "average error per step:  0.3522551334576741\n",
      "iteration:  469\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "593\n",
      "average reward\n",
      "0.6279569892473118\n",
      "logistic evaluation:  0.32675830393484323\n",
      "average error per step:  0.3524482171305396\n",
      "iteration:  470\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "94\n",
      "average reward\n",
      "0.628755364806867\n",
      "logistic evaluation:  0.3262138824054947\n",
      "average error per step:  0.35184797786773353\n",
      "iteration:  471\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "872\n",
      "average reward\n",
      "0.6295503211991434\n",
      "logistic evaluation:  0.3272452948339093\n",
      "average error per step:  0.3528271553003226\n",
      "iteration:  472\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "971\n",
      "average reward\n",
      "0.6303418803418803\n",
      "logistic evaluation:  0.32857963411009644\n",
      "average error per step:  0.35411012270958137\n",
      "iteration:  473\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "211\n",
      "average reward\n",
      "0.6289978678038379\n",
      "logistic evaluation:  0.32878429410333265\n",
      "average error per step:  0.3542612397247916\n",
      "iteration:  474\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "483\n",
      "average reward\n",
      "0.6276595744680851\n",
      "logistic evaluation:  0.32873705018823707\n",
      "average error per step:  0.3541601473085641\n",
      "iteration:  475\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "559\n",
      "average reward\n",
      "0.6263269639065817\n",
      "logistic evaluation:  0.32879284693609495\n",
      "average error per step:  0.3541625392135326\n",
      "iteration:  476\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "403\n",
      "average reward\n",
      "0.6271186440677966\n",
      "logistic evaluation:  0.328685401008606\n",
      "average error per step:  0.3540015698864534\n",
      "iteration:  477\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "687\n",
      "average reward\n",
      "0.6257928118393234\n",
      "logistic evaluation:  0.32853921672930636\n",
      "average error per step:  0.3538020054118558\n",
      "iteration:  478\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "677\n",
      "average reward\n",
      "0.6265822784810127\n",
      "logistic evaluation:  0.3297801911729498\n",
      "average error per step:  0.35499272501399526\n",
      "iteration:  479\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "129\n",
      "average reward\n",
      "0.6252631578947369\n",
      "logistic evaluation:  0.3303669758930958\n",
      "average error per step:  0.3555280989844108\n",
      "iteration:  480\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "823\n",
      "average reward\n",
      "0.6260504201680672\n",
      "logistic evaluation:  0.33064231936570126\n",
      "average error per step:  0.35575159708281057\n",
      "iteration:  481\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "764\n",
      "average reward\n",
      "0.6268343815513627\n",
      "logistic evaluation:  0.3306701267326028\n",
      "average error per step:  0.35572726002070965\n",
      "iteration:  482\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "452\n",
      "average reward\n",
      "0.6255230125523012\n",
      "logistic evaluation:  0.3305163378620204\n",
      "average error per step:  0.3555211663323706\n",
      "iteration:  483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "42\n",
      "average reward\n",
      "0.6263048016701461\n",
      "logistic evaluation:  0.3300081978649775\n",
      "average error per step:  0.3549602044544428\n",
      "iteration:  484\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "368\n",
      "average reward\n",
      "0.625\n",
      "logistic evaluation:  0.32981484948809636\n",
      "average error per step:  0.3547149028648213\n",
      "iteration:  485\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "55\n",
      "average reward\n",
      "0.6257796257796258\n",
      "logistic evaluation:  0.32916263277922214\n",
      "average error per step:  0.3540100010629871\n",
      "iteration:  486\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "349\n",
      "average reward\n",
      "0.6244813278008299\n",
      "logistic evaluation:  0.32882921932695813\n",
      "average error per step:  0.35362477530262426\n",
      "iteration:  487\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "199\n",
      "average reward\n",
      "0.6252587991718427\n",
      "logistic evaluation:  0.3291470343129446\n",
      "average error per step:  0.35389232798678383\n",
      "iteration:  488\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "741\n",
      "average reward\n",
      "0.6239669421487604\n",
      "logistic evaluation:  0.32901244943646724\n",
      "average error per step:  0.3537067597526214\n",
      "iteration:  489\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "786\n",
      "average reward\n",
      "0.6247422680412371\n",
      "logistic evaluation:  0.3285860819006414\n",
      "average error per step:  0.35322902068744594\n",
      "iteration:  490\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "457\n",
      "average reward\n",
      "0.6255144032921811\n",
      "logistic evaluation:  0.3285238666513219\n",
      "average error per step:  0.35311638675642\n",
      "iteration:  491\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "418\n",
      "average reward\n",
      "0.6262833675564682\n",
      "logistic evaluation:  0.3283957270770832\n",
      "average error per step:  0.3529378996064597\n",
      "iteration:  492\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "212\n",
      "average reward\n",
      "0.625\n",
      "logistic evaluation:  0.32839668767880686\n",
      "average error per step:  0.35288897969613525\n",
      "iteration:  493\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "859\n",
      "average reward\n",
      "0.623721881390593\n",
      "logistic evaluation:  0.328490706227129\n",
      "average error per step:  0.35293350884594016\n",
      "iteration:  494\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "746\n",
      "average reward\n",
      "0.6224489795918368\n",
      "logistic evaluation:  0.3282169434345131\n",
      "average error per step:  0.3526097125201027\n",
      "iteration:  495\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "248\n",
      "average reward\n",
      "0.6211812627291242\n",
      "logistic evaluation:  0.32855412782712995\n",
      "average error per step:  0.35289829977192566\n",
      "iteration:  496\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "449\n",
      "average reward\n",
      "0.6199186991869918\n",
      "logistic evaluation:  0.3289298946461222\n",
      "average error per step:  0.35322574319348693\n",
      "iteration:  497\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "575\n",
      "average reward\n",
      "0.6206896551724138\n",
      "logistic evaluation:  0.32855468359449935\n",
      "average error per step:  0.35280089218291233\n",
      "iteration:  498\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "916\n",
      "average reward\n",
      "0.6214574898785425\n",
      "logistic evaluation:  0.32813266234390903\n",
      "average error per step:  0.3523293363342518\n",
      "iteration:  499\n",
      "estimator:  [ 0.00377509 -0.00472776 -0.01170844]\n",
      "action\n",
      "310\n",
      "average reward\n",
      "0.6222222222222222\n",
      "logistic evaluation:  0.32798530313450946\n",
      "average error per step:  0.35213319148717737\n",
      "iteration:  500\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "664\n",
      "average reward\n",
      "0.6229838709677419\n",
      "logistic evaluation:  0.3204484921908075\n",
      "average error per step:  0.3521085860061606\n",
      "iteration:  501\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "308\n",
      "average reward\n",
      "0.6237424547283702\n",
      "logistic evaluation:  0.32003800701241886\n",
      "average error per step:  0.35163408769604787\n",
      "iteration:  502\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "558\n",
      "average reward\n",
      "0.6244979919678715\n",
      "logistic evaluation:  0.3203506451761422\n",
      "average error per step:  0.35188440824518974\n",
      "iteration:  503\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "866\n",
      "average reward\n",
      "0.625250501002004\n",
      "logistic evaluation:  0.31983125987171884\n",
      "average error per step:  0.3513012989877376\n",
      "iteration:  504\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "410\n",
      "average reward\n",
      "0.624\n",
      "logistic evaluation:  0.3197393114482924\n",
      "average error per step:  0.35114672757316145\n",
      "iteration:  505\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "944\n",
      "average reward\n",
      "0.6227544910179641\n",
      "logistic evaluation:  0.3194971217498409\n",
      "average error per step:  0.3508418653879311\n",
      "iteration:  506\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "224\n",
      "average reward\n",
      "0.6235059760956175\n",
      "logistic evaluation:  0.31967258366621804\n",
      "average error per step:  0.35095572793331675\n",
      "iteration:  507\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "348\n",
      "average reward\n",
      "0.6222664015904572\n",
      "logistic evaluation:  0.3199343194985796\n",
      "average error per step:  0.35115627755574785\n",
      "iteration:  508\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "919\n",
      "average reward\n",
      "0.623015873015873\n",
      "logistic evaluation:  0.31976189473825967\n",
      "average error per step:  0.35092205282925176\n",
      "iteration:  509\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "855\n",
      "average reward\n",
      "0.6237623762376238\n",
      "logistic evaluation:  0.3198562045879039\n",
      "average error per step:  0.3509553295782254\n",
      "iteration:  510\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "223\n",
      "average reward\n",
      "0.6245059288537549\n",
      "logistic evaluation:  0.3201623271585918\n",
      "average error per step:  0.35120107371279635\n",
      "iteration:  511\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "612\n",
      "average reward\n",
      "0.6252465483234714\n",
      "logistic evaluation:  0.3200519410583466\n",
      "average error per step:  0.351029730405791\n",
      "iteration:  512\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "998\n",
      "average reward\n",
      "0.6259842519685039\n",
      "logistic evaluation:  0.31945674447224276\n",
      "average error per step:  0.35037286783153565\n",
      "iteration:  513\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "810\n",
      "average reward\n",
      "0.6247544204322201\n",
      "logistic evaluation:  0.31941411912144874\n",
      "average error per step:  0.3502698940427103\n",
      "iteration:  514\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "328\n",
      "average reward\n",
      "0.6254901960784314\n",
      "logistic evaluation:  0.3195223788716848\n",
      "average error per step:  0.3503183337245202\n",
      "iteration:  515\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "144\n",
      "average reward\n",
      "0.62426614481409\n",
      "logistic evaluation:  0.3194345225346755\n",
      "average error per step:  0.3501705088220938\n",
      "iteration:  516\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "706\n",
      "average reward\n",
      "0.623046875\n",
      "logistic evaluation:  0.31965134054453265\n",
      "average error per step:  0.3503281811569944\n",
      "iteration:  517\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "426\n",
      "average reward\n",
      "0.621832358674464\n",
      "logistic evaluation:  0.3198160479199255\n",
      "average error per step:  0.35043387086655153\n",
      "iteration:  518\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "113\n",
      "average reward\n",
      "0.622568093385214\n",
      "logistic evaluation:  0.3210830287555967\n",
      "average error per step:  0.3516441898448656\n",
      "iteration:  519\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "751\n",
      "average reward\n",
      "0.6213592233009708\n",
      "logistic evaluation:  0.32095314668816394\n",
      "average error per step:  0.3514551728195202\n",
      "iteration:  520\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "35\n",
      "average reward\n",
      "0.622093023255814\n",
      "logistic evaluation:  0.3205802394634526\n",
      "average error per step:  0.35102289072297027\n",
      "iteration:  521\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "179\n",
      "average reward\n",
      "0.6228239845261122\n",
      "logistic evaluation:  0.3199831658896844\n",
      "average error per step:  0.3503662399422284\n",
      "iteration:  522\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "326\n",
      "average reward\n",
      "0.6235521235521235\n",
      "logistic evaluation:  0.31961210835019926\n",
      "average error per step:  0.34993626644183895\n",
      "iteration:  523\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "415\n",
      "average reward\n",
      "0.6242774566473989\n",
      "logistic evaluation:  0.3191579568194746\n",
      "average error per step:  0.3494232653707274\n",
      "iteration:  524\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "942\n",
      "average reward\n",
      "0.6230769230769231\n",
      "logistic evaluation:  0.3189790404263753\n",
      "average error per step:  0.3491862493117037\n",
      "iteration:  525\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "959\n",
      "average reward\n",
      "0.6238003838771593\n",
      "logistic evaluation:  0.31848758144748185\n",
      "average error per step:  0.34863631667973555\n",
      "iteration:  526\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "8\n",
      "average reward\n",
      "0.6245210727969349\n",
      "logistic evaluation:  0.3182912989200824\n",
      "average error per step:  0.3483823440045041\n",
      "iteration:  527\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "493\n",
      "average reward\n",
      "0.6252390057361377\n",
      "logistic evaluation:  0.3179210293951684\n",
      "average error per step:  0.34795427312359517\n",
      "iteration:  528\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "240\n",
      "average reward\n",
      "0.6259541984732825\n",
      "logistic evaluation:  0.31735067183599497\n",
      "average error per step:  0.3473259541983467\n",
      "iteration:  529\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "203\n",
      "average reward\n",
      "0.6266666666666667\n",
      "logistic evaluation:  0.3176800595114793\n",
      "average error per step:  0.347599300485009\n",
      "iteration:  530\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "267\n",
      "average reward\n",
      "0.6273764258555133\n",
      "logistic evaluation:  0.31889065859908555\n",
      "average error per step:  0.3487557323237738\n",
      "iteration:  531\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "53\n",
      "average reward\n",
      "0.6280834914611005\n",
      "logistic evaluation:  0.3188636879058916\n",
      "average error per step:  0.3486724677616197\n",
      "iteration:  532\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "635\n",
      "average reward\n",
      "0.6287878787878788\n",
      "logistic evaluation:  0.31989096162748343\n",
      "average error per step:  0.34964564090777145\n",
      "iteration:  533\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "162\n",
      "average reward\n",
      "0.6294896030245747\n",
      "logistic evaluation:  0.32090011014203923\n",
      "average error per step:  0.3506008578449056\n",
      "iteration:  534\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "639\n",
      "average reward\n",
      "0.6283018867924528\n",
      "logistic evaluation:  0.3207850887377414\n",
      "average error per step:  0.35043000166699884\n",
      "iteration:  535\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "896\n",
      "average reward\n",
      "0.6271186440677966\n",
      "logistic evaluation:  0.3209264591870322\n",
      "average error per step:  0.35051622530791593\n",
      "iteration:  536\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "871\n",
      "average reward\n",
      "0.6259398496240601\n",
      "logistic evaluation:  0.32078096205665363\n",
      "average error per step:  0.3503152519401282\n",
      "iteration:  537\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "751\n",
      "average reward\n",
      "0.626641651031895\n",
      "logistic evaluation:  0.32187727148734324\n",
      "average error per step:  0.35135860423775866\n",
      "iteration:  538\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "129\n",
      "average reward\n",
      "0.6273408239700374\n",
      "logistic evaluation:  0.32217587620846977\n",
      "average error per step:  0.3516029659699832\n",
      "iteration:  539\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "877\n",
      "average reward\n",
      "0.6280373831775701\n",
      "logistic evaluation:  0.3215969287894643\n",
      "average error per step:  0.35096834872318444\n",
      "iteration:  540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "248\n",
      "average reward\n",
      "0.628731343283582\n",
      "logistic evaluation:  0.3219834555836751\n",
      "average error per step:  0.35130119978935914\n",
      "iteration:  541\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "382\n",
      "average reward\n",
      "0.62756052141527\n",
      "logistic evaluation:  0.3217760514700425\n",
      "average error per step:  0.35103922054020104\n",
      "iteration:  542\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "321\n",
      "average reward\n",
      "0.6282527881040892\n",
      "logistic evaluation:  0.32168390552687176\n",
      "average error per step:  0.3508929134992197\n",
      "iteration:  543\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "476\n",
      "average reward\n",
      "0.6289424860853432\n",
      "logistic evaluation:  0.3212941530438416\n",
      "average error per step:  0.35044865132842645\n",
      "iteration:  544\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "369\n",
      "average reward\n",
      "0.6277777777777778\n",
      "logistic evaluation:  0.3210963409804333\n",
      "average error per step:  0.3501968828121726\n",
      "iteration:  545\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "104\n",
      "average reward\n",
      "0.6266173752310537\n",
      "logistic evaluation:  0.32136250447631404\n",
      "average error per step:  0.3504101391918407\n",
      "iteration:  546\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "815\n",
      "average reward\n",
      "0.6254612546125461\n",
      "logistic evaluation:  0.32155400407918383\n",
      "average error per step:  0.35054878873040163\n",
      "iteration:  547\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "745\n",
      "average reward\n",
      "0.6261510128913443\n",
      "logistic evaluation:  0.3212784590942029\n",
      "average error per step:  0.35021973308795046\n",
      "iteration:  548\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "869\n",
      "average reward\n",
      "0.6268382352941176\n",
      "logistic evaluation:  0.32070599016404844\n",
      "average error per step:  0.3495934069626794\n",
      "iteration:  549\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "426\n",
      "average reward\n",
      "0.6275229357798165\n",
      "logistic evaluation:  0.32050922000631216\n",
      "average error per step:  0.3493436601438204\n",
      "iteration:  550\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "685\n",
      "average reward\n",
      "0.6282051282051282\n",
      "logistic evaluation:  0.31993933794859686\n",
      "average error per step:  0.3487203156821138\n",
      "iteration:  551\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "674\n",
      "average reward\n",
      "0.6270566727605119\n",
      "logistic evaluation:  0.3198719000264979\n",
      "average error per step:  0.34860052128877056\n",
      "iteration:  552\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "289\n",
      "average reward\n",
      "0.6259124087591241\n",
      "logistic evaluation:  0.31954222825126305\n",
      "average error per step:  0.34821820767832284\n",
      "iteration:  553\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "95\n",
      "average reward\n",
      "0.6247723132969034\n",
      "logistic evaluation:  0.31972532223873545\n",
      "average error per step:  0.3483497774606603\n",
      "iteration:  554\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "46\n",
      "average reward\n",
      "0.6236363636363637\n",
      "logistic evaluation:  0.31959262794745485\n",
      "average error per step:  0.34816517495726207\n",
      "iteration:  555\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "75\n",
      "average reward\n",
      "0.6243194192377496\n",
      "logistic evaluation:  0.3198109649459054\n",
      "average error per step:  0.3483324232890254\n",
      "iteration:  556\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "173\n",
      "average reward\n",
      "0.625\n",
      "logistic evaluation:  0.31935772771154813\n",
      "average error per step:  0.3478270732928382\n",
      "iteration:  557\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "441\n",
      "average reward\n",
      "0.6238698010849909\n",
      "logistic evaluation:  0.31967313067579445\n",
      "average error per step:  0.34809193057913645\n",
      "iteration:  558\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "156\n",
      "average reward\n",
      "0.6245487364620939\n",
      "logistic evaluation:  0.31912306340351504\n",
      "average error per step:  0.34748994777428427\n",
      "iteration:  559\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "852\n",
      "average reward\n",
      "0.6252252252252253\n",
      "logistic evaluation:  0.3188167168543741\n",
      "average error per step:  0.3471323074310112\n",
      "iteration:  560\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "508\n",
      "average reward\n",
      "0.6241007194244604\n",
      "logistic evaluation:  0.31892740120117635\n",
      "average error per step:  0.34719262587383154\n",
      "iteration:  561\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "968\n",
      "average reward\n",
      "0.6229802513464991\n",
      "logistic evaluation:  0.31896842212933296\n",
      "average error per step:  0.3471833362783794\n",
      "iteration:  562\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "161\n",
      "average reward\n",
      "0.6218637992831542\n",
      "logistic evaluation:  0.31935394119815963\n",
      "average error per step:  0.34751933685062203\n",
      "iteration:  563\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "881\n",
      "average reward\n",
      "0.6225402504472272\n",
      "logistic evaluation:  0.3194022488653516\n",
      "average error per step:  0.3475177029760995\n",
      "iteration:  564\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "913\n",
      "average reward\n",
      "0.6214285714285714\n",
      "logistic evaluation:  0.3193409610580438\n",
      "average error per step:  0.34740645640652573\n",
      "iteration:  565\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "487\n",
      "average reward\n",
      "0.6221033868092691\n",
      "logistic evaluation:  0.31937621464556054\n",
      "average error per step:  0.34739209894667783\n",
      "iteration:  566\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "432\n",
      "average reward\n",
      "0.6227758007117438\n",
      "logistic evaluation:  0.3193435390201829\n",
      "average error per step:  0.34730986756171284\n",
      "iteration:  567\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "329\n",
      "average reward\n",
      "0.6234458259325044\n",
      "logistic evaluation:  0.31910424760273604\n",
      "average error per step:  0.3470208307827862\n",
      "iteration:  568\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "945\n",
      "average reward\n",
      "0.624113475177305\n",
      "logistic evaluation:  0.3201304014232687\n",
      "average error per step:  0.3479996422981085\n",
      "iteration:  569\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "713\n",
      "average reward\n",
      "0.6247787610619469\n",
      "logistic evaluation:  0.31998480958011744\n",
      "average error per step:  0.3478048152480715\n",
      "iteration:  570\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "271\n",
      "average reward\n",
      "0.6254416961130742\n",
      "logistic evaluation:  0.3210102568745446\n",
      "average error per step:  0.34878325454535214\n",
      "iteration:  571\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "303\n",
      "average reward\n",
      "0.6243386243386243\n",
      "logistic evaluation:  0.3210855519688587\n",
      "average error per step:  0.3488100422796373\n",
      "iteration:  572\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "565\n",
      "average reward\n",
      "0.625\n",
      "logistic evaluation:  0.3206466651574162\n",
      "average error per step:  0.3483219187949042\n",
      "iteration:  573\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "964\n",
      "average reward\n",
      "0.6239015817223199\n",
      "logistic evaluation:  0.320735167535727\n",
      "average error per step:  0.3483622767556597\n",
      "iteration:  574\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "457\n",
      "average reward\n",
      "0.6228070175438597\n",
      "logistic evaluation:  0.32103844691934863\n",
      "average error per step:  0.34861795364827736\n",
      "iteration:  575\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "256\n",
      "average reward\n",
      "0.6217162872154116\n",
      "logistic evaluation:  0.320996817316564\n",
      "average error per step:  0.3485282872866549\n",
      "iteration:  576\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "693\n",
      "average reward\n",
      "0.6223776223776224\n",
      "logistic evaluation:  0.32082302576280275\n",
      "average error per step:  0.3483063963205259\n",
      "iteration:  577\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "168\n",
      "average reward\n",
      "0.6212914485165794\n",
      "logistic evaluation:  0.3208881405851002\n",
      "average error per step:  0.34832399250203405\n",
      "iteration:  578\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "8\n",
      "average reward\n",
      "0.6219512195121951\n",
      "logistic evaluation:  0.320960353936411\n",
      "average error per step:  0.34834886391811015\n",
      "iteration:  579\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "739\n",
      "average reward\n",
      "0.6208695652173913\n",
      "logistic evaluation:  0.32117968685475573\n",
      "average error per step:  0.34852127252373755\n",
      "iteration:  580\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "233\n",
      "average reward\n",
      "0.6215277777777778\n",
      "logistic evaluation:  0.32091925557006673\n",
      "average error per step:  0.3482132515546457\n",
      "iteration:  581\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "549\n",
      "average reward\n",
      "0.6221837088388215\n",
      "logistic evaluation:  0.3208633147130419\n",
      "average error per step:  0.3481102367960002\n",
      "iteration:  582\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "324\n",
      "average reward\n",
      "0.6228373702422145\n",
      "logistic evaluation:  0.32194315006910207\n",
      "average error per step:  0.34914511152194544\n",
      "iteration:  583\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "707\n",
      "average reward\n",
      "0.6234887737478411\n",
      "logistic evaluation:  0.32141321553900265\n",
      "average error per step:  0.3485676094172612\n",
      "iteration:  584\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "400\n",
      "average reward\n",
      "0.6241379310344828\n",
      "logistic evaluation:  0.3216130384864163\n",
      "average error per step:  0.3487212772774645\n",
      "iteration:  585\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "605\n",
      "average reward\n",
      "0.6230636833046471\n",
      "logistic evaluation:  0.3214669788535281\n",
      "average error per step:  0.34852862910026183\n",
      "iteration:  586\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "447\n",
      "average reward\n",
      "0.6237113402061856\n",
      "logistic evaluation:  0.32092741368096317\n",
      "average error per step:  0.34794196287749335\n",
      "iteration:  587\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "995\n",
      "average reward\n",
      "0.6243567753001715\n",
      "logistic evaluation:  0.3209912676398029\n",
      "average error per step:  0.34795990423797246\n",
      "iteration:  588\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "254\n",
      "average reward\n",
      "0.625\n",
      "logistic evaluation:  0.32047208925666937\n",
      "average error per step:  0.34739397787017684\n",
      "iteration:  589\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "145\n",
      "average reward\n",
      "0.6256410256410256\n",
      "logistic evaluation:  0.3202372941875991\n",
      "average error per step:  0.3471130763771973\n",
      "iteration:  590\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "318\n",
      "average reward\n",
      "0.6245733788395904\n",
      "logistic evaluation:  0.32048956134451545\n",
      "average error per step:  0.34732021893236337\n",
      "iteration:  591\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "715\n",
      "average reward\n",
      "0.6235093696763203\n",
      "logistic evaluation:  0.32074884587750674\n",
      "average error per step:  0.3475345434432652\n",
      "iteration:  592\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "231\n",
      "average reward\n",
      "0.6241496598639455\n",
      "logistic evaluation:  0.321595823433298\n",
      "average error per step:  0.3483377055936342\n",
      "iteration:  593\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "39\n",
      "average reward\n",
      "0.6230899830220713\n",
      "logistic evaluation:  0.32137707913702007\n",
      "average error per step:  0.3480734964972608\n",
      "iteration:  594\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "271\n",
      "average reward\n",
      "0.6220338983050847\n",
      "logistic evaluation:  0.32139505963295245\n",
      "average error per step:  0.3480465637998189\n",
      "iteration:  595\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "206\n",
      "average reward\n",
      "0.6209813874788495\n",
      "logistic evaluation:  0.32147245134528907\n",
      "average error per step:  0.3480792931382824\n",
      "iteration:  596\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "352\n",
      "average reward\n",
      "0.6216216216216216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic evaluation:  0.32132255797823595\n",
      "average error per step:  0.3478845059202896\n",
      "iteration:  597\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "736\n",
      "average reward\n",
      "0.6222596964586846\n",
      "logistic evaluation:  0.3212893742729772\n",
      "average error per step:  0.3478067742558226\n",
      "iteration:  598\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "872\n",
      "average reward\n",
      "0.6212121212121212\n",
      "logistic evaluation:  0.3210871812593372\n",
      "average error per step:  0.347559899648543\n",
      "iteration:  599\n",
      "estimator:  [ 0.00335636 -0.00607438 -0.01201304]\n",
      "action\n",
      "615\n",
      "average reward\n",
      "0.6218487394957983\n",
      "logistic evaluation:  0.3209137380219955\n",
      "average error per step:  0.3473419720011403\n",
      "iteration:  600\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "945\n",
      "average reward\n",
      "0.62248322147651\n",
      "logistic evaluation:  0.32294173505447554\n",
      "average error per step:  0.3467881889898595\n",
      "iteration:  601\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "371\n",
      "average reward\n",
      "0.6231155778894473\n",
      "logistic evaluation:  0.32259611983723335\n",
      "average error per step:  0.3464023207457411\n",
      "iteration:  602\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "1\n",
      "average reward\n",
      "0.6237458193979933\n",
      "logistic evaluation:  0.32283949064659095\n",
      "average error per step:  0.34660655064131274\n",
      "iteration:  603\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "345\n",
      "average reward\n",
      "0.6243739565943238\n",
      "logistic evaluation:  0.3229305236218777\n",
      "average error per step:  0.3466583198901991\n",
      "iteration:  604\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "747\n",
      "average reward\n",
      "0.6233333333333333\n",
      "logistic evaluation:  0.3227519187948236\n",
      "average error per step:  0.34644013492888115\n",
      "iteration:  605\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "633\n",
      "average reward\n",
      "0.6239600665557404\n",
      "logistic evaluation:  0.323671135241739\n",
      "average error per step:  0.3473217166655699\n",
      "iteration:  606\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "426\n",
      "average reward\n",
      "0.6229235880398671\n",
      "logistic evaluation:  0.32386240825998874\n",
      "average error per step:  0.3474742779537774\n",
      "iteration:  607\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "778\n",
      "average reward\n",
      "0.6218905472636815\n",
      "logistic evaluation:  0.32399607226194455\n",
      "average error per step:  0.3475692628689262\n",
      "iteration:  608\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "157\n",
      "average reward\n",
      "0.6225165562913907\n",
      "logistic evaluation:  0.32349117739003797\n",
      "average error per step:  0.34702476588274517\n",
      "iteration:  609\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "292\n",
      "average reward\n",
      "0.6231404958677685\n",
      "logistic evaluation:  0.3230953908254692\n",
      "average error per step:  0.3465896864198886\n",
      "iteration:  610\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "120\n",
      "average reward\n",
      "0.6237623762376238\n",
      "logistic evaluation:  0.32273701907263863\n",
      "average error per step:  0.34619221193370187\n",
      "iteration:  611\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "160\n",
      "average reward\n",
      "0.6243822075782537\n",
      "logistic evaluation:  0.3228745721729255\n",
      "average error per step:  0.3462916019574571\n",
      "iteration:  612\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "873\n",
      "average reward\n",
      "0.625\n",
      "logistic evaluation:  0.3226277540153631\n",
      "average error per step:  0.34600611738168874\n",
      "iteration:  613\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "810\n",
      "average reward\n",
      "0.6239737274220033\n",
      "logistic evaluation:  0.3229336364617902\n",
      "average error per step:  0.3462743611969251\n",
      "iteration:  614\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "975\n",
      "average reward\n",
      "0.6229508196721312\n",
      "logistic evaluation:  0.3232274443712784\n",
      "average error per step:  0.34653063341125756\n",
      "iteration:  615\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "731\n",
      "average reward\n",
      "0.6219312602291326\n",
      "logistic evaluation:  0.32330390967700495\n",
      "average error per step:  0.34656933168652193\n",
      "iteration:  616\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "608\n",
      "average reward\n",
      "0.6209150326797386\n",
      "logistic evaluation:  0.32303144612423645\n",
      "average error per step:  0.3462586572805679\n",
      "iteration:  617\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "941\n",
      "average reward\n",
      "0.6215334420880914\n",
      "logistic evaluation:  0.3225213917639283\n",
      "average error per step:  0.3457101308529718\n",
      "iteration:  618\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "670\n",
      "average reward\n",
      "0.6221498371335505\n",
      "logistic evaluation:  0.32243779397775973\n",
      "average error per step:  0.34558887556376894\n",
      "iteration:  619\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "30\n",
      "average reward\n",
      "0.6227642276422765\n",
      "logistic evaluation:  0.32222673437155114\n",
      "average error per step:  0.3453400742108847\n",
      "iteration:  620\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "720\n",
      "average reward\n",
      "0.6217532467532467\n",
      "logistic evaluation:  0.32209534747843627\n",
      "average error per step:  0.34517119582304007\n",
      "iteration:  621\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "814\n",
      "average reward\n",
      "0.6223662884927067\n",
      "logistic evaluation:  0.3229656937289124\n",
      "average error per step:  0.3460057844211907\n",
      "iteration:  622\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "642\n",
      "average reward\n",
      "0.6229773462783171\n",
      "logistic evaluation:  0.3224654738202788\n",
      "average error per step:  0.3454677183540348\n",
      "iteration:  623\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "217\n",
      "average reward\n",
      "0.6219709208400647\n",
      "logistic evaluation:  0.32242810596755567\n",
      "average error per step:  0.345393368779985\n",
      "iteration:  624\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "894\n",
      "average reward\n",
      "0.6209677419354839\n",
      "logistic evaluation:  0.3221997543925934\n",
      "average error per step:  0.34512784795119683\n",
      "iteration:  625\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "36\n",
      "average reward\n",
      "0.6215780998389694\n",
      "logistic evaluation:  0.3221858198050476\n",
      "average error per step:  0.3450772061186172\n",
      "iteration:  626\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "137\n",
      "average reward\n",
      "0.6221864951768489\n",
      "logistic evaluation:  0.32198589474070827\n",
      "average error per step:  0.3448403939753994\n",
      "iteration:  627\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "99\n",
      "average reward\n",
      "0.622792937399679\n",
      "logistic evaluation:  0.32149503109002064\n",
      "average error per step:  0.3443122968910827\n",
      "iteration:  628\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "187\n",
      "average reward\n",
      "0.6217948717948718\n",
      "logistic evaluation:  0.32132303569303816\n",
      "average error per step:  0.3441036943902817\n",
      "iteration:  629\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "448\n",
      "average reward\n",
      "0.6224\n",
      "logistic evaluation:  0.3214560216809351\n",
      "average error per step:  0.3442006745392131\n",
      "iteration:  630\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "315\n",
      "average reward\n",
      "0.6230031948881789\n",
      "logistic evaluation:  0.3215319071766387\n",
      "average error per step:  0.3442405778644999\n",
      "iteration:  631\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "983\n",
      "average reward\n",
      "0.6220095693779905\n",
      "logistic evaluation:  0.32175220606813093\n",
      "average error per step:  0.3444252374979947\n",
      "iteration:  632\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "903\n",
      "average reward\n",
      "0.6210191082802548\n",
      "logistic evaluation:  0.3217529909273164\n",
      "average error per step:  0.3443901485493152\n",
      "iteration:  633\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "74\n",
      "average reward\n",
      "0.6200317965023847\n",
      "logistic evaluation:  0.3217649618840664\n",
      "average error per step:  0.3443663767151248\n",
      "iteration:  634\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "436\n",
      "average reward\n",
      "0.6206349206349207\n",
      "logistic evaluation:  0.32162151270782874\n",
      "average error per step:  0.34418705235906494\n",
      "iteration:  635\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "601\n",
      "average reward\n",
      "0.6212361331220285\n",
      "logistic evaluation:  0.32138656401094473\n",
      "average error per step:  0.34391619738131773\n",
      "iteration:  636\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "63\n",
      "average reward\n",
      "0.6218354430379747\n",
      "logistic evaluation:  0.321507466212966\n",
      "average error per step:  0.3440018657293007\n",
      "iteration:  637\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "964\n",
      "average reward\n",
      "0.6224328593996841\n",
      "logistic evaluation:  0.3213393218272439\n",
      "average error per step:  0.3437981443515817\n",
      "iteration:  638\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "917\n",
      "average reward\n",
      "0.6230283911671924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic evaluation:  0.3212049596754796\n",
      "average error per step:  0.34362836968465105\n",
      "iteration:  639\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "341\n",
      "average reward\n",
      "0.6220472440944882\n",
      "logistic evaluation:  0.3213398950422423\n",
      "average error per step:  0.3437284248094069\n",
      "iteration:  640\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "209\n",
      "average reward\n",
      "0.6210691823899371\n",
      "logistic evaluation:  0.321103653113324\n",
      "average error per step:  0.3434568316747134\n",
      "iteration:  641\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "290\n",
      "average reward\n",
      "0.6216640502354788\n",
      "logistic evaluation:  0.32068155103595813\n",
      "average error per step:  0.3429991987383168\n",
      "iteration:  642\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "241\n",
      "average reward\n",
      "0.622257053291536\n",
      "logistic evaluation:  0.3208552589652746\n",
      "average error per step:  0.3431384145496067\n",
      "iteration:  643\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "986\n",
      "average reward\n",
      "0.622848200312989\n",
      "logistic evaluation:  0.3206387831326855\n",
      "average error per step:  0.3428869470662914\n",
      "iteration:  644\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "344\n",
      "average reward\n",
      "0.621875\n",
      "logistic evaluation:  0.3209220545793182\n",
      "average error per step:  0.3431361115370127\n",
      "iteration:  645\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "416\n",
      "average reward\n",
      "0.6209048361934477\n",
      "logistic evaluation:  0.32072967563115673\n",
      "average error per step:  0.342908993928532\n",
      "iteration:  646\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "749\n",
      "average reward\n",
      "0.6214953271028038\n",
      "logistic evaluation:  0.3207282097758041\n",
      "average error per step:  0.34287319249399556\n",
      "iteration:  647\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "193\n",
      "average reward\n",
      "0.6220839813374806\n",
      "logistic evaluation:  0.32047926741093336\n",
      "average error per step:  0.34258963818927474\n",
      "iteration:  648\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "35\n",
      "average reward\n",
      "0.6226708074534162\n",
      "logistic evaluation:  0.32021395575060235\n",
      "average error per step:  0.34228979615481\n",
      "iteration:  649\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "218\n",
      "average reward\n",
      "0.6232558139534884\n",
      "logistic evaluation:  0.32040983833215025\n",
      "average error per step:  0.3424519653961072\n",
      "iteration:  650\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "793\n",
      "average reward\n",
      "0.6238390092879257\n",
      "logistic evaluation:  0.32037515518709864\n",
      "average error per step:  0.34238331792765714\n",
      "iteration:  651\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "803\n",
      "average reward\n",
      "0.624420401854714\n",
      "logistic evaluation:  0.32126929051122866\n",
      "average error per step:  0.34324502002994933\n",
      "iteration:  652\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "688\n",
      "average reward\n",
      "0.625\n",
      "logistic evaluation:  0.3214944411831366\n",
      "average error per step:  0.3434368109183499\n",
      "iteration:  653\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "505\n",
      "average reward\n",
      "0.6255778120184899\n",
      "logistic evaluation:  0.3210193994775235\n",
      "average error per step:  0.3429274393330418\n",
      "iteration:  654\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "899\n",
      "average reward\n",
      "0.6261538461538462\n",
      "logistic evaluation:  0.3212324422967219\n",
      "average error per step:  0.34310730937389716\n",
      "iteration:  655\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "528\n",
      "average reward\n",
      "0.6251920122887865\n",
      "logistic evaluation:  0.3211679715297243\n",
      "average error per step:  0.3430093434346184\n",
      "iteration:  656\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "256\n",
      "average reward\n",
      "0.6242331288343558\n",
      "logistic evaluation:  0.32118412472229196\n",
      "average error per step:  0.34299222647670996\n",
      "iteration:  657\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "728\n",
      "average reward\n",
      "0.6232771822358346\n",
      "logistic evaluation:  0.3210489790558495\n",
      "average error per step:  0.34282368165133165\n",
      "iteration:  658\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "597\n",
      "average reward\n",
      "0.6238532110091743\n",
      "logistic evaluation:  0.3207878135462129\n",
      "average error per step:  0.3425290269804411\n",
      "iteration:  659\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "206\n",
      "average reward\n",
      "0.6244274809160305\n",
      "logistic evaluation:  0.32086097797977536\n",
      "average error per step:  0.3425693112182514\n",
      "iteration:  660\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "265\n",
      "average reward\n",
      "0.625\n",
      "logistic evaluation:  0.32060557763133724\n",
      "average error per step:  0.34228063248559065\n",
      "iteration:  661\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "448\n",
      "average reward\n",
      "0.6255707762557078\n",
      "logistic evaluation:  0.32150298714127035\n",
      "average error per step:  0.34314660834144767\n",
      "iteration:  662\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "901\n",
      "average reward\n",
      "0.6246200607902735\n",
      "logistic evaluation:  0.3215342025526254\n",
      "average error per step:  0.34314517661414884\n",
      "iteration:  663\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "662\n",
      "average reward\n",
      "0.6251896813353566\n",
      "logistic evaluation:  0.32251406027274143\n",
      "average error per step:  0.3440939165117289\n",
      "iteration:  664\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "473\n",
      "average reward\n",
      "0.6242424242424243\n",
      "logistic evaluation:  0.32256534047920105\n",
      "average error per step:  0.3441127741639226\n",
      "iteration:  665\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "223\n",
      "average reward\n",
      "0.6232980332829047\n",
      "logistic evaluation:  0.32245865340731655\n",
      "average error per step:  0.3439735245044342\n",
      "iteration:  666\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "597\n",
      "average reward\n",
      "0.6238670694864048\n",
      "logistic evaluation:  0.3221912849470202\n",
      "average error per step:  0.34367344997873633\n",
      "iteration:  667\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "194\n",
      "average reward\n",
      "0.6229260935143288\n",
      "logistic evaluation:  0.3222787877223266\n",
      "average error per step:  0.3437288767986358\n",
      "iteration:  668\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "827\n",
      "average reward\n",
      "0.6219879518072289\n",
      "logistic evaluation:  0.3221919332722306\n",
      "average error per step:  0.34360978141511705\n",
      "iteration:  669\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "937\n",
      "average reward\n",
      "0.6225563909774436\n",
      "logistic evaluation:  0.32172122284414295\n",
      "average error per step:  0.343106352663306\n",
      "iteration:  670\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "131\n",
      "average reward\n",
      "0.6231231231231231\n",
      "logistic evaluation:  0.32157412439823435\n",
      "average error per step:  0.34292711656327046\n",
      "iteration:  671\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "71\n",
      "average reward\n",
      "0.6221889055472264\n",
      "logistic evaluation:  0.32165361348280286\n",
      "average error per step:  0.34297490147037174\n",
      "iteration:  672\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "275\n",
      "average reward\n",
      "0.6227544910179641\n",
      "logistic evaluation:  0.3226163608999711\n",
      "average error per step:  0.34390735344026263\n",
      "iteration:  673\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "279\n",
      "average reward\n",
      "0.6233183856502242\n",
      "logistic evaluation:  0.32230461863136967\n",
      "average error per step:  0.3435635120114697\n",
      "iteration:  674\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "154\n",
      "average reward\n",
      "0.6238805970149254\n",
      "logistic evaluation:  0.32322456177518466\n",
      "average error per step:  0.3444532786712545\n",
      "iteration:  675\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "118\n",
      "average reward\n",
      "0.624441132637854\n",
      "logistic evaluation:  0.3229228483497773\n",
      "average error per step:  0.3441196683120376\n",
      "iteration:  676\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "920\n",
      "average reward\n",
      "0.625\n",
      "logistic evaluation:  0.3229263053984198\n",
      "average error per step:  0.3440917742321097\n",
      "iteration:  677\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "732\n",
      "average reward\n",
      "0.6240713224368499\n",
      "logistic evaluation:  0.3230505942160761\n",
      "average error per step:  0.34418498302020023\n",
      "iteration:  678\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "803\n",
      "average reward\n",
      "0.6246290801186943\n",
      "logistic evaluation:  0.32392535390056426\n",
      "average error per step:  0.3450298612458098\n",
      "iteration:  679\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "621\n",
      "average reward\n",
      "0.6251851851851852\n",
      "logistic evaluation:  0.3238328641401285\n",
      "average error per step:  0.3449061535220373\n",
      "iteration:  680\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "39\n",
      "average reward\n",
      "0.6257396449704142\n",
      "logistic evaluation:  0.323505216820246\n",
      "average error per step:  0.34454703423641686\n",
      "iteration:  681\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "943\n",
      "average reward\n",
      "0.6262924667651403\n",
      "logistic evaluation:  0.3237209337502067\n",
      "average error per step:  0.34473216952102337\n",
      "iteration:  682\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "231\n",
      "average reward\n",
      "0.6268436578171092\n",
      "logistic evaluation:  0.32339612982245103\n",
      "average error per step:  0.3443760810775806\n",
      "iteration:  683\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "197\n",
      "average reward\n",
      "0.625920471281296\n",
      "logistic evaluation:  0.3235616123943978\n",
      "average error per step:  0.34451108858556956\n",
      "iteration:  684\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "22\n",
      "average reward\n",
      "0.625\n",
      "logistic evaluation:  0.3234765656965632\n",
      "average error per step:  0.344395289661289\n",
      "iteration:  685\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "552\n",
      "average reward\n",
      "0.6255506607929515\n",
      "logistic evaluation:  0.32303738508942226\n",
      "average error per step:  0.34392492963141547\n",
      "iteration:  686\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "48\n",
      "average reward\n",
      "0.626099706744868\n",
      "logistic evaluation:  0.3232011155212273\n",
      "average error per step:  0.3440584504216605\n",
      "iteration:  687\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "327\n",
      "average reward\n",
      "0.6266471449487555\n",
      "logistic evaluation:  0.3228201241582807\n",
      "average error per step:  0.34364654446444404\n",
      "iteration:  688\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "774\n",
      "average reward\n",
      "0.6271929824561403\n",
      "logistic evaluation:  0.32284574860034987\n",
      "average error per step:  0.34364193519159447\n",
      "iteration:  689\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "256\n",
      "average reward\n",
      "0.6277372262773723\n",
      "logistic evaluation:  0.3237668631547845\n",
      "average error per step:  0.3445342034876302\n",
      "iteration:  690\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "601\n",
      "average reward\n",
      "0.6282798833819242\n",
      "logistic evaluation:  0.3246342016550735\n",
      "average error per step:  0.3453727014055532\n",
      "iteration:  691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "562\n",
      "average reward\n",
      "0.6273653566229985\n",
      "logistic evaluation:  0.32480667008383074\n",
      "average error per step:  0.3455154071261748\n",
      "iteration:  692\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "281\n",
      "average reward\n",
      "0.627906976744186\n",
      "logistic evaluation:  0.32501995293177277\n",
      "average error per step:  0.3456990722657434\n",
      "iteration:  693\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "236\n",
      "average reward\n",
      "0.6284470246734397\n",
      "logistic evaluation:  0.32457619611553\n",
      "average error per step:  0.3452248351087356\n",
      "iteration:  694\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "672\n",
      "average reward\n",
      "0.6275362318840579\n",
      "logistic evaluation:  0.32467863238351874\n",
      "average error per step:  0.34529766589729316\n",
      "iteration:  695\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "873\n",
      "average reward\n",
      "0.6266280752532561\n",
      "logistic evaluation:  0.3248461552157371\n",
      "average error per step:  0.34543576209543736\n",
      "iteration:  696\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "289\n",
      "average reward\n",
      "0.6257225433526011\n",
      "logistic evaluation:  0.325054306817875\n",
      "average error per step:  0.3456146299974638\n",
      "iteration:  697\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "845\n",
      "average reward\n",
      "0.6262626262626263\n",
      "logistic evaluation:  0.32478885410838565\n",
      "average error per step:  0.3453192981260102\n",
      "iteration:  698\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "669\n",
      "average reward\n",
      "0.6268011527377522\n",
      "logistic evaluation:  0.3244218771641918\n",
      "average error per step:  0.3449223821833037\n",
      "iteration:  699\n",
      "estimator:  [ 0.00328266 -0.00649672 -0.01141064]\n",
      "action\n",
      "769\n",
      "average reward\n",
      "0.6258992805755396\n",
      "logistic evaluation:  0.32463433738195235\n",
      "average error per step:  0.34510581801651297\n",
      "iteration:  700\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "482\n",
      "average reward\n",
      "0.625\n",
      "logistic evaluation:  0.3305174828460803\n",
      "average error per step:  0.34499694361447825\n",
      "iteration:  701\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "471\n",
      "average reward\n",
      "0.6255380200860832\n",
      "logistic evaluation:  0.33062900273948237\n",
      "average error per step:  0.345087967158558\n",
      "iteration:  702\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "312\n",
      "average reward\n",
      "0.6260744985673352\n",
      "logistic evaluation:  0.3305713935154521\n",
      "average error per step:  0.3450096790546942\n",
      "iteration:  703\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "632\n",
      "average reward\n",
      "0.6266094420600858\n",
      "logistic evaluation:  0.33064641438617454\n",
      "average error per step:  0.3450642685389749\n",
      "iteration:  704\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "146\n",
      "average reward\n",
      "0.6257142857142857\n",
      "logistic evaluation:  0.3308819626898813\n",
      "average error per step:  0.3452796715218733\n",
      "iteration:  705\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "382\n",
      "average reward\n",
      "0.6262482168330956\n",
      "logistic evaluation:  0.33056443080367426\n",
      "average error per step:  0.3449412669537965\n",
      "iteration:  706\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "461\n",
      "average reward\n",
      "0.6253561253561254\n",
      "logistic evaluation:  0.3305822303169215\n",
      "average error per step:  0.344938727888238\n",
      "iteration:  707\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "898\n",
      "average reward\n",
      "0.6258890469416786\n",
      "logistic evaluation:  0.33065617851949725\n",
      "average error per step:  0.34499247446511533\n",
      "iteration:  708\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "681\n",
      "average reward\n",
      "0.6264204545454546\n",
      "logistic evaluation:  0.3303689953316781\n",
      "average error per step:  0.3446846366457517\n",
      "iteration:  709\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "101\n",
      "average reward\n",
      "0.625531914893617\n",
      "logistic evaluation:  0.3304715874254117\n",
      "average error per step:  0.34476718212563445\n",
      "iteration:  710\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "517\n",
      "average reward\n",
      "0.6260623229461756\n",
      "logistic evaluation:  0.33017062549308374\n",
      "average error per step:  0.3444456616628381\n",
      "iteration:  711\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "875\n",
      "average reward\n",
      "0.6265912305516266\n",
      "logistic evaluation:  0.33027538087834024\n",
      "average error per step:  0.3445304869766677\n",
      "iteration:  712\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "248\n",
      "average reward\n",
      "0.6257062146892656\n",
      "logistic evaluation:  0.33040494508088275\n",
      "average error per step:  0.34464021193497457\n",
      "iteration:  713\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "214\n",
      "average reward\n",
      "0.6262341325811002\n",
      "logistic evaluation:  0.3301938561776575\n",
      "average error per step:  0.34440886166322576\n",
      "iteration:  714\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "579\n",
      "average reward\n",
      "0.6253521126760564\n",
      "logistic evaluation:  0.3303741794463604\n",
      "average error per step:  0.34456952851425793\n",
      "iteration:  715\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "886\n",
      "average reward\n",
      "0.6258790436005626\n",
      "logistic evaluation:  0.32994949288687914\n",
      "average error per step:  0.34412439435250064\n",
      "iteration:  716\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "341\n",
      "average reward\n",
      "0.625\n",
      "logistic evaluation:  0.33009696256494003\n",
      "average error per step:  0.3442522726453834\n",
      "iteration:  717\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "495\n",
      "average reward\n",
      "0.6241234221598878\n",
      "logistic evaluation:  0.3302128795753081\n",
      "average error per step:  0.34434860891227853\n",
      "iteration:  718\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "481\n",
      "average reward\n",
      "0.6246498599439776\n",
      "logistic evaluation:  0.3297706887912745\n",
      "average error per step:  0.34388611461832713\n",
      "iteration:  719\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "342\n",
      "average reward\n",
      "0.6251748251748251\n",
      "logistic evaluation:  0.32955668541977057\n",
      "average error per step:  0.3436521815817348\n",
      "iteration:  720\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "627\n",
      "average reward\n",
      "0.6243016759776536\n",
      "logistic evaluation:  0.3294070747582419\n",
      "average error per step:  0.3434827860496179\n",
      "iteration:  721\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "132\n",
      "average reward\n",
      "0.6248256624825662\n",
      "logistic evaluation:  0.3289679402090994\n",
      "average error per step:  0.3430235199528464\n",
      "iteration:  722\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "264\n",
      "average reward\n",
      "0.6239554317548747\n",
      "logistic evaluation:  0.3291858390616463\n",
      "average error per step:  0.3432222530423861\n",
      "iteration:  723\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "537\n",
      "average reward\n",
      "0.6230876216968011\n",
      "logistic evaluation:  0.3291313888219212\n",
      "average error per step:  0.3431483133639052\n",
      "iteration:  724\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "898\n",
      "average reward\n",
      "0.6236111111111111\n",
      "logistic evaluation:  0.3286948482064451\n",
      "average error per step:  0.3426918093987641\n",
      "iteration:  725\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "92\n",
      "average reward\n",
      "0.6227461858529819\n",
      "logistic evaluation:  0.32852918527467384\n",
      "average error per step:  0.34250661181302855\n",
      "iteration:  726\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "499\n",
      "average reward\n",
      "0.6232686980609419\n",
      "logistic evaluation:  0.32933466132306\n",
      "average error per step:  0.3432939446789216\n",
      "iteration:  727\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "272\n",
      "average reward\n",
      "0.623789764868603\n",
      "logistic evaluation:  0.32896277746002683\n",
      "average error per step:  0.34290234806868225\n",
      "iteration:  728\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "209\n",
      "average reward\n",
      "0.6229281767955801\n",
      "logistic evaluation:  0.3291055677097811\n",
      "average error per step:  0.3430261866970645\n",
      "iteration:  729\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "177\n",
      "average reward\n",
      "0.6220689655172413\n",
      "logistic evaluation:  0.32928169271296703\n",
      "average error per step:  0.34318345779903764\n",
      "iteration:  730\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "510\n",
      "average reward\n",
      "0.6225895316804407\n",
      "logistic evaluation:  0.3300994892806332\n",
      "average error per step:  0.34398333112215806\n",
      "iteration:  731\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "839\n",
      "average reward\n",
      "0.6231086657496562\n",
      "logistic evaluation:  0.32978120044751913\n",
      "average error per step:  0.3436456139297079\n",
      "iteration:  732\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "906\n",
      "average reward\n",
      "0.6222527472527473\n",
      "logistic evaluation:  0.3298848005041458\n",
      "average error per step:  0.34373041506088986\n",
      "iteration:  733\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "111\n",
      "average reward\n",
      "0.6227709190672154\n",
      "logistic evaluation:  0.32992178277322565\n",
      "average error per step:  0.3437485588138883\n",
      "iteration:  734\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "228\n",
      "average reward\n",
      "0.6232876712328768\n",
      "logistic evaluation:  0.3298640516978251\n",
      "average error per step:  0.34367191151625875\n",
      "iteration:  735\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "111\n",
      "average reward\n",
      "0.6238030095759234\n",
      "logistic evaluation:  0.3299054574396479\n",
      "average error per step:  0.3436945873885896\n",
      "iteration:  736\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "828\n",
      "average reward\n",
      "0.6243169398907104\n",
      "logistic evaluation:  0.32999243686651214\n",
      "average error per step:  0.34376294976311406\n",
      "iteration:  737\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "915\n",
      "average reward\n",
      "0.6248294679399727\n",
      "logistic evaluation:  0.32988518648541226\n",
      "average error per step:  0.3436368693097242\n",
      "iteration:  738\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "546\n",
      "average reward\n",
      "0.6253405994550408\n",
      "logistic evaluation:  0.3295676745373172\n",
      "average error per step:  0.3433002934120731\n",
      "iteration:  739\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "988\n",
      "average reward\n",
      "0.6244897959183674\n",
      "logistic evaluation:  0.32957372936035423\n",
      "average error per step:  0.3432877737235381\n",
      "iteration:  740\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "451\n",
      "average reward\n",
      "0.625\n",
      "logistic evaluation:  0.33034774957008756\n",
      "average error per step:  0.3440443074141451\n",
      "iteration:  741\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "780\n",
      "average reward\n",
      "0.6241519674355496\n",
      "logistic evaluation:  0.33017804970457987\n",
      "average error per step:  0.34385589465024397\n",
      "iteration:  742\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "383\n",
      "average reward\n",
      "0.6246612466124661\n",
      "logistic evaluation:  0.3308482299559024\n",
      "average error per step:  0.34450854435615635\n",
      "iteration:  743\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "675\n",
      "average reward\n",
      "0.625169147496617\n",
      "logistic evaluation:  0.33077256776999253\n",
      "average error per step:  0.3444143949877617\n",
      "iteration:  744\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "69\n",
      "average reward\n",
      "0.6256756756756757\n",
      "logistic evaluation:  0.3303485654124752\n",
      "average error per step:  0.34397148694533136\n",
      "iteration:  745\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "881\n",
      "average reward\n",
      "0.6261808367071525\n",
      "logistic evaluation:  0.33049201793945343\n",
      "average error per step:  0.3440968462253218\n",
      "iteration:  746\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "976\n",
      "average reward\n",
      "0.6253369272237197\n",
      "logistic evaluation:  0.3306152964879575\n",
      "average error per step:  0.34420205299133605\n",
      "iteration:  747\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "115\n",
      "average reward\n",
      "0.6244952893674294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic evaluation:  0.3305139270799797\n",
      "average error per step:  0.3440823594522855\n",
      "iteration:  748\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "821\n",
      "average reward\n",
      "0.6236559139784946\n",
      "logistic evaluation:  0.330480377305528\n",
      "average error per step:  0.3440306252097231\n",
      "iteration:  749\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "610\n",
      "average reward\n",
      "0.6241610738255033\n",
      "logistic evaluation:  0.3304560968389774\n",
      "average error per step:  0.343988221207297\n",
      "iteration:  750\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "614\n",
      "average reward\n",
      "0.6246648793565683\n",
      "logistic evaluation:  0.3303763280248644\n",
      "average error per step:  0.34389030320227404\n",
      "iteration:  751\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "908\n",
      "average reward\n",
      "0.6238286479250335\n",
      "logistic evaluation:  0.3302225624061268\n",
      "average error per step:  0.343718338194993\n",
      "iteration:  752\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "754\n",
      "average reward\n",
      "0.6243315508021391\n",
      "logistic evaluation:  0.3303975454923308\n",
      "average error per step:  0.3438756074611138\n",
      "iteration:  753\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "239\n",
      "average reward\n",
      "0.6248331108144193\n",
      "logistic evaluation:  0.3303769291385984\n",
      "average error per step:  0.34383706457574453\n",
      "iteration:  754\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "17\n",
      "average reward\n",
      "0.6253333333333333\n",
      "logistic evaluation:  0.3305340694498595\n",
      "average error per step:  0.3439765616573957\n",
      "iteration:  755\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "425\n",
      "average reward\n",
      "0.625832223701731\n",
      "logistic evaluation:  0.3303183177532129\n",
      "average error per step:  0.34374271957147196\n",
      "iteration:  756\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "606\n",
      "average reward\n",
      "0.625\n",
      "logistic evaluation:  0.3303096922374287\n",
      "average error per step:  0.34371632550101305\n",
      "iteration:  757\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "994\n",
      "average reward\n",
      "0.6254980079681275\n",
      "logistic evaluation:  0.33044299492905116\n",
      "average error per step:  0.34383209407034765\n",
      "iteration:  758\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "81\n",
      "average reward\n",
      "0.6246684350132626\n",
      "logistic evaluation:  0.33060737061040135\n",
      "average error per step:  0.34397902288697496\n",
      "iteration:  759\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "839\n",
      "average reward\n",
      "0.623841059602649\n",
      "logistic evaluation:  0.33068019916162644\n",
      "average error per step:  0.34403432993131555\n",
      "iteration:  760\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "673\n",
      "average reward\n",
      "0.6243386243386243\n",
      "logistic evaluation:  0.3303245061875208\n",
      "average error per step:  0.3436605977154417\n",
      "iteration:  761\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "316\n",
      "average reward\n",
      "0.6248348745046235\n",
      "logistic evaluation:  0.33000651201420156\n",
      "average error per step:  0.3433246612481656\n",
      "iteration:  762\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "278\n",
      "average reward\n",
      "0.6253298153034301\n",
      "logistic evaluation:  0.32959472484008323\n",
      "average error per step:  0.34289485578479784\n",
      "iteration:  763\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "620\n",
      "average reward\n",
      "0.6258234519104084\n",
      "logistic evaluation:  0.32977682112049206\n",
      "average error per step:  0.34305975935922456\n",
      "iteration:  764\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "614\n",
      "average reward\n",
      "0.6263157894736842\n",
      "logistic evaluation:  0.3298830102327704\n",
      "average error per step:  0.34314870141767245\n",
      "iteration:  765\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "289\n",
      "average reward\n",
      "0.6254927726675427\n",
      "logistic evaluation:  0.32988228125215274\n",
      "average error per step:  0.34313063071134825\n",
      "iteration:  766\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "322\n",
      "average reward\n",
      "0.6259842519685039\n",
      "logistic evaluation:  0.33000621945993286\n",
      "average error per step:  0.3432374352229776\n",
      "iteration:  767\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "488\n",
      "average reward\n",
      "0.6251638269986893\n",
      "logistic evaluation:  0.33003144073438057\n",
      "average error per step:  0.3432454387731899\n",
      "iteration:  768\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "799\n",
      "average reward\n",
      "0.6256544502617801\n",
      "logistic evaluation:  0.3307543294909705\n",
      "average error per step:  0.34395206306456855\n",
      "iteration:  769\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "718\n",
      "average reward\n",
      "0.6261437908496732\n",
      "logistic evaluation:  0.33067858954578633\n",
      "average error per step:  0.3438590624256018\n",
      "iteration:  770\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "316\n",
      "average reward\n",
      "0.6266318537859008\n",
      "logistic evaluation:  0.3302649498599459\n",
      "average error per step:  0.3434277680481177\n",
      "iteration:  771\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "170\n",
      "average reward\n",
      "0.6271186440677966\n",
      "logistic evaluation:  0.32984986214706996\n",
      "average error per step:  0.34299506956234804\n",
      "iteration:  772\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "57\n",
      "average reward\n",
      "0.6276041666666666\n",
      "logistic evaluation:  0.3297840845640712\n",
      "average error per step:  0.34291217930448104\n",
      "iteration:  773\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "554\n",
      "average reward\n",
      "0.6280884265279584\n",
      "logistic evaluation:  0.32968874314106417\n",
      "average error per step:  0.34279973123701935\n",
      "iteration:  774\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "963\n",
      "average reward\n",
      "0.6285714285714286\n",
      "logistic evaluation:  0.3292717828233447\n",
      "average error per step:  0.34236529294977314\n",
      "iteration:  775\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "9\n",
      "average reward\n",
      "0.62905317769131\n",
      "logistic evaluation:  0.3290044310049983\n",
      "average error per step:  0.34208070130956253\n",
      "iteration:  776\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "727\n",
      "average reward\n",
      "0.6282383419689119\n",
      "logistic evaluation:  0.3292069098336074\n",
      "average error per step:  0.3422665902007026\n",
      "iteration:  777\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "714\n",
      "average reward\n",
      "0.628719275549806\n",
      "logistic evaluation:  0.3298703393612267\n",
      "average error per step:  0.3429140657375376\n",
      "iteration:  778\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "105\n",
      "average reward\n",
      "0.6291989664082688\n",
      "logistic evaluation:  0.3299012193993115\n",
      "average error per step:  0.3429282197520514\n",
      "iteration:  779\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "251\n",
      "average reward\n",
      "0.6296774193548387\n",
      "logistic evaluation:  0.3297190275230853\n",
      "average error per step:  0.342729071274761\n",
      "iteration:  780\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "727\n",
      "average reward\n",
      "0.6301546391752577\n",
      "logistic evaluation:  0.3293132749287044\n",
      "average error per step:  0.3423061189414749\n",
      "iteration:  781\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "554\n",
      "average reward\n",
      "0.6293436293436293\n",
      "logistic evaluation:  0.3293934061987679\n",
      "average error per step:  0.34236971664848753\n",
      "iteration:  782\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "326\n",
      "average reward\n",
      "0.62853470437018\n",
      "logistic evaluation:  0.3292301810954254\n",
      "average error per step:  0.3421896890700133\n",
      "iteration:  783\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "843\n",
      "average reward\n",
      "0.6290115532734275\n",
      "logistic evaluation:  0.3300556434587632\n",
      "average error per step:  0.34299965456794723\n",
      "iteration:  784\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "98\n",
      "average reward\n",
      "0.6282051282051282\n",
      "logistic evaluation:  0.3302309792067918\n",
      "average error per step:  0.34315870374026003\n",
      "iteration:  785\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "209\n",
      "average reward\n",
      "0.6274007682458387\n",
      "logistic evaluation:  0.3304159425698808\n",
      "average error per step:  0.34332743428657153\n",
      "iteration:  786\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "605\n",
      "average reward\n",
      "0.6278772378516624\n",
      "logistic evaluation:  0.3304244792260198\n",
      "average error per step:  0.343319554969351\n",
      "iteration:  787\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "810\n",
      "average reward\n",
      "0.6283524904214559\n",
      "logistic evaluation:  0.33029893269467175\n",
      "average error per step:  0.3431774638099538\n",
      "iteration:  788\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "7\n",
      "average reward\n",
      "0.6288265306122449\n",
      "logistic evaluation:  0.33031546685416663\n",
      "average error per step:  0.3431776756382865\n",
      "iteration:  789\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "17\n",
      "average reward\n",
      "0.6292993630573248\n",
      "logistic evaluation:  0.33048312983057704\n",
      "average error per step:  0.3433292492030268\n",
      "iteration:  790\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "61\n",
      "average reward\n",
      "0.6297709923664122\n",
      "logistic evaluation:  0.3302886979602979\n",
      "average error per step:  0.34311831030585815\n",
      "iteration:  791\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "859\n",
      "average reward\n",
      "0.6302414231257941\n",
      "logistic evaluation:  0.33013463284285693\n",
      "average error per step:  0.3429478309311947\n",
      "iteration:  792\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "312\n",
      "average reward\n",
      "0.6294416243654822\n",
      "logistic evaluation:  0.33008144553862817\n",
      "average error per step:  0.3428783981908642\n",
      "iteration:  793\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "729\n",
      "average reward\n",
      "0.6286438529784537\n",
      "logistic evaluation:  0.3300400377467559\n",
      "average error per step:  0.34282080078935245\n",
      "iteration:  794\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "310\n",
      "average reward\n",
      "0.6278481012658228\n",
      "logistic evaluation:  0.33022462622044674\n",
      "average error per step:  0.3429895250633343\n",
      "iteration:  795\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "375\n",
      "average reward\n",
      "0.6283185840707964\n",
      "logistic evaluation:  0.3299512967733233\n",
      "average error per step:  0.34269979532905365\n",
      "iteration:  796\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "131\n",
      "average reward\n",
      "0.6287878787878788\n",
      "logistic evaluation:  0.3298055635822101\n",
      "average error per step:  0.3425378633543389\n",
      "iteration:  797\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "555\n",
      "average reward\n",
      "0.6292559899117276\n",
      "logistic evaluation:  0.3305308262289366\n",
      "average error per step:  0.34324806070981645\n",
      "iteration:  798\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "94\n",
      "average reward\n",
      "0.6297229219143576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic evaluation:  0.33072653578383454\n",
      "average error per step:  0.34342807913072193\n",
      "iteration:  799\n",
      "estimator:  [ 0.00298317 -0.00642082 -0.01071586]\n",
      "action\n",
      "937\n",
      "average reward\n",
      "0.6289308176100629\n",
      "logistic evaluation:  0.3306030592448064\n",
      "average error per step:  0.34328855125266255\n",
      "iteration:  800\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "313\n",
      "average reward\n",
      "0.628140703517588\n",
      "logistic evaluation:  0.330995109663269\n",
      "average error per step:  0.3432168569411562\n",
      "iteration:  801\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "723\n",
      "average reward\n",
      "0.6286072772898369\n",
      "logistic evaluation:  0.33171033054750804\n",
      "average error per step:  0.343917712623905\n",
      "iteration:  802\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "934\n",
      "average reward\n",
      "0.6278195488721805\n",
      "logistic evaluation:  0.33181910609888515\n",
      "average error per step:  0.3440114026309866\n",
      "iteration:  803\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "464\n",
      "average reward\n",
      "0.6282853566958698\n",
      "logistic evaluation:  0.3318664909071202\n",
      "average error per step:  0.34404366301615336\n",
      "iteration:  804\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "573\n",
      "average reward\n",
      "0.6275\n",
      "logistic evaluation:  0.33181199376050635\n",
      "average error per step:  0.34397395235056477\n",
      "iteration:  805\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "673\n",
      "average reward\n",
      "0.6279650436953808\n",
      "logistic evaluation:  0.3319902714158425\n",
      "average error per step:  0.34413734344573355\n",
      "iteration:  806\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "258\n",
      "average reward\n",
      "0.628428927680798\n",
      "logistic evaluation:  0.33159250826599307\n",
      "average error per step:  0.3437240159842468\n",
      "iteration:  807\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "135\n",
      "average reward\n",
      "0.6288916562889165\n",
      "logistic evaluation:  0.33141317489627803\n",
      "average error per step:  0.3435294275450299\n",
      "iteration:  808\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "834\n",
      "average reward\n",
      "0.6293532338308457\n",
      "logistic evaluation:  0.3310358414536083\n",
      "average error per step:  0.3431366317433362\n",
      "iteration:  809\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "707\n",
      "average reward\n",
      "0.6298136645962733\n",
      "logistic evaluation:  0.33064765897735476\n",
      "average error per step:  0.3427330117234905\n",
      "iteration:  810\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "543\n",
      "average reward\n",
      "0.630272952853598\n",
      "logistic evaluation:  0.33083194415454426\n",
      "average error per step:  0.342902604224669\n",
      "iteration:  811\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "814\n",
      "average reward\n",
      "0.630731102850062\n",
      "logistic evaluation:  0.3309922890826294\n",
      "average error per step:  0.3430482631908034\n",
      "iteration:  812\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "827\n",
      "average reward\n",
      "0.6311881188118812\n",
      "logistic evaluation:  0.33118038759671814\n",
      "average error per step:  0.34322174609455464\n",
      "iteration:  813\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "384\n",
      "average reward\n",
      "0.6316440049443758\n",
      "logistic evaluation:  0.3313450321956725\n",
      "average error per step:  0.3433717821893283\n",
      "iteration:  814\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "522\n",
      "average reward\n",
      "0.6320987654320988\n",
      "logistic evaluation:  0.33129549467216557\n",
      "average error per step:  0.3433074089317708\n",
      "iteration:  815\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "811\n",
      "average reward\n",
      "0.6325524044389642\n",
      "logistic evaluation:  0.33089917814401204\n",
      "average error per step:  0.3428958675805648\n",
      "iteration:  816\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "299\n",
      "average reward\n",
      "0.6330049261083743\n",
      "logistic evaluation:  0.3309594202373158\n",
      "average error per step:  0.34294148167467337\n",
      "iteration:  817\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "248\n",
      "average reward\n",
      "0.6322263222632226\n",
      "logistic evaluation:  0.33106175447917074\n",
      "average error per step:  0.3430292752467664\n",
      "iteration:  818\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "665\n",
      "average reward\n",
      "0.6326781326781327\n",
      "logistic evaluation:  0.3312487450661279\n",
      "average error per step:  0.34320186420758586\n",
      "iteration:  819\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "167\n",
      "average reward\n",
      "0.6331288343558282\n",
      "logistic evaluation:  0.33132308376786024\n",
      "average error per step:  0.3432616989038973\n",
      "iteration:  820\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "705\n",
      "average reward\n",
      "0.633578431372549\n",
      "logistic evaluation:  0.33208727122608644\n",
      "average error per step:  0.3440122590112969\n",
      "iteration:  821\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "35\n",
      "average reward\n",
      "0.6340269277845777\n",
      "logistic evaluation:  0.33169284135195554\n",
      "average error per step:  0.3436028237563385\n",
      "iteration:  822\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "377\n",
      "average reward\n",
      "0.6332518337408313\n",
      "logistic evaluation:  0.33169420011752193\n",
      "average error per step:  0.34358969514521537\n",
      "iteration:  823\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "859\n",
      "average reward\n",
      "0.6336996336996337\n",
      "logistic evaluation:  0.33235966924493826\n",
      "average error per step:  0.3442415190406751\n",
      "iteration:  824\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "150\n",
      "average reward\n",
      "0.6341463414634146\n",
      "logistic evaluation:  0.3320910486054874\n",
      "average error per step:  0.34395815268467667\n",
      "iteration:  825\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "747\n",
      "average reward\n",
      "0.633373934226553\n",
      "logistic evaluation:  0.33215377371987287\n",
      "average error per step:  0.344006569460923\n",
      "iteration:  826\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "808\n",
      "average reward\n",
      "0.6326034063260341\n",
      "logistic evaluation:  0.3322947374662453\n",
      "average error per step:  0.3441333542339363\n",
      "iteration:  827\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "404\n",
      "average reward\n",
      "0.6330498177399757\n",
      "logistic evaluation:  0.33191536306073416\n",
      "average error per step:  0.343739205957599\n",
      "iteration:  828\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "259\n",
      "average reward\n",
      "0.633495145631068\n",
      "logistic evaluation:  0.3325538874761879\n",
      "average error per step:  0.34436422153430707\n",
      "iteration:  829\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "781\n",
      "average reward\n",
      "0.6339393939393939\n",
      "logistic evaluation:  0.3325543567049805\n",
      "average error per step:  0.3443504448465384\n",
      "iteration:  830\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "998\n",
      "average reward\n",
      "0.6343825665859564\n",
      "logistic evaluation:  0.332510971731255\n",
      "average error per step:  0.34429279544737273\n",
      "iteration:  831\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "993\n",
      "average reward\n",
      "0.6348246674727932\n",
      "logistic evaluation:  0.3323039017216249\n",
      "average error per step:  0.3440712983694806\n",
      "iteration:  832\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "291\n",
      "average reward\n",
      "0.6352657004830918\n",
      "logistic evaluation:  0.332300538560375\n",
      "average error per step:  0.34405378766038325\n",
      "iteration:  833\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "723\n",
      "average reward\n",
      "0.6357056694813028\n",
      "logistic evaluation:  0.3329772968210725\n",
      "average error per step:  0.34471724881323046\n",
      "iteration:  834\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "438\n",
      "average reward\n",
      "0.636144578313253\n",
      "logistic evaluation:  0.33320943023765337\n",
      "average error per step:  0.34493558388619555\n",
      "iteration:  835\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "374\n",
      "average reward\n",
      "0.6365824308062575\n",
      "logistic evaluation:  0.33304277151353323\n",
      "average error per step:  0.3447546822730063\n",
      "iteration:  836\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "765\n",
      "average reward\n",
      "0.6370192307692307\n",
      "logistic evaluation:  0.33266276542816464\n",
      "average error per step:  0.3443602121722731\n",
      "iteration:  837\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "539\n",
      "average reward\n",
      "0.6374549819927972\n",
      "logistic evaluation:  0.3324094050771354\n",
      "average error per step:  0.34409257367656626\n",
      "iteration:  838\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "277\n",
      "average reward\n",
      "0.6366906474820144\n",
      "logistic evaluation:  0.33261383939939027\n",
      "average error per step:  0.3442833102252207\n",
      "iteration:  839\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "425\n",
      "average reward\n",
      "0.637125748502994\n",
      "logistic evaluation:  0.3322373609535048\n",
      "average error per step:  0.34389247427126407\n",
      "iteration:  840\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "892\n",
      "average reward\n",
      "0.6363636363636364\n",
      "logistic evaluation:  0.33232306865188493\n",
      "average error per step:  0.34396440886771634\n",
      "iteration:  841\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "600\n",
      "average reward\n",
      "0.6367980884109916\n",
      "logistic evaluation:  0.3324612376056532\n",
      "average error per step:  0.3440888998532776\n",
      "iteration:  842\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "747\n",
      "average reward\n",
      "0.6372315035799523\n",
      "logistic evaluation:  0.33209415828944283\n",
      "average error per step:  0.34370757500076815\n",
      "iteration:  843\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "166\n",
      "average reward\n",
      "0.636471990464839\n",
      "logistic evaluation:  0.33200423312445365\n",
      "average error per step:  0.3436037668679542\n",
      "iteration:  844\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "82\n",
      "average reward\n",
      "0.6357142857142857\n",
      "logistic evaluation:  0.332007782876598\n",
      "average error per step:  0.3435935773025732\n",
      "iteration:  845\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "111\n",
      "average reward\n",
      "0.6361474435196195\n",
      "logistic evaluation:  0.3316314322657459\n",
      "average error per step:  0.3432030703070621\n",
      "iteration:  846\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "61\n",
      "average reward\n",
      "0.6353919239904988\n",
      "logistic evaluation:  0.3315590187720574\n",
      "average error per step:  0.34311689315907695\n",
      "iteration:  847\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "20\n",
      "average reward\n",
      "0.6358244365361803\n",
      "logistic evaluation:  0.33157166806088906\n",
      "average error per step:  0.34311591172170064\n",
      "iteration:  848\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "445\n",
      "average reward\n",
      "0.6350710900473934\n",
      "logistic evaluation:  0.33149805483012323\n",
      "average error per step:  0.34302859818799664\n",
      "iteration:  849\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "757\n",
      "average reward\n",
      "0.6355029585798817\n",
      "logistic evaluation:  0.3312872775180574\n",
      "average error per step:  0.34280399128739136\n",
      "iteration:  850\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "105\n",
      "average reward\n",
      "0.6347517730496454\n",
      "logistic evaluation:  0.33108341895514026\n",
      "average error per step:  0.342586343815848\n",
      "iteration:  851\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "261\n",
      "average reward\n",
      "0.6340023612750886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic evaluation:  0.3309523419624369\n",
      "average error per step:  0.34244159584564365\n",
      "iteration:  852\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "597\n",
      "average reward\n",
      "0.6344339622641509\n",
      "logistic evaluation:  0.33076347853590277\n",
      "average error per step:  0.34223902570865206\n",
      "iteration:  853\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "733\n",
      "average reward\n",
      "0.6336866902237926\n",
      "logistic evaluation:  0.3308551086973805\n",
      "average error per step:  0.3423173101292022\n",
      "iteration:  854\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "819\n",
      "average reward\n",
      "0.6341176470588236\n",
      "logistic evaluation:  0.33095714539735593\n",
      "average error per step:  0.3424060445285548\n",
      "iteration:  855\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "757\n",
      "average reward\n",
      "0.6345475910693302\n",
      "logistic evaluation:  0.3306657746754689\n",
      "average error per step:  0.3421009424968981\n",
      "iteration:  856\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "745\n",
      "average reward\n",
      "0.6349765258215962\n",
      "logistic evaluation:  0.33041903486095964\n",
      "average error per step:  0.3418405555940291\n",
      "iteration:  857\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "43\n",
      "average reward\n",
      "0.634232121922626\n",
      "logistic evaluation:  0.3304630624356668\n",
      "average error per step:  0.34187130721405906\n",
      "iteration:  858\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "152\n",
      "average reward\n",
      "0.6334894613583139\n",
      "logistic evaluation:  0.3306443605039265\n",
      "average error per step:  0.342039520262843\n",
      "iteration:  859\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "47\n",
      "average reward\n",
      "0.6339181286549708\n",
      "logistic evaluation:  0.3305359453051085\n",
      "average error per step:  0.3419177132421884\n",
      "iteration:  860\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "824\n",
      "average reward\n",
      "0.633177570093458\n",
      "logistic evaluation:  0.33070692009728386\n",
      "average error per step:  0.34207565222838127\n",
      "iteration:  861\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "913\n",
      "average reward\n",
      "0.6336056009334889\n",
      "logistic evaluation:  0.33074768892493955\n",
      "average error per step:  0.3421032643042327\n",
      "iteration:  862\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "868\n",
      "average reward\n",
      "0.634032634032634\n",
      "logistic evaluation:  0.3306849373517398\n",
      "average error per step:  0.3420272664120626\n",
      "iteration:  863\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "605\n",
      "average reward\n",
      "0.6344586728754366\n",
      "logistic evaluation:  0.33085161256033924\n",
      "average error per step:  0.34218099184794853\n",
      "iteration:  864\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "889\n",
      "average reward\n",
      "0.6348837209302326\n",
      "logistic evaluation:  0.3307863786375783\n",
      "average error per step:  0.3421025697154534\n",
      "iteration:  865\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "517\n",
      "average reward\n",
      "0.6353077816492451\n",
      "logistic evaluation:  0.3306643957316316\n",
      "average error per step:  0.34196736348698203\n",
      "iteration:  866\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "113\n",
      "average reward\n",
      "0.6357308584686775\n",
      "logistic evaluation:  0.33030905691923657\n",
      "average error per step:  0.34159856242681824\n",
      "iteration:  867\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "813\n",
      "average reward\n",
      "0.6361529548088065\n",
      "logistic evaluation:  0.33042765606751395\n",
      "average error per step:  0.3417042770233548\n",
      "iteration:  868\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "755\n",
      "average reward\n",
      "0.6354166666666666\n",
      "logistic evaluation:  0.3302585772958378\n",
      "average error per step:  0.3415220119616699\n",
      "iteration:  869\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "625\n",
      "average reward\n",
      "0.6358381502890174\n",
      "logistic evaluation:  0.33010643951958285\n",
      "average error per step:  0.34135673773841607\n",
      "iteration:  870\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "270\n",
      "average reward\n",
      "0.6362586605080831\n",
      "logistic evaluation:  0.32998885113868404\n",
      "average error per step:  0.34122608282119576\n",
      "iteration:  871\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "334\n",
      "average reward\n",
      "0.6366782006920415\n",
      "logistic evaluation:  0.32977529163320624\n",
      "average error per step:  0.34099937659793605\n",
      "iteration:  872\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "312\n",
      "average reward\n",
      "0.6370967741935484\n",
      "logistic evaluation:  0.3299398429698996\n",
      "average error per step:  0.34115124498322114\n",
      "iteration:  873\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "54\n",
      "average reward\n",
      "0.6363636363636364\n",
      "logistic evaluation:  0.330008497775891\n",
      "average error per step:  0.34120713604670694\n",
      "iteration:  874\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "146\n",
      "average reward\n",
      "0.6367816091954023\n",
      "logistic evaluation:  0.32974823281198107\n",
      "average error per step:  0.3409337602095308\n",
      "iteration:  875\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "732\n",
      "average reward\n",
      "0.6371986222732492\n",
      "logistic evaluation:  0.329502455233867\n",
      "average error per step:  0.34067491828287316\n",
      "iteration:  876\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "352\n",
      "average reward\n",
      "0.6376146788990825\n",
      "logistic evaluation:  0.32917974372499303\n",
      "average error per step:  0.34033908442861344\n",
      "iteration:  877\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "594\n",
      "average reward\n",
      "0.6380297823596792\n",
      "logistic evaluation:  0.32976907509933073\n",
      "average error per step:  0.3409163633407741\n",
      "iteration:  878\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "618\n",
      "average reward\n",
      "0.6372997711670481\n",
      "logistic evaluation:  0.32987927104065357\n",
      "average error per step:  0.3410139885619373\n",
      "iteration:  879\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "447\n",
      "average reward\n",
      "0.6377142857142857\n",
      "logistic evaluation:  0.3300200938605569\n",
      "average error per step:  0.3411423041068675\n",
      "iteration:  880\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "49\n",
      "average reward\n",
      "0.636986301369863\n",
      "logistic evaluation:  0.3301185918312428\n",
      "average error per step:  0.34122827513178566\n",
      "iteration:  881\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "968\n",
      "average reward\n",
      "0.636259977194983\n",
      "logistic evaluation:  0.33026155349430764\n",
      "average error per step:  0.34135878875666953\n",
      "iteration:  882\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "192\n",
      "average reward\n",
      "0.6366742596810934\n",
      "logistic evaluation:  0.33084485231747907\n",
      "average error per step:  0.3419301670169847\n",
      "iteration:  883\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "663\n",
      "average reward\n",
      "0.6370875995449374\n",
      "logistic evaluation:  0.3304886405249496\n",
      "average error per step:  0.34156099766330905\n",
      "iteration:  884\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "967\n",
      "average reward\n",
      "0.6375\n",
      "logistic evaluation:  0.3311975724109783\n",
      "average error per step:  0.3422582062176044\n",
      "iteration:  885\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "243\n",
      "average reward\n",
      "0.637911464245176\n",
      "logistic evaluation:  0.33082570583578125\n",
      "average error per step:  0.34187342156287986\n",
      "iteration:  886\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "503\n",
      "average reward\n",
      "0.6383219954648526\n",
      "logistic evaluation:  0.3308535414012827\n",
      "average error per step:  0.34188881934038856\n",
      "iteration:  887\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "80\n",
      "average reward\n",
      "0.637599093997735\n",
      "logistic evaluation:  0.33095696290995696\n",
      "average error per step:  0.34197991632095637\n",
      "iteration:  888\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "555\n",
      "average reward\n",
      "0.6380090497737556\n",
      "logistic evaluation:  0.33061520767481634\n",
      "average error per step:  0.3416253629904935\n",
      "iteration:  889\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "420\n",
      "average reward\n",
      "0.6372881355932203\n",
      "logistic evaluation:  0.33065307249271125\n",
      "average error per step:  0.3416508855243639\n",
      "iteration:  890\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "678\n",
      "average reward\n",
      "0.6376975169300225\n",
      "logistic evaluation:  0.33068753352663155\n",
      "average error per step:  0.341673028185253\n",
      "iteration:  891\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "241\n",
      "average reward\n",
      "0.6381059751972943\n",
      "logistic evaluation:  0.3303317386168922\n",
      "average error per step:  0.3413045045554594\n",
      "iteration:  892\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "607\n",
      "average reward\n",
      "0.6385135135135135\n",
      "logistic evaluation:  0.3299808624067138\n",
      "average error per step:  0.340940933679195\n",
      "iteration:  893\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "745\n",
      "average reward\n",
      "0.6389201349831272\n",
      "logistic evaluation:  0.3300049413565859\n",
      "average error per step:  0.34095276627708204\n",
      "iteration:  894\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "562\n",
      "average reward\n",
      "0.6382022471910113\n",
      "logistic evaluation:  0.33004100944521403\n",
      "average error per step:  0.34097662882115554\n",
      "iteration:  895\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "218\n",
      "average reward\n",
      "0.6374859708193041\n",
      "logistic evaluation:  0.3301688686333121\n",
      "average error per step:  0.3410924122995465\n",
      "iteration:  896\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "811\n",
      "average reward\n",
      "0.6378923766816144\n",
      "logistic evaluation:  0.32983856676797974\n",
      "average error per step:  0.3407495503387548\n",
      "iteration:  897\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "956\n",
      "average reward\n",
      "0.6371780515117581\n",
      "logistic evaluation:  0.329754018482465\n",
      "average error per step:  0.3406527439352286\n",
      "iteration:  898\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "407\n",
      "average reward\n",
      "0.6375838926174496\n",
      "logistic evaluation:  0.329535085659388\n",
      "average error per step:  0.34042143064636554\n",
      "iteration:  899\n",
      "estimator:  [ 0.0029648  -0.00649299 -0.01061606]\n",
      "action\n",
      "242\n",
      "average reward\n",
      "0.6368715083798883\n",
      "logistic evaluation:  0.3296038956987507\n",
      "average error per step:  0.3404782078326164\n",
      "iteration:  900\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "255\n",
      "average reward\n",
      "0.6372767857142857\n",
      "logistic evaluation:  0.3304962525466465\n",
      "average error per step:  0.34043969706814586\n",
      "iteration:  901\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "287\n",
      "average reward\n",
      "0.6376811594202898\n",
      "logistic evaluation:  0.33064182098277245\n",
      "average error per step:  0.34057439105800613\n",
      "iteration:  902\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "726\n",
      "average reward\n",
      "0.6380846325167038\n",
      "logistic evaluation:  0.3306880008903794\n",
      "average error per step:  0.340609610444363\n",
      "iteration:  903\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "838\n",
      "average reward\n",
      "0.6384872080088988\n",
      "logistic evaluation:  0.33064705844059245\n",
      "average error per step:  0.3405576352681045\n",
      "iteration:  904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "935\n",
      "average reward\n",
      "0.6377777777777778\n",
      "logistic evaluation:  0.33082584923158814\n",
      "average error per step:  0.3407256608090598\n",
      "iteration:  905\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "679\n",
      "average reward\n",
      "0.6381798002219756\n",
      "logistic evaluation:  0.33102450163728836\n",
      "average error per step:  0.3409135937018631\n",
      "iteration:  906\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "776\n",
      "average reward\n",
      "0.6374722838137472\n",
      "logistic evaluation:  0.33116369179249916\n",
      "average error per step:  0.3410420223759377\n",
      "iteration:  907\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "648\n",
      "average reward\n",
      "0.6378737541528239\n",
      "logistic evaluation:  0.3308646484186025\n",
      "average error per step:  0.3407317580825732\n",
      "iteration:  908\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "649\n",
      "average reward\n",
      "0.6382743362831859\n",
      "logistic evaluation:  0.33071144654667906\n",
      "average error per step:  0.3405675206252578\n",
      "iteration:  909\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "65\n",
      "average reward\n",
      "0.6375690607734806\n",
      "logistic evaluation:  0.3308913757684769\n",
      "average error per step:  0.3407368050232308\n",
      "iteration:  910\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "324\n",
      "average reward\n",
      "0.6379690949227373\n",
      "logistic evaluation:  0.33055540223297275\n",
      "average error per step:  0.34038964313301207\n",
      "iteration:  911\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "485\n",
      "average reward\n",
      "0.6372657111356119\n",
      "logistic evaluation:  0.3304124352698902\n",
      "average error per step:  0.3402357242403323\n",
      "iteration:  912\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "485\n",
      "average reward\n",
      "0.6365638766519823\n",
      "logistic evaluation:  0.3303224089249156\n",
      "average error per step:  0.34013482803207323\n",
      "iteration:  913\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "993\n",
      "average reward\n",
      "0.636963696369637\n",
      "logistic evaluation:  0.3304393830997174\n",
      "average error per step:  0.34024118288055255\n",
      "iteration:  914\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "251\n",
      "average reward\n",
      "0.6373626373626373\n",
      "logistic evaluation:  0.3303829311549225\n",
      "average error per step:  0.3401739451023599\n",
      "iteration:  915\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "447\n",
      "average reward\n",
      "0.6377607025246982\n",
      "logistic evaluation:  0.33018460237147296\n",
      "average error per step:  0.3399646990044503\n",
      "iteration:  916\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "787\n",
      "average reward\n",
      "0.6381578947368421\n",
      "logistic evaluation:  0.3300423726873363\n",
      "average error per step:  0.33981163708634304\n",
      "iteration:  917\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "282\n",
      "average reward\n",
      "0.6374589266155531\n",
      "logistic evaluation:  0.33000274139922353\n",
      "average error per step:  0.3397613090744711\n",
      "iteration:  918\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "369\n",
      "average reward\n",
      "0.6367614879649891\n",
      "logistic evaluation:  0.3298546784027929\n",
      "average error per step:  0.3396024545413611\n",
      "iteration:  919\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "305\n",
      "average reward\n",
      "0.6371584699453552\n",
      "logistic evaluation:  0.32964330208268183\n",
      "average error per step:  0.33938024127624605\n",
      "iteration:  920\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "41\n",
      "average reward\n",
      "0.6375545851528385\n",
      "logistic evaluation:  0.32969057107651795\n",
      "average error per step:  0.33941697801986503\n",
      "iteration:  921\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "188\n",
      "average reward\n",
      "0.6379498364231189\n",
      "logistic evaluation:  0.32941920860874974\n",
      "average error per step:  0.3391347602107167\n",
      "iteration:  922\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "986\n",
      "average reward\n",
      "0.6372549019607843\n",
      "logistic evaluation:  0.32936313128738764\n",
      "average error per step:  0.3390680845933423\n",
      "iteration:  923\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "74\n",
      "average reward\n",
      "0.6376496191512514\n",
      "logistic evaluation:  0.3291394691468107\n",
      "average error per step:  0.33883366555629024\n",
      "iteration:  924\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "243\n",
      "average reward\n",
      "0.6380434782608696\n",
      "logistic evaluation:  0.32921454990411786\n",
      "average error per step:  0.3388983360152725\n",
      "iteration:  925\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "673\n",
      "average reward\n",
      "0.6384364820846905\n",
      "logistic evaluation:  0.3291700953831655\n",
      "average error per step:  0.33884336447742064\n",
      "iteration:  926\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "304\n",
      "average reward\n",
      "0.6377440347071583\n",
      "logistic evaluation:  0.32924742950781916\n",
      "average error per step:  0.33891033582132957\n",
      "iteration:  927\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "302\n",
      "average reward\n",
      "0.6370530877573131\n",
      "logistic evaluation:  0.32933847708764563\n",
      "average error per step:  0.3389910577714541\n",
      "iteration:  928\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "65\n",
      "average reward\n",
      "0.6374458874458875\n",
      "logistic evaluation:  0.3291811945011432\n",
      "average error per step:  0.33882320421160006\n",
      "iteration:  929\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "199\n",
      "average reward\n",
      "0.6378378378378379\n",
      "logistic evaluation:  0.32925603851979063\n",
      "average error per step:  0.33888774988181714\n",
      "iteration:  930\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "605\n",
      "average reward\n",
      "0.6382289416846653\n",
      "logistic evaluation:  0.3292847171115004\n",
      "average error per step:  0.3389061026318384\n",
      "iteration:  931\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "250\n",
      "average reward\n",
      "0.6386192017259978\n",
      "logistic evaluation:  0.3293129120000157\n",
      "average error per step:  0.33892399334137213\n",
      "iteration:  932\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "636\n",
      "average reward\n",
      "0.6390086206896551\n",
      "logistic evaluation:  0.3290887670425591\n",
      "average error per step:  0.33868929556599836\n",
      "iteration:  933\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "40\n",
      "average reward\n",
      "0.6383207750269106\n",
      "logistic evaluation:  0.32912968620105043\n",
      "average error per step:  0.3387199686265637\n",
      "iteration:  934\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "431\n",
      "average reward\n",
      "0.6387096774193548\n",
      "logistic evaluation:  0.3291304470021461\n",
      "average error per step:  0.3387104622738859\n",
      "iteration:  935\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "566\n",
      "average reward\n",
      "0.6390977443609023\n",
      "logistic evaluation:  0.3289809429553562\n",
      "average error per step:  0.3385505523240815\n",
      "iteration:  936\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "516\n",
      "average reward\n",
      "0.6394849785407726\n",
      "logistic evaluation:  0.32908673194819965\n",
      "average error per step:  0.33864623039771996\n",
      "iteration:  937\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "198\n",
      "average reward\n",
      "0.639871382636656\n",
      "logistic evaluation:  0.32911758709127636\n",
      "average error per step:  0.3386669162309712\n",
      "iteration:  938\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "665\n",
      "average reward\n",
      "0.6402569593147751\n",
      "logistic evaluation:  0.32892196180516026\n",
      "average error per step:  0.3384609018676421\n",
      "iteration:  939\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "838\n",
      "average reward\n",
      "0.6395721925133689\n",
      "logistic evaluation:  0.3288577215111351\n",
      "average error per step:  0.33838643454448336\n",
      "iteration:  940\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "140\n",
      "average reward\n",
      "0.6388888888888888\n",
      "logistic evaluation:  0.3290252758098152\n",
      "average error per step:  0.33854403016365847\n",
      "iteration:  941\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "923\n",
      "average reward\n",
      "0.6382070437566703\n",
      "logistic evaluation:  0.3289563436790111\n",
      "average error per step:  0.3384649092055593\n",
      "iteration:  942\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "416\n",
      "average reward\n",
      "0.6375266524520256\n",
      "logistic evaluation:  0.3289987672085895\n",
      "average error per step:  0.33849728375212607\n",
      "iteration:  943\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "898\n",
      "average reward\n",
      "0.6379126730564431\n",
      "logistic evaluation:  0.3287013283949991\n",
      "average error per step:  0.33818945686286533\n",
      "iteration:  944\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "983\n",
      "average reward\n",
      "0.6382978723404256\n",
      "logistic evaluation:  0.3292950513694526\n",
      "average error per step:  0.33877375779760116\n",
      "iteration:  945\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "436\n",
      "average reward\n",
      "0.6376195536663124\n",
      "logistic evaluation:  0.3292890696824584\n",
      "average error per step:  0.3387577394036069\n",
      "iteration:  946\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "224\n",
      "average reward\n",
      "0.638004246284501\n",
      "logistic evaluation:  0.3293765597232699\n",
      "average error per step:  0.33883531276399514\n",
      "iteration:  947\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "944\n",
      "average reward\n",
      "0.6383881230116649\n",
      "logistic evaluation:  0.3291691421817316\n",
      "average error per step:  0.3386176880729508\n",
      "iteration:  948\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "653\n",
      "average reward\n",
      "0.638771186440678\n",
      "logistic evaluation:  0.3289978286521516\n",
      "average error per step:  0.33843622701233617\n",
      "iteration:  949\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "315\n",
      "average reward\n",
      "0.6391534391534391\n",
      "logistic evaluation:  0.32874103654078585\n",
      "average error per step:  0.33816921868340294\n",
      "iteration:  950\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "819\n",
      "average reward\n",
      "0.6395348837209303\n",
      "logistic evaluation:  0.3288546575532262\n",
      "average error per step:  0.3382730348946536\n",
      "iteration:  951\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "813\n",
      "average reward\n",
      "0.6388595564941922\n",
      "logistic evaluation:  0.3287895813331871\n",
      "average error per step:  0.33819798658885064\n",
      "iteration:  952\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "449\n",
      "average reward\n",
      "0.6392405063291139\n",
      "logistic evaluation:  0.3287062609877204\n",
      "average error per step:  0.3381046959433827\n",
      "iteration:  953\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "974\n",
      "average reward\n",
      "0.6396206533192834\n",
      "logistic evaluation:  0.32887041592089794\n",
      "average error per step:  0.33825916118083893\n",
      "iteration:  954\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "682\n",
      "average reward\n",
      "0.6389473684210526\n",
      "logistic evaluation:  0.3288540306528929\n",
      "average error per step:  0.33823291728544613\n",
      "iteration:  955\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "575\n",
      "average reward\n",
      "0.6393270241850684\n",
      "logistic evaluation:  0.3287124529409853\n",
      "average error per step:  0.33808137050092646\n",
      "iteration:  956\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "371\n",
      "average reward\n",
      "0.6397058823529411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic evaluation:  0.32838643531025574\n",
      "average error per step:  0.3377452117246\n",
      "iteration:  957\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "994\n",
      "average reward\n",
      "0.640083945435467\n",
      "logistic evaluation:  0.3284600746805578\n",
      "average error per step:  0.3378091487573429\n",
      "iteration:  958\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "179\n",
      "average reward\n",
      "0.640461215932914\n",
      "logistic evaluation:  0.32902343437078907\n",
      "average error per step:  0.3383633375557302\n",
      "iteration:  959\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "854\n",
      "average reward\n",
      "0.6408376963350786\n",
      "logistic evaluation:  0.3291403923891462\n",
      "average error per step:  0.33847067832156746\n",
      "iteration:  960\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "535\n",
      "average reward\n",
      "0.641213389121339\n",
      "logistic evaluation:  0.329297677177438\n",
      "average error per step:  0.33861840790033415\n",
      "iteration:  961\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "86\n",
      "average reward\n",
      "0.6415882967607106\n",
      "logistic evaluation:  0.32910250607623653\n",
      "average error per step:  0.3384133347160691\n",
      "iteration:  962\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "521\n",
      "average reward\n",
      "0.6419624217118998\n",
      "logistic evaluation:  0.3287742172986994\n",
      "average error per step:  0.3380750260659567\n",
      "iteration:  963\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "796\n",
      "average reward\n",
      "0.6423357664233577\n",
      "logistic evaluation:  0.32869976112956206\n",
      "average error per step:  0.33799083441921146\n",
      "iteration:  964\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "769\n",
      "average reward\n",
      "0.6427083333333333\n",
      "logistic evaluation:  0.32856509597511246\n",
      "average error per step:  0.33784639152778667\n",
      "iteration:  965\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "42\n",
      "average reward\n",
      "0.6430801248699272\n",
      "logistic evaluation:  0.32824810305416985\n",
      "average error per step:  0.33751945219391805\n",
      "iteration:  966\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "497\n",
      "average reward\n",
      "0.6434511434511434\n",
      "logistic evaluation:  0.3283758340638528\n",
      "average error per step:  0.33763771776040213\n",
      "iteration:  967\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "420\n",
      "average reward\n",
      "0.6427829698857737\n",
      "logistic evaluation:  0.328510397632886\n",
      "average error per step:  0.33776284252888983\n",
      "iteration:  968\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "618\n",
      "average reward\n",
      "0.6431535269709544\n",
      "logistic evaluation:  0.32857399964001716\n",
      "average error per step:  0.3378169519297308\n",
      "iteration:  969\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "71\n",
      "average reward\n",
      "0.6435233160621762\n",
      "logistic evaluation:  0.3283696789418064\n",
      "average error per step:  0.3376028817237926\n",
      "iteration:  970\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "485\n",
      "average reward\n",
      "0.6428571428571429\n",
      "logistic evaluation:  0.3283231208199216\n",
      "average error per step:  0.3375467568380893\n",
      "iteration:  971\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "321\n",
      "average reward\n",
      "0.6432264736297828\n",
      "logistic evaluation:  0.3281960742188931\n",
      "average error per step:  0.33741008028585673\n",
      "iteration:  972\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "572\n",
      "average reward\n",
      "0.6425619834710744\n",
      "logistic evaluation:  0.3280986953745701\n",
      "average error per step:  0.3373031218274275\n",
      "iteration:  973\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "96\n",
      "average reward\n",
      "0.6429308565531475\n",
      "logistic evaluation:  0.32876601683030793\n",
      "average error per step:  0.33796166928008503\n",
      "iteration:  974\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "694\n",
      "average reward\n",
      "0.643298969072165\n",
      "logistic evaluation:  0.3287047064988512\n",
      "average error per step:  0.33789085488006443\n",
      "iteration:  975\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "332\n",
      "average reward\n",
      "0.6436663233779608\n",
      "logistic evaluation:  0.3286726513101901\n",
      "average error per step:  0.3378493451236393\n",
      "iteration:  976\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "320\n",
      "average reward\n",
      "0.6440329218106996\n",
      "logistic evaluation:  0.328677990462734\n",
      "average error per step:  0.3378452873964077\n",
      "iteration:  977\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "553\n",
      "average reward\n",
      "0.644398766700925\n",
      "logistic evaluation:  0.3286116624108259\n",
      "average error per step:  0.3377695083465615\n",
      "iteration:  978\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "801\n",
      "average reward\n",
      "0.6447638603696099\n",
      "logistic evaluation:  0.328729861009509\n",
      "average error per step:  0.33787846395205745\n",
      "iteration:  979\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "854\n",
      "average reward\n",
      "0.6451282051282051\n",
      "logistic evaluation:  0.3293228869914023\n",
      "average error per step:  0.33846275083593164\n",
      "iteration:  980\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "609\n",
      "average reward\n",
      "0.6454918032786885\n",
      "logistic evaluation:  0.3290259987823233\n",
      "average error per step:  0.33815623328802247\n",
      "iteration:  981\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "239\n",
      "average reward\n",
      "0.6458546571136131\n",
      "logistic evaluation:  0.32886771620984045\n",
      "average error per step:  0.3379884822985384\n",
      "iteration:  982\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "440\n",
      "average reward\n",
      "0.6462167689161554\n",
      "logistic evaluation:  0.32947778254236854\n",
      "average error per step:  0.3385898819307038\n",
      "iteration:  983\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "835\n",
      "average reward\n",
      "0.6465781409601634\n",
      "logistic evaluation:  0.3295920534684332\n",
      "average error per step:  0.338694999419879\n",
      "iteration:  984\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "49\n",
      "average reward\n",
      "0.6459183673469387\n",
      "logistic evaluation:  0.32963473811223026\n",
      "average error per step:  0.33872847648104637\n",
      "iteration:  985\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "992\n",
      "average reward\n",
      "0.6462793068297655\n",
      "logistic evaluation:  0.32949703822790044\n",
      "average error per step:  0.3385814045781855\n",
      "iteration:  986\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "360\n",
      "average reward\n",
      "0.6466395112016293\n",
      "logistic evaluation:  0.3295155463659056\n",
      "average error per step:  0.33859071813382513\n",
      "iteration:  987\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "389\n",
      "average reward\n",
      "0.646998982706002\n",
      "logistic evaluation:  0.32929099968641123\n",
      "average error per step:  0.33835674924719056\n",
      "iteration:  988\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "107\n",
      "average reward\n",
      "0.6473577235772358\n",
      "logistic evaluation:  0.3291647240491131\n",
      "average error per step:  0.33822116994066365\n",
      "iteration:  989\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "591\n",
      "average reward\n",
      "0.6467005076142132\n",
      "logistic evaluation:  0.3293349513367039\n",
      "average error per step:  0.3383824121740543\n",
      "iteration:  990\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "927\n",
      "average reward\n",
      "0.6470588235294118\n",
      "logistic evaluation:  0.32934566362658946\n",
      "average error per step:  0.33838399643510403\n",
      "iteration:  991\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "485\n",
      "average reward\n",
      "0.6474164133738601\n",
      "logistic evaluation:  0.3293292386505961\n",
      "average error per step:  0.33835843446840985\n",
      "iteration:  992\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "235\n",
      "average reward\n",
      "0.6467611336032388\n",
      "logistic evaluation:  0.32933933700360785\n",
      "average error per step:  0.33835944098929976\n",
      "iteration:  993\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "263\n",
      "average reward\n",
      "0.647118301314459\n",
      "logistic evaluation:  0.32939594912362813\n",
      "average error per step:  0.3384070264307041\n",
      "iteration:  994\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "658\n",
      "average reward\n",
      "0.6464646464646465\n",
      "logistic evaluation:  0.3293949407281582\n",
      "average error per step:  0.338396951550624\n",
      "iteration:  995\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "359\n",
      "average reward\n",
      "0.6468213925327951\n",
      "logistic evaluation:  0.3294595132136596\n",
      "average error per step:  0.338452541686038\n",
      "iteration:  996\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "379\n",
      "average reward\n",
      "0.6471774193548387\n",
      "logistic evaluation:  0.32947360142369975\n",
      "average error per step:  0.3384576148958147\n",
      "iteration:  997\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "630\n",
      "average reward\n",
      "0.6475327291037261\n",
      "logistic evaluation:  0.3300476081363068\n",
      "average error per step:  0.33902318629572414\n",
      "iteration:  998\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "241\n",
      "average reward\n",
      "0.647887323943662\n",
      "logistic evaluation:  0.32973311973549363\n",
      "average error per step:  0.3386993892109829\n",
      "iteration:  999\n",
      "estimator:  [ 0.00306351 -0.00644878 -0.01048289]\n",
      "action\n",
      "25\n",
      "average reward\n",
      "0.6472361809045226\n",
      "logistic evaluation:  0.32978709364466857\n",
      "average error per step:  0.33874444190337477\n"
     ]
    }
   ],
   "source": [
    "#contextual bandits takes covariates and labels\n",
    "def contextual_bandit(cov_label, mode = 'vanilla'):\n",
    "    cov = cov_label['cov']\n",
    "    labels = cov_label['label']\n",
    "    (N,d,k) = cov.shape\n",
    "    (N,k) = labels.shape\n",
    "    estimator = np.zeros(d)\n",
    "    action_list = []\n",
    "    mu = k\n",
    "    delta = 0.1\n",
    "    gamma = np.sqrt(k*N/(d*np.log(N/d) + 1./(2*delta)))\n",
    "    params = (mu,gamma)\n",
    "    rewards = []\n",
    "    mean_reward = []\n",
    "    total_x = np.zeros((N,d))\n",
    "    total_y = np.zeros(N)\n",
    "    tot_error = 0\n",
    "    for i in range(N):\n",
    "        print('iteration: ',i)\n",
    "        if i < 5:\n",
    "            action = 0\n",
    "        else: \n",
    "            arms = cov[i,:,:]\n",
    "            values = np.zeros(k)\n",
    "            for j in range(k):\n",
    "                values[j] = expit(np.inner(estimator,arms[:,j]))\n",
    "            action = select_action(values,params)\n",
    "            action_list.append(action)\n",
    "            bandit_feedback = labels[i,action]\n",
    "            rewards.append(bandit_feedback)\n",
    "            \n",
    "            #rewriting get_data\n",
    "            total_x[i,:] = arms[:,action]\n",
    "            total_y[i] = labels[i,action]\n",
    "            data_x = total_x[:i+1,:]\n",
    "            data_y = total_y[:i+1]\n",
    "\n",
    "            #bug, ols can run on one datapoint but scram can't\n",
    "            if i%100 == 0:\n",
    "                if mode == 'vanilla':\n",
    "                    estimator = logistic_reg_oracle(data_x,data_y,mode='vanilla')\n",
    "                if mode == 'robust-logistic':  \n",
    "                    estimator = logistic_reg_oracle(data_x,data_y,mode='robust-logistic')\n",
    "            print('estimator: ', estimator)\n",
    "            #estimators[action,:] = regression_oracle(data_x,data_y,mode='ols')\n",
    "            #estimators[action,:] = regression_oracle(data_x,data_y,mode='scram')\n",
    "            print('action')\n",
    "            print(action)\n",
    "            print('average reward')\n",
    "            avg_reward = sum(rewards)/len(rewards)\n",
    "            mean_reward.append(avg_reward)\n",
    "            print(avg_reward) \n",
    "            print('logistic evaluation: ', logistic_eval(data_x,data_y,estimator))\n",
    "            \n",
    "            tot_error += logistic_eval(np.array([arms[:,action]]), np.array([labels[i,action]]), estimator)\n",
    "            print('average error per step: ', tot_error/i)\n",
    "            \n",
    "    return mean_reward\n",
    "\n",
    "# def get_data(cov_label,action_list):\n",
    "#     cov = cov_label['cov']\n",
    "#     labels = cov_label['label']\n",
    "#     (N,d,k) = cov.shape\n",
    "#     (N,k) = labels.shape\n",
    "#     count = len(action_list)\n",
    "    \n",
    "#     #ensure two classes in data\n",
    "#     data_x = np.zeros((count+2,d))\n",
    "#     data_y = np.zeros(count+2)\n",
    "#     for i in range(count):\n",
    "#         data_x[i,:] = cov[i,:,action_list[i]]\n",
    "#         data_y[i] = labels[i,action_list[i]]\n",
    "#     data_x[count:count+2,:] = np.zeros((2,d))\n",
    "#     data_y[count] = 0\n",
    "#     data_y[count+1] = 1\n",
    "#     return (data_x,data_y) \n",
    "\n",
    "\n",
    "def select_action(values,params):\n",
    "    (mu,gamma) = params\n",
    "    k = mu\n",
    "    max_value = np.amax(values)\n",
    "    max_index = np.where(values == max_value)[0][0]\n",
    "    prob = np.zeros(len(values))\n",
    "    for i in range(k): \n",
    "        if i == max_index:\n",
    "            next\n",
    "        else: \n",
    "            prob[i] = 1./(mu + gamma*(max_value - values[i]))\n",
    "    prob[max_index] = 1 - np.sum(prob)\n",
    "    prob = prob/np.sum(prob)\n",
    "    #TODO roulette wheel\n",
    "    draw = np.random.rand()\n",
    "    sums = 0\n",
    "    action = 0\n",
    "    for i in range(k):\n",
    "        sums = sums + prob[i]\n",
    "        if sums >= draw:\n",
    "            action = i\n",
    "            break\n",
    "    return action\n",
    "\n",
    "mean_reward = contextual_bandit(data, mode='vanilla')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0\n",
      "iteration:  1\n",
      "iteration:  2\n",
      "iteration:  3\n",
      "iteration:  4\n",
      "iteration:  5\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "138\n",
      "average reward\n",
      "1.0\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.1\n",
      "iteration:  6\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "674\n",
      "average reward\n",
      "1.0\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.16666666666666666\n",
      "iteration:  7\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "26\n",
      "average reward\n",
      "1.0\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.21428571428571427\n",
      "iteration:  8\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "396\n",
      "average reward\n",
      "0.75\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.25\n",
      "iteration:  9\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "972\n",
      "average reward\n",
      "0.8\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.2777777777777778\n",
      "iteration:  10\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "566\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.3\n",
      "iteration:  11\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "546\n",
      "average reward\n",
      "0.5714285714285714\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.3181818181818182\n",
      "iteration:  12\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "285\n",
      "average reward\n",
      "0.625\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.3333333333333333\n",
      "iteration:  13\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "449\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.34615384615384615\n",
      "iteration:  14\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "996\n",
      "average reward\n",
      "0.6\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.35714285714285715\n",
      "iteration:  15\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "317\n",
      "average reward\n",
      "0.6363636363636364\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.36666666666666664\n",
      "iteration:  16\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "934\n",
      "average reward\n",
      "0.5833333333333334\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.375\n",
      "iteration:  17\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "827\n",
      "average reward\n",
      "0.6153846153846154\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.38235294117647056\n",
      "iteration:  18\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "630\n",
      "average reward\n",
      "0.6428571428571429\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.3888888888888889\n",
      "iteration:  19\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "83\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.39473684210526316\n",
      "iteration:  20\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "364\n",
      "average reward\n",
      "0.6875\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4\n",
      "iteration:  21\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "369\n",
      "average reward\n",
      "0.6470588235294118\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.40476190476190477\n",
      "iteration:  22\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "206\n",
      "average reward\n",
      "0.6111111111111112\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4090909090909091\n",
      "iteration:  23\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "648\n",
      "average reward\n",
      "0.5789473684210527\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.41304347826086957\n",
      "iteration:  24\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "690\n",
      "average reward\n",
      "0.55\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4166666666666667\n",
      "iteration:  25\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "477\n",
      "average reward\n",
      "0.5714285714285714\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.42\n",
      "iteration:  26\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "607\n",
      "average reward\n",
      "0.5909090909090909\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4230769230769231\n",
      "iteration:  27\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "816\n",
      "average reward\n",
      "0.6086956521739131\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.42592592592592593\n",
      "iteration:  28\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "320\n",
      "average reward\n",
      "0.625\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.42857142857142855\n",
      "iteration:  29\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "720\n",
      "average reward\n",
      "0.64\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.43103448275862066\n",
      "iteration:  30\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "84\n",
      "average reward\n",
      "0.6538461538461539\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.43333333333333335\n",
      "iteration:  31\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "90\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.43548387096774194\n",
      "iteration:  32\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "468\n",
      "average reward\n",
      "0.6785714285714286\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4375\n",
      "iteration:  33\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "149\n",
      "average reward\n",
      "0.6896551724137931\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4393939393939394\n",
      "iteration:  34\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "71\n",
      "average reward\n",
      "0.7\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4411764705882353\n",
      "iteration:  35\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "896\n",
      "average reward\n",
      "0.6774193548387096\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.44285714285714284\n",
      "iteration:  36\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "249\n",
      "average reward\n",
      "0.6875\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4444444444444444\n",
      "iteration:  37\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "673\n",
      "average reward\n",
      "0.696969696969697\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.44594594594594594\n",
      "iteration:  38\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "448\n",
      "average reward\n",
      "0.6764705882352942\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4473684210526316\n",
      "iteration:  39\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "595\n",
      "average reward\n",
      "0.6857142857142857\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.44871794871794873\n",
      "iteration:  40\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "7\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.45\n",
      "iteration:  41\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "182\n",
      "average reward\n",
      "0.6756756756756757\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.45121951219512196\n",
      "iteration:  42\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "256\n",
      "average reward\n",
      "0.6578947368421053\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4523809523809524\n",
      "iteration:  43\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "678\n",
      "average reward\n",
      "0.6410256410256411\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.45348837209302323\n",
      "iteration:  44\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "675\n",
      "average reward\n",
      "0.625\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.45454545454545453\n",
      "iteration:  45\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "963\n",
      "average reward\n",
      "0.6341463414634146\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.45555555555555555\n",
      "iteration:  46\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "167\n",
      "average reward\n",
      "0.6428571428571429\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.45652173913043476\n",
      "iteration:  47\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "121\n",
      "average reward\n",
      "0.6511627906976745\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4574468085106383\n",
      "iteration:  48\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "809\n",
      "average reward\n",
      "0.6363636363636364\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4583333333333333\n",
      "iteration:  49\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "199\n",
      "average reward\n",
      "0.6444444444444445\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.45918367346938777\n",
      "iteration:  50\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "918\n",
      "average reward\n",
      "0.6304347826086957\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.46\n",
      "iteration:  51\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "870\n",
      "average reward\n",
      "0.6382978723404256\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.46078431372549017\n",
      "iteration:  52\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "482\n",
      "average reward\n",
      "0.6458333333333334\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.46153846153846156\n",
      "iteration:  53\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "402\n",
      "average reward\n",
      "0.6530612244897959\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.46226415094339623\n",
      "iteration:  54\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "891\n",
      "average reward\n",
      "0.66\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.46296296296296297\n",
      "iteration:  55\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "963\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4636363636363636\n",
      "iteration:  56\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "873\n",
      "average reward\n",
      "0.6538461538461539\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4642857142857143\n",
      "iteration:  57\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "574\n",
      "average reward\n",
      "0.660377358490566\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4649122807017544\n",
      "iteration:  58\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "228\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.46551724137931033\n",
      "iteration:  59\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "595\n",
      "average reward\n",
      "0.6545454545454545\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4661016949152542\n",
      "iteration:  60\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "879\n",
      "average reward\n",
      "0.6607142857142857\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4666666666666667\n",
      "iteration:  61\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "991\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4672131147540984\n",
      "iteration:  62\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "201\n",
      "average reward\n",
      "0.6724137931034483\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.46774193548387094\n",
      "iteration:  63\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "455\n",
      "average reward\n",
      "0.6610169491525424\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.46825396825396826\n",
      "iteration:  64\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "47\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.46875\n",
      "iteration:  65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "598\n",
      "average reward\n",
      "0.6721311475409836\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.46923076923076923\n",
      "iteration:  66\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "946\n",
      "average reward\n",
      "0.6774193548387096\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4696969696969697\n",
      "iteration:  67\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "188\n",
      "average reward\n",
      "0.6825396825396826\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4701492537313433\n",
      "iteration:  68\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "0\n",
      "average reward\n",
      "0.6875\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47058823529411764\n",
      "iteration:  69\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "972\n",
      "average reward\n",
      "0.6923076923076923\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47101449275362317\n",
      "iteration:  70\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "231\n",
      "average reward\n",
      "0.696969696969697\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4714285714285714\n",
      "iteration:  71\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "553\n",
      "average reward\n",
      "0.6865671641791045\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47183098591549294\n",
      "iteration:  72\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "632\n",
      "average reward\n",
      "0.6911764705882353\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4722222222222222\n",
      "iteration:  73\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "414\n",
      "average reward\n",
      "0.6956521739130435\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4726027397260274\n",
      "iteration:  74\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "506\n",
      "average reward\n",
      "0.7\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47297297297297297\n",
      "iteration:  75\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "954\n",
      "average reward\n",
      "0.704225352112676\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47333333333333333\n",
      "iteration:  76\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "852\n",
      "average reward\n",
      "0.7083333333333334\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47368421052631576\n",
      "iteration:  77\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "265\n",
      "average reward\n",
      "0.6986301369863014\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.474025974025974\n",
      "iteration:  78\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "673\n",
      "average reward\n",
      "0.6891891891891891\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47435897435897434\n",
      "iteration:  79\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "346\n",
      "average reward\n",
      "0.68\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47468354430379744\n",
      "iteration:  80\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "641\n",
      "average reward\n",
      "0.6710526315789473\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.475\n",
      "iteration:  81\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "306\n",
      "average reward\n",
      "0.6753246753246753\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47530864197530864\n",
      "iteration:  82\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "847\n",
      "average reward\n",
      "0.6794871794871795\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47560975609756095\n",
      "iteration:  83\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "736\n",
      "average reward\n",
      "0.6835443037974683\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4759036144578313\n",
      "iteration:  84\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "70\n",
      "average reward\n",
      "0.675\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47619047619047616\n",
      "iteration:  85\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "535\n",
      "average reward\n",
      "0.6790123456790124\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4764705882352941\n",
      "iteration:  86\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "279\n",
      "average reward\n",
      "0.6707317073170732\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47674418604651164\n",
      "iteration:  87\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "336\n",
      "average reward\n",
      "0.6746987951807228\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47701149425287354\n",
      "iteration:  88\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "377\n",
      "average reward\n",
      "0.6785714285714286\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4772727272727273\n",
      "iteration:  89\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "117\n",
      "average reward\n",
      "0.6823529411764706\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47752808988764045\n",
      "iteration:  90\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "197\n",
      "average reward\n",
      "0.6744186046511628\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4777777777777778\n",
      "iteration:  91\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "822\n",
      "average reward\n",
      "0.6781609195402298\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47802197802197804\n",
      "iteration:  92\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "728\n",
      "average reward\n",
      "0.6818181818181818\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4782608695652174\n",
      "iteration:  93\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "737\n",
      "average reward\n",
      "0.6853932584269663\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.478494623655914\n",
      "iteration:  94\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "436\n",
      "average reward\n",
      "0.6777777777777778\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4787234042553192\n",
      "iteration:  95\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "965\n",
      "average reward\n",
      "0.6813186813186813\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4789473684210526\n",
      "iteration:  96\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "361\n",
      "average reward\n",
      "0.6847826086956522\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4791666666666667\n",
      "iteration:  97\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "447\n",
      "average reward\n",
      "0.6881720430107527\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4793814432989691\n",
      "iteration:  98\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "230\n",
      "average reward\n",
      "0.6914893617021277\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.47959183673469385\n",
      "iteration:  99\n",
      "estimator:  [0. 0. 0.]\n",
      "action\n",
      "759\n",
      "average reward\n",
      "0.6842105263157895\n",
      "logistic evaluation:  0.5\n",
      "average error per step:  0.4797979797979798\n",
      "iteration:  100\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "277\n",
      "average reward\n",
      "0.6770833333333334\n",
      "logistic evaluation:  0.3478612387313612\n",
      "average error per step:  0.4782159609698873\n",
      "iteration:  101\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "921\n",
      "average reward\n",
      "0.6701030927835051\n",
      "logistic evaluation:  0.34578167078968963\n",
      "average error per step:  0.47482516243237216\n",
      "iteration:  102\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "862\n",
      "average reward\n",
      "0.673469387755102\n",
      "logistic evaluation:  0.35054223253526084\n",
      "average error per step:  0.47836726408091285\n",
      "iteration:  103\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "78\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.3482969713332279\n",
      "average error per step:  0.4748591845026888\n",
      "iteration:  104\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "802\n",
      "average reward\n",
      "0.67\n",
      "logistic evaluation:  0.3498131578126585\n",
      "average error per step:  0.47517300534086915\n",
      "iteration:  105\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "90\n",
      "average reward\n",
      "0.6732673267326733\n",
      "logistic evaluation:  0.34809920959441315\n",
      "average error per step:  0.47224883049646704\n",
      "iteration:  106\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "783\n",
      "average reward\n",
      "0.6764705882352942\n",
      "logistic evaluation:  0.3492149789353944\n",
      "average error per step:  0.47220390312460797\n",
      "iteration:  107\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "406\n",
      "average reward\n",
      "0.6796116504854369\n",
      "logistic evaluation:  0.34725184928417835\n",
      "average error per step:  0.4690729972692758\n",
      "iteration:  108\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "271\n",
      "average reward\n",
      "0.6826923076923077\n",
      "logistic evaluation:  0.35318886026744806\n",
      "average error per step:  0.47393700698401003\n",
      "iteration:  109\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "295\n",
      "average reward\n",
      "0.6857142857142857\n",
      "logistic evaluation:  0.3522724350811977\n",
      "average error per step:  0.4719043930647064\n",
      "iteration:  110\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "881\n",
      "average reward\n",
      "0.6792452830188679\n",
      "logistic evaluation:  0.35081269522938424\n",
      "average error per step:  0.46934381959620813\n",
      "iteration:  111\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "829\n",
      "average reward\n",
      "0.6822429906542056\n",
      "logistic evaluation:  0.3561137675635782\n",
      "average error per step:  0.4736248013715496\n",
      "iteration:  112\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "242\n",
      "average reward\n",
      "0.6851851851851852\n",
      "logistic evaluation:  0.3606664922514795\n",
      "average error per step:  0.4771689697280217\n",
      "iteration:  113\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "746\n",
      "average reward\n",
      "0.6880733944954128\n",
      "logistic evaluation:  0.35778904858036276\n",
      "average error per step:  0.47323506657772213\n",
      "iteration:  114\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "960\n",
      "average reward\n",
      "0.6818181818181818\n",
      "logistic evaluation:  0.3558615284132651\n",
      "average error per step:  0.47027795397058536\n",
      "iteration:  115\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "494\n",
      "average reward\n",
      "0.6846846846846847\n",
      "logistic evaluation:  0.3535818596783583\n",
      "average error per step:  0.46698353658965924\n",
      "iteration:  116\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "210\n",
      "average reward\n",
      "0.6875\n",
      "logistic evaluation:  0.3517799486574394\n",
      "average error per step:  0.46418849119001426\n",
      "iteration:  117\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "870\n",
      "average reward\n",
      "0.6902654867256637\n",
      "logistic evaluation:  0.3492595848585356\n",
      "average error per step:  0.460685829046397\n",
      "iteration:  118\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "12\n",
      "average reward\n",
      "0.6842105263157895\n",
      "logistic evaluation:  0.34788089236430986\n",
      "average error per step:  0.4583511625124925\n",
      "iteration:  119\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "662\n",
      "average reward\n",
      "0.6869565217391305\n",
      "logistic evaluation:  0.3460041662304787\n",
      "average error per step:  0.45553034397293013\n",
      "iteration:  120\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "654\n",
      "average reward\n",
      "0.6896551724137931\n",
      "logistic evaluation:  0.3473891400956579\n",
      "average error per step:  0.45601414113913213\n",
      "iteration:  121\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "111\n",
      "average reward\n",
      "0.6923076923076923\n",
      "logistic evaluation:  0.3445915496937222\n",
      "average error per step:  0.45229570287401116\n",
      "iteration:  122\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "323\n",
      "average reward\n",
      "0.6864406779661016\n",
      "logistic evaluation:  0.3426477942918831\n",
      "average error per step:  0.4494531941231382\n",
      "iteration:  123\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "539\n",
      "average reward\n",
      "0.680672268907563\n",
      "logistic evaluation:  0.34128066318930617\n",
      "average error per step:  0.4472066115495546\n",
      "iteration:  124\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "504\n",
      "average reward\n",
      "0.675\n",
      "logistic evaluation:  0.34198897714544846\n",
      "average error per step:  0.4470663961959863\n",
      "iteration:  125\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "75\n",
      "average reward\n",
      "0.6694214876033058\n",
      "logistic evaluation:  0.34046046279851316\n",
      "average error per step:  0.44468503438187124\n",
      "iteration:  126\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "567\n",
      "average reward\n",
      "0.6721311475409836\n",
      "logistic evaluation:  0.3379333232348283\n",
      "average error per step:  0.44131065901543204\n",
      "iteration:  127\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "665\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.33621622560090436\n",
      "average error per step:  0.4387660461577717\n",
      "iteration:  128\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "711\n",
      "average reward\n",
      "0.6612903225806451\n",
      "logistic evaluation:  0.3349421546822702\n",
      "average error per step:  0.4366808510869851\n",
      "iteration:  129\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "58\n",
      "average reward\n",
      "0.656\n",
      "logistic evaluation:  0.33354146277700886\n",
      "average error per step:  0.43448062903978607\n",
      "iteration:  130\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "250\n",
      "average reward\n",
      "0.6587301587301587\n",
      "logistic evaluation:  0.3317402911920124\n",
      "average error per step:  0.4318891471636529\n",
      "iteration:  131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "981\n",
      "average reward\n",
      "0.6614173228346457\n",
      "logistic evaluation:  0.3316056811703542\n",
      "average error per step:  0.43098901450082444\n",
      "iteration:  132\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "797\n",
      "average reward\n",
      "0.6640625\n",
      "logistic evaluation:  0.32913977945571565\n",
      "average error per step:  0.4277515276722078\n",
      "iteration:  133\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "221\n",
      "average reward\n",
      "0.6589147286821705\n",
      "logistic evaluation:  0.33027626669643206\n",
      "average error per step:  0.4281551182138582\n",
      "iteration:  134\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "387\n",
      "average reward\n",
      "0.6615384615384615\n",
      "logistic evaluation:  0.3305484032364981\n",
      "average error per step:  0.42769884643319767\n",
      "iteration:  135\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "407\n",
      "average reward\n",
      "0.6641221374045801\n",
      "logistic evaluation:  0.32866101621151833\n",
      "average error per step:  0.4250778458510203\n",
      "iteration:  136\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "819\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.32834286341524244\n",
      "average error per step:  0.42404840641918723\n",
      "iteration:  137\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "23\n",
      "average reward\n",
      "0.6691729323308271\n",
      "logistic evaluation:  0.32729855892728704\n",
      "average error per step:  0.42229789866486755\n",
      "iteration:  138\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "987\n",
      "average reward\n",
      "0.6716417910447762\n",
      "logistic evaluation:  0.3258358383206562\n",
      "average error per step:  0.42013617762095984\n",
      "iteration:  139\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "321\n",
      "average reward\n",
      "0.674074074074074\n",
      "logistic evaluation:  0.3235285445063797\n",
      "average error per step:  0.417133864863413\n",
      "iteration:  140\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "935\n",
      "average reward\n",
      "0.6691176470588235\n",
      "logistic evaluation:  0.3235103830112357\n",
      "average error per step:  0.41644696421218197\n",
      "iteration:  141\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "187\n",
      "average reward\n",
      "0.6715328467153284\n",
      "logistic evaluation:  0.32154074829055135\n",
      "average error per step:  0.413804235761557\n",
      "iteration:  142\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "801\n",
      "average reward\n",
      "0.6739130434782609\n",
      "logistic evaluation:  0.31933529243310926\n",
      "average error per step:  0.41093350565532305\n",
      "iteration:  143\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "704\n",
      "average reward\n",
      "0.6762589928057554\n",
      "logistic evaluation:  0.31992405525029544\n",
      "average error per step:  0.4108858387493971\n",
      "iteration:  144\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "872\n",
      "average reward\n",
      "0.6714285714285714\n",
      "logistic evaluation:  0.3185723588987886\n",
      "average error per step:  0.4088930765655944\n",
      "iteration:  145\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "589\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.31774852171871704\n",
      "average error per step:  0.4074406562486478\n",
      "iteration:  146\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "231\n",
      "average reward\n",
      "0.6690140845070423\n",
      "logistic evaluation:  0.3173309494400094\n",
      "average error per step:  0.40640589419727824\n",
      "iteration:  147\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "445\n",
      "average reward\n",
      "0.6643356643356644\n",
      "logistic evaluation:  0.31777284982518506\n",
      "average error per step:  0.4062448487023716\n",
      "iteration:  148\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "589\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.31579384745760825\n",
      "average error per step:  0.40365469092097883\n",
      "iteration:  149\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "982\n",
      "average reward\n",
      "0.6620689655172414\n",
      "logistic evaluation:  0.3156107288522064\n",
      "average error per step:  0.40288067324128995\n",
      "iteration:  150\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "364\n",
      "average reward\n",
      "0.6643835616438356\n",
      "logistic evaluation:  0.3139251732653187\n",
      "average error per step:  0.4006020809878958\n",
      "iteration:  151\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "406\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.3129153457272341\n",
      "average error per step:  0.3990115465937803\n",
      "iteration:  152\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "494\n",
      "average reward\n",
      "0.668918918918919\n",
      "logistic evaluation:  0.31191025865370986\n",
      "average error per step:  0.39743342473117665\n",
      "iteration:  153\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "209\n",
      "average reward\n",
      "0.6711409395973155\n",
      "logistic evaluation:  0.31054260301272535\n",
      "average error per step:  0.39549785522275127\n",
      "iteration:  154\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "100\n",
      "average reward\n",
      "0.6733333333333333\n",
      "logistic evaluation:  0.3087426988724807\n",
      "average error per step:  0.3931346059114009\n",
      "iteration:  155\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "210\n",
      "average reward\n",
      "0.6754966887417219\n",
      "logistic evaluation:  0.3067676041523838\n",
      "average error per step:  0.3906023047283427\n",
      "iteration:  156\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "847\n",
      "average reward\n",
      "0.6776315789473685\n",
      "logistic evaluation:  0.3049903001689587\n",
      "average error per step:  0.3882762058438959\n",
      "iteration:  157\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "553\n",
      "average reward\n",
      "0.673202614379085\n",
      "logistic evaluation:  0.30445732509625667\n",
      "average error per step:  0.38720935254987127\n",
      "iteration:  158\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "976\n",
      "average reward\n",
      "0.6688311688311688\n",
      "logistic evaluation:  0.3037727657221886\n",
      "average error per step:  0.38599671351233683\n",
      "iteration:  159\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "642\n",
      "average reward\n",
      "0.6645161290322581\n",
      "logistic evaluation:  0.3028802782510702\n",
      "average error per step:  0.38458148116536145\n",
      "iteration:  160\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "330\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.30167594816299165\n",
      "average error per step:  0.3828589914960181\n",
      "iteration:  161\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "414\n",
      "average reward\n",
      "0.6687898089171974\n",
      "logistic evaluation:  0.3008147884789825\n",
      "average error per step:  0.38148824048892177\n",
      "iteration:  162\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "819\n",
      "average reward\n",
      "0.6708860759493671\n",
      "logistic evaluation:  0.30118605301068363\n",
      "average error per step:  0.38136381250532514\n",
      "iteration:  163\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "840\n",
      "average reward\n",
      "0.6729559748427673\n",
      "logistic evaluation:  0.30327890176146804\n",
      "average error per step:  0.38297761272393865\n",
      "iteration:  164\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "484\n",
      "average reward\n",
      "0.675\n",
      "logistic evaluation:  0.3073113013732593\n",
      "average error per step:  0.38654863238846965\n",
      "iteration:  165\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "693\n",
      "average reward\n",
      "0.6770186335403726\n",
      "logistic evaluation:  0.3077203696593799\n",
      "average error per step:  0.3864799536277473\n",
      "iteration:  166\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "287\n",
      "average reward\n",
      "0.6790123456790124\n",
      "logistic evaluation:  0.3086034759142426\n",
      "average error per step:  0.3868939244746972\n",
      "iteration:  167\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "930\n",
      "average reward\n",
      "0.6809815950920245\n",
      "logistic evaluation:  0.3087393634254297\n",
      "average error per step:  0.38656182060235583\n",
      "iteration:  168\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "139\n",
      "average reward\n",
      "0.676829268292683\n",
      "logistic evaluation:  0.3074627612393615\n",
      "average error per step:  0.38481439068198414\n",
      "iteration:  169\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "714\n",
      "average reward\n",
      "0.6787878787878788\n",
      "logistic evaluation:  0.3070967221883385\n",
      "average error per step:  0.383988483770052\n",
      "iteration:  170\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "12\n",
      "average reward\n",
      "0.6807228915662651\n",
      "logistic evaluation:  0.3108643178966524\n",
      "average error per step:  0.3873259373261695\n",
      "iteration:  171\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "668\n",
      "average reward\n",
      "0.6826347305389222\n",
      "logistic evaluation:  0.3093767167604136\n",
      "average error per step:  0.3853824927948093\n",
      "iteration:  172\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "160\n",
      "average reward\n",
      "0.6845238095238095\n",
      "logistic evaluation:  0.30883241244456744\n",
      "average error per step:  0.38439312987227564\n",
      "iteration:  173\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "650\n",
      "average reward\n",
      "0.6804733727810651\n",
      "logistic evaluation:  0.30850680522507334\n",
      "average error per step:  0.3836288733773642\n",
      "iteration:  174\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "110\n",
      "average reward\n",
      "0.6823529411764706\n",
      "logistic evaluation:  0.30676641524466564\n",
      "average error per step:  0.3814467451318261\n",
      "iteration:  175\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "637\n",
      "average reward\n",
      "0.6842105263157895\n",
      "logistic evaluation:  0.3050865477021524\n",
      "average error per step:  0.3793305336040004\n",
      "iteration:  176\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "169\n",
      "average reward\n",
      "0.6802325581395349\n",
      "logistic evaluation:  0.30651694601413226\n",
      "average error per step:  0.3803472183501288\n",
      "iteration:  177\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "966\n",
      "average reward\n",
      "0.6763005780346821\n",
      "logistic evaluation:  0.306715724572153\n",
      "average error per step:  0.38012999976816103\n",
      "iteration:  178\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "834\n",
      "average reward\n",
      "0.6781609195402298\n",
      "logistic evaluation:  0.3050144809446085\n",
      "average error per step:  0.37800675884385493\n",
      "iteration:  179\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "252\n",
      "average reward\n",
      "0.68\n",
      "logistic evaluation:  0.30431282843002866\n",
      "average error per step:  0.3768934083940023\n",
      "iteration:  180\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "607\n",
      "average reward\n",
      "0.6818181818181818\n",
      "logistic evaluation:  0.3060652229286546\n",
      "average error per step:  0.3782523129733764\n",
      "iteration:  181\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "756\n",
      "average reward\n",
      "0.6836158192090396\n",
      "logistic evaluation:  0.30522635238558526\n",
      "average error per step:  0.3770099840845181\n",
      "iteration:  182\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "945\n",
      "average reward\n",
      "0.6797752808988764\n",
      "logistic evaluation:  0.3059750195275587\n",
      "average error per step:  0.37736834922343127\n",
      "iteration:  183\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "558\n",
      "average reward\n",
      "0.6759776536312849\n",
      "logistic evaluation:  0.306778997742438\n",
      "average error per step:  0.3777865932772123\n",
      "iteration:  184\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "788\n",
      "average reward\n",
      "0.6777777777777778\n",
      "logistic evaluation:  0.30746831072070213\n",
      "average error per step:  0.37809374167636495\n",
      "iteration:  185\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "367\n",
      "average reward\n",
      "0.6795580110497238\n",
      "logistic evaluation:  0.3072539203384394\n",
      "average error per step:  0.3774964333409243\n",
      "iteration:  186\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "941\n",
      "average reward\n",
      "0.6813186813186813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic evaluation:  0.3109114629718021\n",
      "average error per step:  0.38079599226262495\n",
      "iteration:  187\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "9\n",
      "average reward\n",
      "0.6775956284153005\n",
      "logistic evaluation:  0.31064707859357404\n",
      "average error per step:  0.38015648000381375\n",
      "iteration:  188\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "836\n",
      "average reward\n",
      "0.6793478260869565\n",
      "logistic evaluation:  0.30972580559969004\n",
      "average error per step:  0.3788605757630992\n",
      "iteration:  189\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "728\n",
      "average reward\n",
      "0.6810810810810811\n",
      "logistic evaluation:  0.31017783042755664\n",
      "average error per step:  0.3789491998219948\n",
      "iteration:  190\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "961\n",
      "average reward\n",
      "0.6827956989247311\n",
      "logistic evaluation:  0.30857689113842074\n",
      "average error per step:  0.3769778799608401\n",
      "iteration:  191\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "795\n",
      "average reward\n",
      "0.6844919786096256\n",
      "logistic evaluation:  0.30792048427859525\n",
      "average error per step:  0.37595991605555784\n",
      "iteration:  192\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "40\n",
      "average reward\n",
      "0.6808510638297872\n",
      "logistic evaluation:  0.3076251378180203\n",
      "average error per step:  0.37530865929166235\n",
      "iteration:  193\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "338\n",
      "average reward\n",
      "0.6825396825396826\n",
      "logistic evaluation:  0.30903026927803323\n",
      "average error per step:  0.37637037940445445\n",
      "iteration:  194\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "214\n",
      "average reward\n",
      "0.6842105263157895\n",
      "logistic evaluation:  0.3091636740411026\n",
      "average error per step:  0.37615735785121784\n",
      "iteration:  195\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "561\n",
      "average reward\n",
      "0.680628272251309\n",
      "logistic evaluation:  0.3090853590757286\n",
      "average error per step:  0.3757350839177644\n",
      "iteration:  196\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "530\n",
      "average reward\n",
      "0.6822916666666666\n",
      "logistic evaluation:  0.3086639342588953\n",
      "average error per step:  0.3749714593577736\n",
      "iteration:  197\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "562\n",
      "average reward\n",
      "0.6839378238341969\n",
      "logistic evaluation:  0.3082786735541764\n",
      "average error per step:  0.37424765659313786\n",
      "iteration:  198\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "556\n",
      "average reward\n",
      "0.6855670103092784\n",
      "logistic evaluation:  0.3067489783361129\n",
      "average error per step:  0.37237705895963485\n",
      "iteration:  199\n",
      "estimator:  [-0.00041743 -0.01169471 -0.01387338]\n",
      "action\n",
      "489\n",
      "average reward\n",
      "0.6871794871794872\n",
      "logistic evaluation:  0.3060895425714199\n",
      "average error per step:  0.37138452009751355\n",
      "iteration:  200\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "823\n",
      "average reward\n",
      "0.6887755102040817\n",
      "logistic evaluation:  0.15251264411783622\n",
      "average error per step:  0.36952770080599145\n",
      "iteration:  201\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "248\n",
      "average reward\n",
      "0.6903553299492385\n",
      "logistic evaluation:  0.151757631028244\n",
      "average error per step:  0.3676892545334254\n",
      "iteration:  202\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "277\n",
      "average reward\n",
      "0.6868686868686869\n",
      "logistic evaluation:  0.15133459678998257\n",
      "average error per step:  0.3661951576330677\n",
      "iteration:  203\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "869\n",
      "average reward\n",
      "0.6884422110552764\n",
      "logistic evaluation:  0.15118120852771003\n",
      "average error per step:  0.36498258735549777\n",
      "iteration:  204\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "339\n",
      "average reward\n",
      "0.69\n",
      "logistic evaluation:  0.15044374222865634\n",
      "average error per step:  0.36319346005092035\n",
      "iteration:  205\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "271\n",
      "average reward\n",
      "0.6865671641791045\n",
      "logistic evaluation:  0.14973499549457575\n",
      "average error per step:  0.3614434525141259\n",
      "iteration:  206\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "167\n",
      "average reward\n",
      "0.6881188118811881\n",
      "logistic evaluation:  0.14915740022387897\n",
      "average error per step:  0.3598353424264861\n",
      "iteration:  207\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "737\n",
      "average reward\n",
      "0.6847290640394089\n",
      "logistic evaluation:  0.1493244254480358\n",
      "average error per step:  0.35898540669905626\n",
      "iteration:  208\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "929\n",
      "average reward\n",
      "0.6862745098039216\n",
      "logistic evaluation:  0.14860998952454396\n",
      "average error per step:  0.3572595505006869\n",
      "iteration:  209\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "724\n",
      "average reward\n",
      "0.6878048780487804\n",
      "logistic evaluation:  0.14790232304947118\n",
      "average error per step:  0.35555017480335954\n",
      "iteration:  210\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "757\n",
      "average reward\n",
      "0.6893203883495146\n",
      "logistic evaluation:  0.14720136417246446\n",
      "average error per step:  0.35385707873287237\n",
      "iteration:  211\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "877\n",
      "average reward\n",
      "0.6908212560386473\n",
      "logistic evaluation:  0.14650844536493238\n",
      "average error per step:  0.3521814649804685\n",
      "iteration:  212\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "439\n",
      "average reward\n",
      "0.6923076923076923\n",
      "logistic evaluation:  0.14582061282695827\n",
      "average error per step:  0.3505202321964873\n",
      "iteration:  213\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "89\n",
      "average reward\n",
      "0.69377990430622\n",
      "logistic evaluation:  0.14546059337533246\n",
      "average error per step:  0.34919749143584206\n",
      "iteration:  214\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "423\n",
      "average reward\n",
      "0.6952380952380952\n",
      "logistic evaluation:  0.14478844113311512\n",
      "average error per step:  0.34757015671557456\n",
      "iteration:  215\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "250\n",
      "average reward\n",
      "0.6966824644549763\n",
      "logistic evaluation:  0.14411812624256473\n",
      "average error per step:  0.3459535533111962\n",
      "iteration:  216\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "360\n",
      "average reward\n",
      "0.6981132075471698\n",
      "logistic evaluation:  0.14361828289203707\n",
      "average error per step:  0.3445169725976168\n",
      "iteration:  217\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "937\n",
      "average reward\n",
      "0.6995305164319249\n",
      "logistic evaluation:  0.14400800446920117\n",
      "average error per step:  0.34398268971335966\n",
      "iteration:  218\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "533\n",
      "average reward\n",
      "0.7009345794392523\n",
      "logistic evaluation:  0.1434600915806792\n",
      "average error per step:  0.3425149483930364\n",
      "iteration:  219\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "148\n",
      "average reward\n",
      "0.7023255813953488\n",
      "logistic evaluation:  0.1428080073055503\n",
      "average error per step:  0.3409509602773254\n",
      "iteration:  220\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "682\n",
      "average reward\n",
      "0.7037037037037037\n",
      "logistic evaluation:  0.14216192205905573\n",
      "average error per step:  0.33940128849347506\n",
      "iteration:  221\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "105\n",
      "average reward\n",
      "0.7050691244239631\n",
      "logistic evaluation:  0.14602597303598377\n",
      "average error per step:  0.3423903380429936\n",
      "iteration:  222\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "960\n",
      "average reward\n",
      "0.7018348623853211\n",
      "logistic evaluation:  0.14700177995387576\n",
      "average error per step:  0.3424860163208445\n",
      "iteration:  223\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "878\n",
      "average reward\n",
      "0.7031963470319634\n",
      "logistic evaluation:  0.14641109699087626\n",
      "average error per step:  0.341016073629908\n",
      "iteration:  224\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "708\n",
      "average reward\n",
      "0.7045454545454546\n",
      "logistic evaluation:  0.14576038100425245\n",
      "average error per step:  0.3394936804440625\n",
      "iteration:  225\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "922\n",
      "average reward\n",
      "0.7058823529411765\n",
      "logistic evaluation:  0.14954008458911056\n",
      "average error per step:  0.3424291458251208\n",
      "iteration:  226\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "351\n",
      "average reward\n",
      "0.7027027027027027\n",
      "logistic evaluation:  0.14916296106040924\n",
      "average error per step:  0.3411968621868411\n",
      "iteration:  227\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "303\n",
      "average reward\n",
      "0.7040358744394619\n",
      "logistic evaluation:  0.14861947008210308\n",
      "average error per step:  0.33980501265300744\n",
      "iteration:  228\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "162\n",
      "average reward\n",
      "0.7053571428571429\n",
      "logistic evaluation:  0.14821118108627784\n",
      "average error per step:  0.3385563998345211\n",
      "iteration:  229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "90\n",
      "average reward\n",
      "0.7022222222222222\n",
      "logistic evaluation:  0.14767026417170162\n",
      "average error per step:  0.33718191900875355\n",
      "iteration:  230\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "992\n",
      "average reward\n",
      "0.6991150442477876\n",
      "logistic evaluation:  0.14779261006051916\n",
      "average error per step:  0.3364808331195353\n",
      "iteration:  231\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "45\n",
      "average reward\n",
      "0.7004405286343612\n",
      "logistic evaluation:  0.1471563788352053\n",
      "average error per step:  0.3350250155120381\n",
      "iteration:  232\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "601\n",
      "average reward\n",
      "0.6973684210526315\n",
      "logistic evaluation:  0.14652495004662247\n",
      "average error per step:  0.33358108644127676\n",
      "iteration:  233\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "368\n",
      "average reward\n",
      "0.6943231441048034\n",
      "logistic evaluation:  0.1461281344366301\n",
      "average error per step:  0.33237975172396833\n",
      "iteration:  234\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "565\n",
      "average reward\n",
      "0.691304347826087\n",
      "logistic evaluation:  0.1456932663578646\n",
      "average error per step:  0.3311470781521853\n",
      "iteration:  235\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "183\n",
      "average reward\n",
      "0.6926406926406926\n",
      "logistic evaluation:  0.14508236913115083\n",
      "average error per step:  0.32974441620623307\n",
      "iteration:  236\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "153\n",
      "average reward\n",
      "0.6939655172413793\n",
      "logistic evaluation:  0.14447026044845243\n",
      "average error per step:  0.32834724754151023\n",
      "iteration:  237\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "99\n",
      "average reward\n",
      "0.6909871244635193\n",
      "logistic evaluation:  0.14386373568721703\n",
      "average error per step:  0.32696231133785164\n",
      "iteration:  238\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "708\n",
      "average reward\n",
      "0.6923076923076923\n",
      "logistic evaluation:  0.1432618066359056\n",
      "average error per step:  0.325588531426448\n",
      "iteration:  239\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "247\n",
      "average reward\n",
      "0.6936170212765957\n",
      "logistic evaluation:  0.14310383298504095\n",
      "average error per step:  0.3246670234724812\n",
      "iteration:  240\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "489\n",
      "average reward\n",
      "0.6949152542372882\n",
      "logistic evaluation:  0.1425100423351232\n",
      "average error per step:  0.32331424540115783\n",
      "iteration:  241\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "355\n",
      "average reward\n",
      "0.6919831223628692\n",
      "logistic evaluation:  0.14341658046772643\n",
      "average error per step:  0.3234743201937883\n",
      "iteration:  242\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "311\n",
      "average reward\n",
      "0.6890756302521008\n",
      "logistic evaluation:  0.14288131873276094\n",
      "average error per step:  0.3221928063866698\n",
      "iteration:  243\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "585\n",
      "average reward\n",
      "0.6903765690376569\n",
      "logistic evaluation:  0.14639410021333552\n",
      "average error per step:  0.3249821364015105\n",
      "iteration:  244\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "477\n",
      "average reward\n",
      "0.6916666666666667\n",
      "logistic evaluation:  0.1457966077661893\n",
      "average error per step:  0.32365027703372773\n",
      "iteration:  245\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "539\n",
      "average reward\n",
      "0.6929460580912863\n",
      "logistic evaluation:  0.14520393864468606\n",
      "average error per step:  0.3223292555106365\n",
      "iteration:  246\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "51\n",
      "average reward\n",
      "0.6942148760330579\n",
      "logistic evaluation:  0.14461665473312035\n",
      "average error per step:  0.3210195626528207\n",
      "iteration:  247\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "951\n",
      "average reward\n",
      "0.6954732510288066\n",
      "logistic evaluation:  0.14407086933186\n",
      "average error per step:  0.3197573857806253\n",
      "iteration:  248\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "872\n",
      "average reward\n",
      "0.6926229508196722\n",
      "logistic evaluation:  0.14349891251218172\n",
      "average error per step:  0.318474709310671\n",
      "iteration:  249\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "523\n",
      "average reward\n",
      "0.6938775510204082\n",
      "logistic evaluation:  0.14692489406752499\n",
      "average error per step:  0.3212117357847165\n",
      "iteration:  250\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "399\n",
      "average reward\n",
      "0.6910569105691057\n",
      "logistic evaluation:  0.14637592536510632\n",
      "average error per step:  0.31996342384061943\n",
      "iteration:  251\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "739\n",
      "average reward\n",
      "0.6923076923076923\n",
      "logistic evaluation:  0.1467717585840781\n",
      "average error per step:  0.31966925042510297\n",
      "iteration:  252\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "609\n",
      "average reward\n",
      "0.6935483870967742\n",
      "logistic evaluation:  0.14635158669698967\n",
      "average error per step:  0.31856131003115695\n",
      "iteration:  253\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "617\n",
      "average reward\n",
      "0.6947791164658634\n",
      "logistic evaluation:  0.145775421259897\n",
      "average error per step:  0.3173021964171028\n",
      "iteration:  254\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "119\n",
      "average reward\n",
      "0.696\n",
      "logistic evaluation:  0.145471470380018\n",
      "average error per step:  0.31632174661581797\n",
      "iteration:  255\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "724\n",
      "average reward\n",
      "0.6972111553784861\n",
      "logistic evaluation:  0.14880944754851405\n",
      "average error per step:  0.31900281280757947\n",
      "iteration:  256\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "154\n",
      "average reward\n",
      "0.6944444444444444\n",
      "logistic evaluation:  0.14824464618637187\n",
      "average error per step:  0.31777098735707315\n",
      "iteration:  257\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "64\n",
      "average reward\n",
      "0.6956521739130435\n",
      "logistic evaluation:  0.1476700552687876\n",
      "average error per step:  0.3165345251084061\n",
      "iteration:  258\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "119\n",
      "average reward\n",
      "0.6968503937007874\n",
      "logistic evaluation:  0.14715743738777756\n",
      "average error per step:  0.3153654068873936\n",
      "iteration:  259\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "915\n",
      "average reward\n",
      "0.6941176470588235\n",
      "logistic evaluation:  0.14814780345946543\n",
      "average error per step:  0.31571014514661844\n",
      "iteration:  260\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "591\n",
      "average reward\n",
      "0.69140625\n",
      "logistic evaluation:  0.14764623406249683\n",
      "average error per step:  0.31456217609163395\n",
      "iteration:  261\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "286\n",
      "average reward\n",
      "0.688715953307393\n",
      "logistic evaluation:  0.14709957624714085\n",
      "average error per step:  0.3133738991197857\n",
      "iteration:  262\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "699\n",
      "average reward\n",
      "0.689922480620155\n",
      "logistic evaluation:  0.14654026227019637\n",
      "average error per step:  0.31217781553654506\n",
      "iteration:  263\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "966\n",
      "average reward\n",
      "0.6911196911196911\n",
      "logistic evaluation:  0.14600669249110704\n",
      "average error per step:  0.311012416392264\n",
      "iteration:  264\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "773\n",
      "average reward\n",
      "0.6923076923076923\n",
      "logistic evaluation:  0.14922930794724729\n",
      "average error per step:  0.31362221704368826\n",
      "iteration:  265\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "335\n",
      "average reward\n",
      "0.6896551724137931\n",
      "logistic evaluation:  0.14894043580735902\n",
      "average error per step:  0.31271190421988937\n",
      "iteration:  266\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "57\n",
      "average reward\n",
      "0.6908396946564885\n",
      "logistic evaluation:  0.14838260645977738\n",
      "average error per step:  0.31153629555742013\n",
      "iteration:  267\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "684\n",
      "average reward\n",
      "0.688212927756654\n",
      "logistic evaluation:  0.1478308868228579\n",
      "average error per step:  0.31037144704883557\n",
      "iteration:  268\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "34\n",
      "average reward\n",
      "0.6893939393939394\n",
      "logistic evaluation:  0.14728146732926142\n",
      "average error per step:  0.30921348285479294\n",
      "iteration:  269\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "928\n",
      "average reward\n",
      "0.6867924528301886\n",
      "logistic evaluation:  0.1475039763243092\n",
      "average error per step:  0.30883484126794297\n",
      "iteration:  270\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "52\n",
      "average reward\n",
      "0.6879699248120301\n",
      "logistic evaluation:  0.14726253799379693\n",
      "average error per step:  0.30799498699937833\n",
      "iteration:  271\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "690\n",
      "average reward\n",
      "0.6853932584269663\n",
      "logistic evaluation:  0.1467219665508345\n",
      "average error per step:  0.30685931215992684\n",
      "iteration:  272\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "430\n",
      "average reward\n",
      "0.6865671641791045\n",
      "logistic evaluation:  0.14618452393116768\n",
      "average error per step:  0.305731153407066\n",
      "iteration:  273\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "395\n",
      "average reward\n",
      "0.6877323420074349\n",
      "logistic evaluation:  0.145651003770835\n",
      "average error per step:  0.3046112590722417\n",
      "iteration:  274\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "227\n",
      "average reward\n",
      "0.6851851851851852\n",
      "logistic evaluation:  0.14548383860681574\n",
      "average error per step:  0.3038633368992245\n",
      "iteration:  275\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "330\n",
      "average reward\n",
      "0.6863468634686347\n",
      "logistic evaluation:  0.14495971833871046\n",
      "average error per step:  0.3027613852908992\n",
      "iteration:  276\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "27\n",
      "average reward\n",
      "0.6875\n",
      "logistic evaluation:  0.14452909578085468\n",
      "average error per step:  0.3017574573362679\n",
      "iteration:  277\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "90\n",
      "average reward\n",
      "0.684981684981685\n",
      "logistic evaluation:  0.14403805470874476\n",
      "average error per step:  0.3006970321391489\n",
      "iteration:  278\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "37\n",
      "average reward\n",
      "0.6861313868613139\n",
      "logistic evaluation:  0.14442633654594\n",
      "average error per step:  0.300523189172052\n",
      "iteration:  279\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "195\n",
      "average reward\n",
      "0.6872727272727273\n",
      "logistic evaluation:  0.14391278986715564\n",
      "average error per step:  0.29944831489719276\n",
      "iteration:  280\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "337\n",
      "average reward\n",
      "0.6847826086956522\n",
      "logistic evaluation:  0.1434007480785426\n",
      "average error per step:  0.29837896036994166\n",
      "iteration:  281\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "337\n",
      "average reward\n",
      "0.6859205776173285\n",
      "logistic evaluation:  0.14294965679335386\n",
      "average error per step:  0.2973747398905302\n",
      "iteration:  282\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "496\n",
      "average reward\n",
      "0.6870503597122302\n",
      "logistic evaluation:  0.14244453433124324\n",
      "average error per step:  0.29632021953636534\n",
      "iteration:  283\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "867\n",
      "average reward\n",
      "0.6845878136200717\n",
      "logistic evaluation:  0.141943050235417\n",
      "average error per step:  0.2952732330755181\n",
      "iteration:  284\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "424\n",
      "average reward\n",
      "0.6857142857142857\n",
      "logistic evaluation:  0.1421705260267031\n",
      "average error per step:  0.29496161482789995\n",
      "iteration:  285\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "114\n",
      "average reward\n",
      "0.6868327402135231\n",
      "logistic evaluation:  0.1416808549543403\n",
      "average error per step:  0.2939341165279106\n",
      "iteration:  286\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "735\n",
      "average reward\n",
      "0.6879432624113475\n",
      "logistic evaluation:  0.14329186913348235\n",
      "average error per step:  0.2950184095623169\n",
      "iteration:  287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "717\n",
      "average reward\n",
      "0.6855123674911661\n",
      "logistic evaluation:  0.14279549898328506\n",
      "average error per step:  0.2939916459954679\n",
      "iteration:  288\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "120\n",
      "average reward\n",
      "0.6866197183098591\n",
      "logistic evaluation:  0.14230139691092536\n",
      "average error per step:  0.2929708416693424\n",
      "iteration:  289\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "460\n",
      "average reward\n",
      "0.6877192982456141\n",
      "logistic evaluation:  0.14525897743846491\n",
      "average error per step:  0.2954173084798201\n",
      "iteration:  290\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "984\n",
      "average reward\n",
      "0.6888111888111889\n",
      "logistic evaluation:  0.14480999734778463\n",
      "average error per step:  0.29444899283351217\n",
      "iteration:  291\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "750\n",
      "average reward\n",
      "0.6898954703832753\n",
      "logistic evaluation:  0.14487563097731634\n",
      "average error per step:  0.2940006286559779\n",
      "iteration:  292\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "575\n",
      "average reward\n",
      "0.6909722222222222\n",
      "logistic evaluation:  0.14446606736755324\n",
      "average error per step:  0.29307896038426823\n",
      "iteration:  293\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "688\n",
      "average reward\n",
      "0.6920415224913494\n",
      "logistic evaluation:  0.14737604234995194\n",
      "average error per step:  0.29549165578293207\n",
      "iteration:  294\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "303\n",
      "average reward\n",
      "0.6931034482758621\n",
      "logistic evaluation:  0.1469028626861913\n",
      "average error per step:  0.29451307206101923\n",
      "iteration:  295\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "343\n",
      "average reward\n",
      "0.6941580756013745\n",
      "logistic evaluation:  0.1497847223160297\n",
      "average error per step:  0.2969043271154509\n",
      "iteration:  296\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "126\n",
      "average reward\n",
      "0.6952054794520548\n",
      "logistic evaluation:  0.14928039665192577\n",
      "average error per step:  0.29590127195653776\n",
      "iteration:  297\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "10\n",
      "average reward\n",
      "0.6928327645051194\n",
      "logistic evaluation:  0.14910412090946884\n",
      "average error per step:  0.29523072971223885\n",
      "iteration:  298\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "175\n",
      "average reward\n",
      "0.6938775510204082\n",
      "logistic evaluation:  0.1486547655780934\n",
      "average error per step:  0.29428950872940657\n",
      "iteration:  299\n",
      "estimator:  [ 0.01560379 -0.04555082 -0.06367874]\n",
      "action\n",
      "829\n",
      "average reward\n",
      "0.6949152542372882\n",
      "logistic evaluation:  0.1514925824276984\n",
      "average error per step:  0.2966497438856948\n",
      "iteration:  300\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "988\n",
      "average reward\n",
      "0.6925675675675675\n",
      "logistic evaluation:  0.20476410314284024\n",
      "average error per step:  0.29610472826069256\n",
      "iteration:  301\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "362\n",
      "average reward\n",
      "0.6902356902356902\n",
      "logistic evaluation:  0.2042381625272198\n",
      "average error per step:  0.2952735831077516\n",
      "iteration:  302\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "663\n",
      "average reward\n",
      "0.6912751677852349\n",
      "logistic evaluation:  0.20356412793027973\n",
      "average error per step:  0.2942958748181709\n",
      "iteration:  303\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "395\n",
      "average reward\n",
      "0.6889632107023411\n",
      "logistic evaluation:  0.20297883432892386\n",
      "average error per step:  0.29340920484556343\n",
      "iteration:  304\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "443\n",
      "average reward\n",
      "0.69\n",
      "logistic evaluation:  0.20326598349380784\n",
      "average error per step:  0.29339983025600086\n",
      "iteration:  305\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "178\n",
      "average reward\n",
      "0.6910299003322259\n",
      "logistic evaluation:  0.20271333869042207\n",
      "average error per step:  0.2925498526933837\n",
      "iteration:  306\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "892\n",
      "average reward\n",
      "0.6920529801324503\n",
      "logistic evaluation:  0.20274345785952025\n",
      "average error per step:  0.2922864869120444\n",
      "iteration:  307\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "679\n",
      "average reward\n",
      "0.6897689768976898\n",
      "logistic evaluation:  0.20288517284142185\n",
      "average error per step:  0.29213699240185925\n",
      "iteration:  308\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "279\n",
      "average reward\n",
      "0.6907894736842105\n",
      "logistic evaluation:  0.20222859341486668\n",
      "average error per step:  0.2911885025889827\n",
      "iteration:  309\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "623\n",
      "average reward\n",
      "0.6918032786885245\n",
      "logistic evaluation:  0.2019443850725519\n",
      "average error per step:  0.2906154783323753\n",
      "iteration:  310\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "897\n",
      "average reward\n",
      "0.6928104575163399\n",
      "logistic evaluation:  0.20129506974112116\n",
      "average error per step:  0.2896780326506502\n",
      "iteration:  311\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "702\n",
      "average reward\n",
      "0.6938110749185668\n",
      "logistic evaluation:  0.20064992571053203\n",
      "average error per step:  0.2887466246106073\n",
      "iteration:  312\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "684\n",
      "average reward\n",
      "0.6948051948051948\n",
      "logistic evaluation:  0.20006094982499154\n",
      "average error per step:  0.2878733997674206\n",
      "iteration:  313\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "948\n",
      "average reward\n",
      "0.6957928802588996\n",
      "logistic evaluation:  0.2002117093277878\n",
      "average error per step:  0.28774408997168766\n",
      "iteration:  314\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "710\n",
      "average reward\n",
      "0.6935483870967742\n",
      "logistic evaluation:  0.20083683527768323\n",
      "average error per step:  0.28809244122510536\n",
      "iteration:  315\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "533\n",
      "average reward\n",
      "0.6945337620578779\n",
      "logistic evaluation:  0.20021002480296932\n",
      "average error per step:  0.28718663895222596\n",
      "iteration:  316\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "866\n",
      "average reward\n",
      "0.6955128205128205\n",
      "logistic evaluation:  0.20273302107086005\n",
      "average error per step:  0.289442376935682\n",
      "iteration:  317\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "530\n",
      "average reward\n",
      "0.6932907348242812\n",
      "logistic evaluation:  0.2032414357389956\n",
      "average error per step:  0.289678864344522\n",
      "iteration:  318\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "169\n",
      "average reward\n",
      "0.6910828025477707\n",
      "logistic evaluation:  0.20316392418620824\n",
      "average error per step:  0.28932929323148837\n",
      "iteration:  319\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "273\n",
      "average reward\n",
      "0.692063492063492\n",
      "logistic evaluation:  0.20252903809342532\n",
      "average error per step:  0.28842230602541996\n",
      "iteration:  320\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "197\n",
      "average reward\n",
      "0.6930379746835443\n",
      "logistic evaluation:  0.2023568795922818\n",
      "average error per step:  0.2879811930666729\n",
      "iteration:  321\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "358\n",
      "average reward\n",
      "0.694006309148265\n",
      "logistic evaluation:  0.20185160090547025\n",
      "average error per step:  0.28720759789337785\n",
      "iteration:  322\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "448\n",
      "average reward\n",
      "0.6918238993710691\n",
      "logistic evaluation:  0.2014392697891888\n",
      "average error per step:  0.28652890550969207\n",
      "iteration:  323\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "321\n",
      "average reward\n",
      "0.6927899686520376\n",
      "logistic evaluation:  0.20127704357948514\n",
      "average error per step:  0.28610274164695376\n",
      "iteration:  324\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "235\n",
      "average reward\n",
      "0.69375\n",
      "logistic evaluation:  0.20373057971676356\n",
      "average error per step:  0.28830204271654636\n",
      "iteration:  325\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "296\n",
      "average reward\n",
      "0.6947040498442367\n",
      "logistic evaluation:  0.2035655936169455\n",
      "average error per step:  0.2878763290810373\n",
      "iteration:  326\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "760\n",
      "average reward\n",
      "0.6956521739130435\n",
      "logistic evaluation:  0.20296138949493084\n",
      "average error per step:  0.28701164968421855\n",
      "iteration:  327\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "540\n",
      "average reward\n",
      "0.6965944272445821\n",
      "logistic evaluation:  0.20234261696007402\n",
      "average error per step:  0.28613395044378337\n",
      "iteration:  328\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "136\n",
      "average reward\n",
      "0.6944444444444444\n",
      "logistic evaluation:  0.2020717671393924\n",
      "average error per step:  0.285606813478881\n",
      "iteration:  329\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "633\n",
      "average reward\n",
      "0.6923076923076923\n",
      "logistic evaluation:  0.2014759236607565\n",
      "average error per step:  0.2847552530099165\n",
      "iteration:  330\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "694\n",
      "average reward\n",
      "0.6932515337423313\n",
      "logistic evaluation:  0.20099675834747582\n",
      "average error per step:  0.2840222740764466\n",
      "iteration:  331\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "310\n",
      "average reward\n",
      "0.6941896024464832\n",
      "logistic evaluation:  0.20171914451847514\n",
      "average error per step:  0.2844960103092043\n",
      "iteration:  332\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "38\n",
      "average reward\n",
      "0.6920731707317073\n",
      "logistic evaluation:  0.20139327467318224\n",
      "average error per step:  0.2839198310192246\n",
      "iteration:  333\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "221\n",
      "average reward\n",
      "0.6930091185410334\n",
      "logistic evaluation:  0.20081405757341472\n",
      "average error per step:  0.2830910470322324\n",
      "iteration:  334\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "873\n",
      "average reward\n",
      "0.693939393939394\n",
      "logistic evaluation:  0.20028771981549848\n",
      "average error per step:  0.28231679512097263\n",
      "iteration:  335\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "202\n",
      "average reward\n",
      "0.6948640483383686\n",
      "logistic evaluation:  0.20079078643772608\n",
      "average error per step:  0.28257650052325023\n",
      "iteration:  336\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "244\n",
      "average reward\n",
      "0.6927710843373494\n",
      "logistic evaluation:  0.20191909693323698\n",
      "average error per step:  0.2834647592223623\n",
      "iteration:  337\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "799\n",
      "average reward\n",
      "0.6906906906906907\n",
      "logistic evaluation:  0.20197005618114705\n",
      "average error per step:  0.28327389442563966\n",
      "iteration:  338\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "248\n",
      "average reward\n",
      "0.688622754491018\n",
      "logistic evaluation:  0.20158885623127765\n",
      "average error per step:  0.2826510227651361\n",
      "iteration:  339\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "350\n",
      "average reward\n",
      "0.6865671641791045\n",
      "logistic evaluation:  0.20109992733851995\n",
      "average error per step:  0.281921530169055\n",
      "iteration:  340\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "871\n",
      "average reward\n",
      "0.6845238095238095\n",
      "logistic evaluation:  0.20056379032580005\n",
      "average error per step:  0.2811461056862079\n",
      "iteration:  341\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "556\n",
      "average reward\n",
      "0.685459940652819\n",
      "logistic evaluation:  0.20290119959934194\n",
      "average error per step:  0.283254057757149\n",
      "iteration:  342\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "849\n",
      "average reward\n",
      "0.6863905325443787\n",
      "logistic evaluation:  0.2023510467372484\n",
      "average error per step:  0.2824673463833014\n",
      "iteration:  343\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "458\n",
      "average reward\n",
      "0.6873156342182891\n",
      "logistic evaluation:  0.20464559732549462\n",
      "average error per step:  0.2845350114057814\n",
      "iteration:  344\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "185\n",
      "average reward\n",
      "0.6882352941176471\n",
      "logistic evaluation:  0.2045989980341087\n",
      "average error per step:  0.2842560399825011\n",
      "iteration:  345\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "553\n",
      "average reward\n",
      "0.6891495601173021\n",
      "logistic evaluation:  0.2068917049236967\n",
      "average error per step:  0.2863245024226433\n",
      "iteration:  346\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "520\n",
      "average reward\n",
      "0.6900584795321637\n",
      "logistic evaluation:  0.20640069519993037\n",
      "average error per step:  0.2856024990363836\n",
      "iteration:  347\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "43\n",
      "average reward\n",
      "0.6909620991253644\n",
      "logistic evaluation:  0.20580762285799056\n",
      "average error per step:  0.28477947027894407\n",
      "iteration:  348\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "964\n",
      "average reward\n",
      "0.6918604651162791\n",
      "logistic evaluation:  0.20686731638366063\n",
      "average error per step:  0.28561527830491507\n",
      "iteration:  349\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "262\n",
      "average reward\n",
      "0.6927536231884058\n",
      "logistic evaluation:  0.20913180308891474\n",
      "average error per step:  0.28766061465138404\n",
      "iteration:  350\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "913\n",
      "average reward\n",
      "0.6907514450867052\n",
      "logistic evaluation:  0.20976667367432708\n",
      "average error per step:  0.2880729311197191\n",
      "iteration:  351\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "873\n",
      "average reward\n",
      "0.6887608069164265\n",
      "logistic evaluation:  0.2091814658124142\n",
      "average error per step:  0.2872629612483837\n",
      "iteration:  352\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "924\n",
      "average reward\n",
      "0.6896551724137931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic evaluation:  0.208588888213647\n",
      "average error per step:  0.28644687776031325\n",
      "iteration:  353\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "646\n",
      "average reward\n",
      "0.6905444126074498\n",
      "logistic evaluation:  0.20803520127986636\n",
      "average error per step:  0.28567106143140386\n",
      "iteration:  354\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "793\n",
      "average reward\n",
      "0.6914285714285714\n",
      "logistic evaluation:  0.20744920100026606\n",
      "average error per step:  0.28486409544437097\n",
      "iteration:  355\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "270\n",
      "average reward\n",
      "0.6923076923076923\n",
      "logistic evaluation:  0.20687242163843517\n",
      "average error per step:  0.2840676212267487\n",
      "iteration:  356\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "769\n",
      "average reward\n",
      "0.6903409090909091\n",
      "logistic evaluation:  0.20636052070713762\n",
      "average error per step:  0.28333744192320504\n",
      "iteration:  357\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "149\n",
      "average reward\n",
      "0.6883852691218131\n",
      "logistic evaluation:  0.20720926103451803\n",
      "average error per step:  0.2839729380464155\n",
      "iteration:  358\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "805\n",
      "average reward\n",
      "0.6864406779661016\n",
      "logistic evaluation:  0.20741301043602872\n",
      "average error per step:  0.28396283290152846\n",
      "iteration:  359\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "539\n",
      "average reward\n",
      "0.6873239436619718\n",
      "logistic evaluation:  0.20744596589468864\n",
      "average error per step:  0.2837826494548768\n",
      "iteration:  360\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "578\n",
      "average reward\n",
      "0.6882022471910112\n",
      "logistic evaluation:  0.20791638226499262\n",
      "average error per step:  0.2840423261940978\n",
      "iteration:  361\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "527\n",
      "average reward\n",
      "0.6890756302521008\n",
      "logistic evaluation:  0.20799235587290477\n",
      "average error per step:  0.28390763506427813\n",
      "iteration:  362\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "950\n",
      "average reward\n",
      "0.6871508379888268\n",
      "logistic evaluation:  0.20838310002413882\n",
      "average error per step:  0.2840897479032466\n",
      "iteration:  363\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "947\n",
      "average reward\n",
      "0.6880222841225627\n",
      "logistic evaluation:  0.20787843143665766\n",
      "average error per step:  0.28337513078555443\n",
      "iteration:  364\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "186\n",
      "average reward\n",
      "0.6888888888888889\n",
      "logistic evaluation:  0.20796898011506101\n",
      "average error per step:  0.2832585197093685\n",
      "iteration:  365\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "423\n",
      "average reward\n",
      "0.6897506925207756\n",
      "logistic evaluation:  0.20821673264333174\n",
      "average error per step:  0.283300678300472\n",
      "iteration:  366\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "166\n",
      "average reward\n",
      "0.6906077348066298\n",
      "logistic evaluation:  0.2078103575034557\n",
      "average error per step:  0.2826880454535003\n",
      "iteration:  367\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "643\n",
      "average reward\n",
      "0.6914600550964187\n",
      "logistic evaluation:  0.20751534620373133\n",
      "average error per step:  0.2821882039105885\n",
      "iteration:  368\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "382\n",
      "average reward\n",
      "0.6923076923076923\n",
      "logistic evaluation:  0.20695298685307592\n",
      "average error per step:  0.2814214010353204\n",
      "iteration:  369\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "700\n",
      "average reward\n",
      "0.6904109589041096\n",
      "logistic evaluation:  0.20656953524153773\n",
      "average error per step:  0.2808350988389752\n",
      "iteration:  370\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "185\n",
      "average reward\n",
      "0.6912568306010929\n",
      "logistic evaluation:  0.20630428992899366\n",
      "average error per step:  0.28036841890775543\n",
      "iteration:  371\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "141\n",
      "average reward\n",
      "0.6920980926430518\n",
      "logistic evaluation:  0.20586796841330227\n",
      "average error per step:  0.2797312875524564\n",
      "iteration:  372\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "992\n",
      "average reward\n",
      "0.6929347826086957\n",
      "logistic evaluation:  0.20579221066000622\n",
      "average error per step:  0.27945676883977205\n",
      "iteration:  373\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "754\n",
      "average reward\n",
      "0.6937669376693767\n",
      "logistic evaluation:  0.20545600647338289\n",
      "average error per step:  0.27892217118835944\n",
      "iteration:  374\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "836\n",
      "average reward\n",
      "0.6945945945945946\n",
      "logistic evaluation:  0.20496409927347872\n",
      "average error per step:  0.2782325151330679\n",
      "iteration:  375\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "354\n",
      "average reward\n",
      "0.692722371967655\n",
      "logistic evaluation:  0.20475292289389324\n",
      "average error per step:  0.2778253931741779\n",
      "iteration:  376\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "624\n",
      "average reward\n",
      "0.6908602150537635\n",
      "logistic evaluation:  0.20596057867998147\n",
      "average error per step:  0.27884191913448375\n",
      "iteration:  377\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "400\n",
      "average reward\n",
      "0.6890080428954424\n",
      "logistic evaluation:  0.2066520443541633\n",
      "average error per step:  0.27934189972967266\n",
      "iteration:  378\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "206\n",
      "average reward\n",
      "0.6871657754010695\n",
      "logistic evaluation:  0.20617143471016253\n",
      "average error per step:  0.2786677174268901\n",
      "iteration:  379\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "919\n",
      "average reward\n",
      "0.688\n",
      "logistic evaluation:  0.20565876076902462\n",
      "average error per step:  0.2779624077162064\n",
      "iteration:  380\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "624\n",
      "average reward\n",
      "0.6861702127659575\n",
      "logistic evaluation:  0.20593528244380896\n",
      "average error per step:  0.27804938432448445\n",
      "iteration:  381\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "62\n",
      "average reward\n",
      "0.6843501326259946\n",
      "logistic evaluation:  0.20581530902589545\n",
      "average error per step:  0.2777398201577557\n",
      "iteration:  382\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "314\n",
      "average reward\n",
      "0.6851851851851852\n",
      "logistic evaluation:  0.20527793663270658\n",
      "average error per step:  0.27701275696999866\n",
      "iteration:  383\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "977\n",
      "average reward\n",
      "0.683377308707124\n",
      "logistic evaluation:  0.205192820951236\n",
      "average error per step:  0.2767401218733355\n",
      "iteration:  384\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "578\n",
      "average reward\n",
      "0.6842105263157895\n",
      "logistic evaluation:  0.2050861524812929\n",
      "average error per step:  0.2764468545247673\n",
      "iteration:  385\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "286\n",
      "average reward\n",
      "0.6850393700787402\n",
      "logistic evaluation:  0.20459444745715136\n",
      "average error per step:  0.27576851987187867\n",
      "iteration:  386\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "568\n",
      "average reward\n",
      "0.6832460732984293\n",
      "logistic evaluation:  0.20440179732617844\n",
      "average error per step:  0.275390981858663\n",
      "iteration:  387\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "840\n",
      "average reward\n",
      "0.6814621409921671\n",
      "logistic evaluation:  0.2039068725774827\n",
      "average error per step:  0.2747113436492924\n",
      "iteration:  388\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "238\n",
      "average reward\n",
      "0.6796875\n",
      "logistic evaluation:  0.20370367612563517\n",
      "average error per step:  0.2743251377450643\n",
      "iteration:  389\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "560\n",
      "average reward\n",
      "0.6779220779220779\n",
      "logistic evaluation:  0.2042266530729944\n",
      "average error per step:  0.2746679129323411\n",
      "iteration:  390\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "646\n",
      "average reward\n",
      "0.6787564766839378\n",
      "logistic evaluation:  0.20370613759299613\n",
      "average error per step:  0.27396544418224195\n",
      "iteration:  391\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "556\n",
      "average reward\n",
      "0.6770025839793282\n",
      "logistic evaluation:  0.20363717938415826\n",
      "average error per step:  0.27371661828849847\n",
      "iteration:  392\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "325\n",
      "average reward\n",
      "0.6752577319587629\n",
      "logistic evaluation:  0.20315820175003999\n",
      "average error per step:  0.27305764469382293\n",
      "iteration:  393\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "3\n",
      "average reward\n",
      "0.6760925449871465\n",
      "logistic evaluation:  0.20341836966433874\n",
      "average error per step:  0.27314061343501866\n",
      "iteration:  394\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "665\n",
      "average reward\n",
      "0.6743589743589744\n",
      "logistic evaluation:  0.2049110077614762\n",
      "average error per step:  0.2744600799441522\n",
      "iteration:  395\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "47\n",
      "average reward\n",
      "0.6726342710997443\n",
      "logistic evaluation:  0.20444166514298875\n",
      "average error per step:  0.27381347551604157\n",
      "iteration:  396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "761\n",
      "average reward\n",
      "0.673469387755102\n",
      "logistic evaluation:  0.203926705424375\n",
      "average error per step:  0.2731220340547721\n",
      "iteration:  397\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "909\n",
      "average reward\n",
      "0.6743002544529262\n",
      "logistic evaluation:  0.20418698083774464\n",
      "average error per step:  0.27320866953560513\n",
      "iteration:  398\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "211\n",
      "average reward\n",
      "0.6725888324873096\n",
      "logistic evaluation:  0.20376544802108315\n",
      "average error per step:  0.272612656262877\n",
      "iteration:  399\n",
      "estimator:  [ 0.00538747 -0.0236434  -0.0333178 ]\n",
      "action\n",
      "825\n",
      "average reward\n",
      "0.6734177215189874\n",
      "logistic evaluation:  0.2038604795062535\n",
      "average error per step:  0.27253537652810594\n",
      "iteration:  400\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "956\n",
      "average reward\n",
      "0.6742424242424242\n",
      "logistic evaluation:  0.18554204366676014\n",
      "average error per step:  0.27185725151673645\n",
      "iteration:  401\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "977\n",
      "average reward\n",
      "0.6750629722921915\n",
      "logistic evaluation:  0.18508304598158457\n",
      "average error per step:  0.2711818593040418\n",
      "iteration:  402\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "161\n",
      "average reward\n",
      "0.6758793969849246\n",
      "logistic evaluation:  0.18531083898450953\n",
      "average error per step:  0.27119604280368437\n",
      "iteration:  403\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "797\n",
      "average reward\n",
      "0.6766917293233082\n",
      "logistic evaluation:  0.18485214933271407\n",
      "average error per step:  0.27052310031449195\n",
      "iteration:  404\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "119\n",
      "average reward\n",
      "0.6775\n",
      "logistic evaluation:  0.1844646854806318\n",
      "average error per step:  0.26992262058410804\n",
      "iteration:  405\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "523\n",
      "average reward\n",
      "0.6783042394014963\n",
      "logistic evaluation:  0.18435711769667418\n",
      "average error per step:  0.2696037799535148\n",
      "iteration:  406\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "545\n",
      "average reward\n",
      "0.6791044776119403\n",
      "logistic evaluation:  0.18419129347501426\n",
      "average error per step:  0.2692275801493955\n",
      "iteration:  407\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "692\n",
      "average reward\n",
      "0.6799007444168734\n",
      "logistic evaluation:  0.1850641928658601\n",
      "average error per step:  0.26989368989089607\n",
      "iteration:  408\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "867\n",
      "average reward\n",
      "0.6806930693069307\n",
      "logistic evaluation:  0.18588536984948298\n",
      "average error per step:  0.2705089641293194\n",
      "iteration:  409\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "484\n",
      "average reward\n",
      "0.6814814814814815\n",
      "logistic evaluation:  0.1854319924150869\n",
      "average error per step:  0.26984757453914276\n",
      "iteration:  410\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "834\n",
      "average reward\n",
      "0.6798029556650246\n",
      "logistic evaluation:  0.18499478888912377\n",
      "average error per step:  0.2692034129993991\n",
      "iteration:  411\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "427\n",
      "average reward\n",
      "0.6805896805896806\n",
      "logistic evaluation:  0.18697256767612713\n",
      "average error per step:  0.27098111673695413\n",
      "iteration:  412\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "685\n",
      "average reward\n",
      "0.678921568627451\n",
      "logistic evaluation:  0.18741605673880635\n",
      "average error per step:  0.27122177798410385\n",
      "iteration:  413\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "514\n",
      "average reward\n",
      "0.6797066014669927\n",
      "logistic evaluation:  0.18731524663874807\n",
      "average error per step:  0.2709178043698922\n",
      "iteration:  414\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "345\n",
      "average reward\n",
      "0.6804878048780488\n",
      "logistic evaluation:  0.1868659487980856\n",
      "average error per step:  0.2702654827235007\n",
      "iteration:  415\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "726\n",
      "average reward\n",
      "0.6788321167883211\n",
      "logistic evaluation:  0.18700070931103327\n",
      "average error per step:  0.27019960522822556\n",
      "iteration:  416\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "771\n",
      "average reward\n",
      "0.6796116504854369\n",
      "logistic evaluation:  0.18656050041313976\n",
      "average error per step:  0.2695583407899112\n",
      "iteration:  417\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "903\n",
      "average reward\n",
      "0.6803874092009685\n",
      "logistic evaluation:  0.186114188730737\n",
      "average error per step:  0.2689119232272706\n",
      "iteration:  418\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "370\n",
      "average reward\n",
      "0.6811594202898551\n",
      "logistic evaluation:  0.1856701592272908\n",
      "average error per step:  0.2682687507477479\n",
      "iteration:  419\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "590\n",
      "average reward\n",
      "0.6819277108433734\n",
      "logistic evaluation:  0.18573410391146145\n",
      "average error per step:  0.2681357153678701\n",
      "iteration:  420\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "301\n",
      "average reward\n",
      "0.6826923076923077\n",
      "logistic evaluation:  0.18703532737697934\n",
      "average error per step:  0.2692438426715049\n",
      "iteration:  421\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "718\n",
      "average reward\n",
      "0.6810551558752997\n",
      "logistic evaluation:  0.18676220158577594\n",
      "average error per step:  0.2687747984929245\n",
      "iteration:  422\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "96\n",
      "average reward\n",
      "0.6794258373205742\n",
      "logistic evaluation:  0.18709348312447274\n",
      "average error per step:  0.26891252241226477\n",
      "iteration:  423\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "639\n",
      "average reward\n",
      "0.6801909307875895\n",
      "logistic evaluation:  0.18702776056224413\n",
      "average error per step:  0.2686532188527548\n",
      "iteration:  424\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "727\n",
      "average reward\n",
      "0.6785714285714286\n",
      "logistic evaluation:  0.1869790871511583\n",
      "average error per step:  0.26841191777256146\n",
      "iteration:  425\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "119\n",
      "average reward\n",
      "0.6793349168646081\n",
      "logistic evaluation:  0.1865451654454889\n",
      "average error per step:  0.26778536841435774\n",
      "iteration:  426\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "136\n",
      "average reward\n",
      "0.6800947867298578\n",
      "logistic evaluation:  0.18611140540894155\n",
      "average error per step:  0.26715988545995734\n",
      "iteration:  427\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "244\n",
      "average reward\n",
      "0.6784869976359338\n",
      "logistic evaluation:  0.18652572700237802\n",
      "average error per step:  0.26738536827480464\n",
      "iteration:  428\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "304\n",
      "average reward\n",
      "0.6768867924528302\n",
      "logistic evaluation:  0.18714576687464826\n",
      "average error per step:  0.2678179324428689\n",
      "iteration:  429\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "655\n",
      "average reward\n",
      "0.6776470588235294\n",
      "logistic evaluation:  0.1874325456628297\n",
      "average error per step:  0.26791733270708756\n",
      "iteration:  430\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "98\n",
      "average reward\n",
      "0.6784037558685446\n",
      "logistic evaluation:  0.18700583617524758\n",
      "average error per step:  0.26730245694850113\n",
      "iteration:  431\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "231\n",
      "average reward\n",
      "0.6791569086651054\n",
      "logistic evaluation:  0.18659532924089803\n",
      "average error per step:  0.2667046944974286\n",
      "iteration:  432\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "923\n",
      "average reward\n",
      "0.6799065420560748\n",
      "logistic evaluation:  0.18664670720252652\n",
      "average error per step:  0.26657075304402256\n",
      "iteration:  433\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "500\n",
      "average reward\n",
      "0.6806526806526807\n",
      "logistic evaluation:  0.1862166467410847\n",
      "average error per step:  0.26595511727934074\n",
      "iteration:  434\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "99\n",
      "average reward\n",
      "0.6790697674418604\n",
      "logistic evaluation:  0.186193992114123\n",
      "average error per step:  0.2657486812579891\n",
      "iteration:  435\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "730\n",
      "average reward\n",
      "0.6774941995359629\n",
      "logistic evaluation:  0.18662486335558087\n",
      "average error per step:  0.2659976586651886\n",
      "iteration:  436\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "520\n",
      "average reward\n",
      "0.6759259259259259\n",
      "logistic evaluation:  0.18633129646855412\n",
      "average error per step:  0.2655213707639494\n",
      "iteration:  437\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "755\n",
      "average reward\n",
      "0.674364896073903\n",
      "logistic evaluation:  0.18603559237087447\n",
      "average error per step:  0.2650437770131963\n",
      "iteration:  438\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "988\n",
      "average reward\n",
      "0.6728110599078341\n",
      "logistic evaluation:  0.18561350643746183\n",
      "average error per step:  0.2644403434300674\n",
      "iteration:  439\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "800\n",
      "average reward\n",
      "0.671264367816092\n",
      "logistic evaluation:  0.18550975437580386\n",
      "average error per step:  0.2641567950379897\n",
      "iteration:  440\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "755\n",
      "average reward\n",
      "0.6697247706422018\n",
      "logistic evaluation:  0.18510821414367773\n",
      "average error per step:  0.26357559894019467\n",
      "iteration:  441\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "455\n",
      "average reward\n",
      "0.6704805491990846\n",
      "logistic evaluation:  0.1848199191880482\n",
      "average error per step:  0.2631087196767371\n",
      "iteration:  442\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "485\n",
      "average reward\n",
      "0.6712328767123288\n",
      "logistic evaluation:  0.18443133295928557\n",
      "average error per step:  0.2625421303106047\n",
      "iteration:  443\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "327\n",
      "average reward\n",
      "0.6697038724373576\n",
      "logistic evaluation:  0.18442564327964106\n",
      "average error per step:  0.26236010544578875\n",
      "iteration:  444\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "880\n",
      "average reward\n",
      "0.6704545454545454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic evaluation:  0.18417444773606406\n",
      "average error per step:  0.2619328160785412\n",
      "iteration:  445\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "587\n",
      "average reward\n",
      "0.671201814058957\n",
      "logistic evaluation:  0.18600317572884087\n",
      "average error per step:  0.26359091566603776\n",
      "iteration:  446\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "601\n",
      "average reward\n",
      "0.6719457013574661\n",
      "logistic evaluation:  0.18561341929493402\n",
      "average error per step:  0.2630263217963213\n",
      "iteration:  447\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "753\n",
      "average reward\n",
      "0.672686230248307\n",
      "logistic evaluation:  0.18563721096170013\n",
      "average error per step:  0.2628769834612202\n",
      "iteration:  448\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "83\n",
      "average reward\n",
      "0.6734234234234234\n",
      "logistic evaluation:  0.18522376512642227\n",
      "average error per step:  0.2622902045493022\n",
      "iteration:  449\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "424\n",
      "average reward\n",
      "0.6741573033707865\n",
      "logistic evaluation:  0.18481215755423852\n",
      "average error per step:  0.2617060400795793\n",
      "iteration:  450\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "206\n",
      "average reward\n",
      "0.672645739910314\n",
      "logistic evaluation:  0.18442796875701947\n",
      "average error per step:  0.2611501222349768\n",
      "iteration:  451\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "505\n",
      "average reward\n",
      "0.6733780760626398\n",
      "logistic evaluation:  0.18404703227271507\n",
      "average error per step:  0.26059822546250777\n",
      "iteration:  452\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "188\n",
      "average reward\n",
      "0.6741071428571429\n",
      "logistic evaluation:  0.1836706609098677\n",
      "average error per step:  0.260051660372774\n",
      "iteration:  453\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "960\n",
      "average reward\n",
      "0.6748329621380846\n",
      "logistic evaluation:  0.18329529232735498\n",
      "average error per step:  0.25950685168420073\n",
      "iteration:  454\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "279\n",
      "average reward\n",
      "0.6733333333333333\n",
      "logistic evaluation:  0.1836841885089735\n",
      "average error per step:  0.25972873759450815\n",
      "iteration:  455\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "446\n",
      "average reward\n",
      "0.6740576496674058\n",
      "logistic evaluation:  0.1833285984187467\n",
      "average error per step:  0.25920523511048854\n",
      "iteration:  456\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "101\n",
      "average reward\n",
      "0.6747787610619469\n",
      "logistic evaluation:  0.18297809069428622\n",
      "average error per step:  0.25868756259564163\n",
      "iteration:  457\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "233\n",
      "average reward\n",
      "0.6754966887417219\n",
      "logistic evaluation:  0.18257857570408212\n",
      "average error per step:  0.25812150715272075\n",
      "iteration:  458\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "72\n",
      "average reward\n",
      "0.6762114537444934\n",
      "logistic evaluation:  0.18350425024671616\n",
      "average error per step:  0.25888426192045083\n",
      "iteration:  459\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "652\n",
      "average reward\n",
      "0.676923076923077\n",
      "logistic evaluation:  0.1852788944199221\n",
      "average error per step:  0.26049854581587784\n",
      "iteration:  460\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "26\n",
      "average reward\n",
      "0.6776315789473685\n",
      "logistic evaluation:  0.18493067403813024\n",
      "average error per step:  0.25998604745196047\n",
      "iteration:  461\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "129\n",
      "average reward\n",
      "0.6761487964989059\n",
      "logistic evaluation:  0.18467436819735603\n",
      "average error per step:  0.25956637571258623\n",
      "iteration:  462\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "4\n",
      "average reward\n",
      "0.6768558951965066\n",
      "logistic evaluation:  0.1842863443925989\n",
      "average error per step:  0.2590154081170932\n",
      "iteration:  463\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "792\n",
      "average reward\n",
      "0.6753812636165577\n",
      "logistic evaluation:  0.1841126207107256\n",
      "average error per step:  0.25867990735658847\n",
      "iteration:  464\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "661\n",
      "average reward\n",
      "0.6739130434782609\n",
      "logistic evaluation:  0.1840136062488848\n",
      "average error per step:  0.25841997414236034\n",
      "iteration:  465\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "508\n",
      "average reward\n",
      "0.6724511930585684\n",
      "logistic evaluation:  0.18362650426123278\n",
      "average error per step:  0.25787202598292097\n",
      "iteration:  466\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "381\n",
      "average reward\n",
      "0.6731601731601732\n",
      "logistic evaluation:  0.1832797000691046\n",
      "average error per step:  0.257365152421879\n",
      "iteration:  467\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "803\n",
      "average reward\n",
      "0.67170626349892\n",
      "logistic evaluation:  0.18323241687446895\n",
      "average error per step:  0.2571591267528378\n",
      "iteration:  468\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "500\n",
      "average reward\n",
      "0.6724137931034483\n",
      "logistic evaluation:  0.18284205910494114\n",
      "average error per step:  0.25660997183021617\n",
      "iteration:  469\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "623\n",
      "average reward\n",
      "0.6731182795698925\n",
      "logistic evaluation:  0.18245501491794439\n",
      "average error per step:  0.25606481472869436\n",
      "iteration:  470\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "847\n",
      "average reward\n",
      "0.6738197424892703\n",
      "logistic evaluation:  0.18241257739309716\n",
      "average error per step:  0.255865670315899\n",
      "iteration:  471\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "473\n",
      "average reward\n",
      "0.6723768736616702\n",
      "logistic evaluation:  0.1822793198619698\n",
      "average error per step:  0.25557617849506054\n",
      "iteration:  472\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "68\n",
      "average reward\n",
      "0.6709401709401709\n",
      "logistic evaluation:  0.18192122265482633\n",
      "average error per step:  0.25506203265266236\n",
      "iteration:  473\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "676\n",
      "average reward\n",
      "0.6716417910447762\n",
      "logistic evaluation:  0.18172848805158232\n",
      "average error per step:  0.2547142588430735\n",
      "iteration:  474\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "803\n",
      "average reward\n",
      "0.6702127659574468\n",
      "logistic evaluation:  0.18153627344500436\n",
      "average error per step:  0.2543676603010566\n",
      "iteration:  475\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "460\n",
      "average reward\n",
      "0.6709129511677282\n",
      "logistic evaluation:  0.18143909868686733\n",
      "average error per step:  0.254116951728995\n",
      "iteration:  476\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "412\n",
      "average reward\n",
      "0.6716101694915254\n",
      "logistic evaluation:  0.18105872732756545\n",
      "average error per step:  0.25358309670498425\n",
      "iteration:  477\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "756\n",
      "average reward\n",
      "0.6701902748414377\n",
      "logistic evaluation:  0.1807540150214519\n",
      "average error per step:  0.2531257028859073\n",
      "iteration:  478\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "629\n",
      "average reward\n",
      "0.6687763713080169\n",
      "logistic evaluation:  0.18079543079677257\n",
      "average error per step:  0.25301580010037206\n",
      "iteration:  479\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "229\n",
      "average reward\n",
      "0.6673684210526316\n",
      "logistic evaluation:  0.18087911380244517\n",
      "average error per step:  0.2529488845960281\n",
      "iteration:  480\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "661\n",
      "average reward\n",
      "0.6659663865546218\n",
      "logistic evaluation:  0.18069392561132336\n",
      "average error per step:  0.2526131652403548\n",
      "iteration:  481\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "521\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.18031904328393358\n",
      "average error per step:  0.25208798328311804\n",
      "iteration:  482\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "146\n",
      "average reward\n",
      "0.6673640167364017\n",
      "logistic evaluation:  0.1812009556631451\n",
      "average error per step:  0.25282282714029636\n",
      "iteration:  483\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "854\n",
      "average reward\n",
      "0.6680584551148225\n",
      "logistic evaluation:  0.1808373966581429\n",
      "average error per step:  0.2523102299769461\n",
      "iteration:  484\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "250\n",
      "average reward\n",
      "0.66875\n",
      "logistic evaluation:  0.18046454143658466\n",
      "average error per step:  0.2517889332501391\n",
      "iteration:  485\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "55\n",
      "average reward\n",
      "0.6694386694386695\n",
      "logistic evaluation:  0.1800932158650513\n",
      "average error per step:  0.2512697814571932\n",
      "iteration:  486\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "321\n",
      "average reward\n",
      "0.6701244813278008\n",
      "logistic evaluation:  0.17972450057521688\n",
      "average error per step:  0.25075385365525593\n",
      "iteration:  487\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "158\n",
      "average reward\n",
      "0.6687370600414079\n",
      "logistic evaluation:  0.17968441572758834\n",
      "average error per step:  0.2505678356701989\n",
      "iteration:  488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "275\n",
      "average reward\n",
      "0.6694214876033058\n",
      "logistic evaluation:  0.1802631428100903\n",
      "average error per step:  0.2510024957591351\n",
      "iteration:  489\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "584\n",
      "average reward\n",
      "0.6701030927835051\n",
      "logistic evaluation:  0.1798952600966429\n",
      "average error per step:  0.25048919947582576\n",
      "iteration:  490\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "450\n",
      "average reward\n",
      "0.6707818930041153\n",
      "logistic evaluation:  0.17952887483294597\n",
      "average error per step:  0.24997799722306174\n",
      "iteration:  491\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "739\n",
      "average reward\n",
      "0.6714579055441479\n",
      "logistic evaluation:  0.17917824700097573\n",
      "average error per step:  0.2494831743804559\n",
      "iteration:  492\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "119\n",
      "average reward\n",
      "0.6721311475409836\n",
      "logistic evaluation:  0.1789351498378522\n",
      "average error per step:  0.24909668692354656\n",
      "iteration:  493\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "524\n",
      "average reward\n",
      "0.6707566462167689\n",
      "logistic evaluation:  0.17879599053275944\n",
      "average error per step:  0.24881492985701203\n",
      "iteration:  494\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "985\n",
      "average reward\n",
      "0.6693877551020408\n",
      "logistic evaluation:  0.17864442345097356\n",
      "average error per step:  0.24852131721569978\n",
      "iteration:  495\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "892\n",
      "average reward\n",
      "0.670061099796334\n",
      "logistic evaluation:  0.17828473559626815\n",
      "average error per step:  0.2480197372769147\n",
      "iteration:  496\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "854\n",
      "average reward\n",
      "0.6707317073170732\n",
      "logistic evaluation:  0.17793266107770717\n",
      "average error per step:  0.2475263581692424\n",
      "iteration:  497\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "954\n",
      "average reward\n",
      "0.6693711967545639\n",
      "logistic evaluation:  0.17845059939264757\n",
      "average error per step:  0.24790531105404884\n",
      "iteration:  498\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "761\n",
      "average reward\n",
      "0.6700404858299596\n",
      "logistic evaluation:  0.1800964278305551\n",
      "average error per step:  0.24941497707584492\n",
      "iteration:  499\n",
      "estimator:  [ 0.01063294 -0.02154379 -0.04221296]\n",
      "action\n",
      "496\n",
      "average reward\n",
      "0.6707070707070707\n",
      "logistic evaluation:  0.18173589213704627\n",
      "average error per step:  0.25091881195360105\n",
      "iteration:  500\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "71\n",
      "average reward\n",
      "0.6693548387096774\n",
      "logistic evaluation:  0.13661912459440764\n",
      "average error per step:  0.2504170966546808\n",
      "iteration:  501\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "984\n",
      "average reward\n",
      "0.670020120724346\n",
      "logistic evaluation:  0.13637956486632025\n",
      "average error per step:  0.24994991710266454\n",
      "iteration:  502\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "852\n",
      "average reward\n",
      "0.6706827309236948\n",
      "logistic evaluation:  0.13610843253061977\n",
      "average error per step:  0.2494520089012827\n",
      "iteration:  503\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "685\n",
      "average reward\n",
      "0.6693386773547094\n",
      "logistic evaluation:  0.13586741006688544\n",
      "average error per step:  0.24898517212575036\n",
      "iteration:  504\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "334\n",
      "average reward\n",
      "0.668\n",
      "logistic evaluation:  0.13559914432706627\n",
      "average error per step:  0.24849193410855286\n",
      "iteration:  505\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "128\n",
      "average reward\n",
      "0.6686626746506986\n",
      "logistic evaluation:  0.13533116182860777\n",
      "average error per step:  0.24799987087290634\n",
      "iteration:  506\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "218\n",
      "average reward\n",
      "0.6693227091633466\n",
      "logistic evaluation:  0.13506424237793024\n",
      "average error per step:  0.24750975848053913\n",
      "iteration:  507\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "945\n",
      "average reward\n",
      "0.6699801192842942\n",
      "logistic evaluation:  0.13552616164376882\n",
      "average error per step:  0.2477508028019265\n",
      "iteration:  508\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "173\n",
      "average reward\n",
      "0.6686507936507936\n",
      "logistic evaluation:  0.13525995738710742\n",
      "average error per step:  0.24726315987318867\n",
      "iteration:  509\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "813\n",
      "average reward\n",
      "0.6673267326732674\n",
      "logistic evaluation:  0.13499499161374837\n",
      "average error per step:  0.2467776279539368\n",
      "iteration:  510\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "468\n",
      "average reward\n",
      "0.6679841897233202\n",
      "logistic evaluation:  0.13668775967580413\n",
      "average error per step:  0.24825453352917268\n",
      "iteration:  511\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "429\n",
      "average reward\n",
      "0.6686390532544378\n",
      "logistic evaluation:  0.13642079150396555\n",
      "average error per step:  0.24776871263321434\n",
      "iteration:  512\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "529\n",
      "average reward\n",
      "0.6692913385826772\n",
      "logistic evaluation:  0.13810417751889498\n",
      "average error per step:  0.24923791010299862\n",
      "iteration:  513\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "128\n",
      "average reward\n",
      "0.6679764243614931\n",
      "logistic evaluation:  0.13783894389314552\n",
      "average error per step:  0.24875552449633326\n",
      "iteration:  514\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "434\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.13759647215285228\n",
      "average error per step:  0.24829679000829005\n",
      "iteration:  515\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "885\n",
      "average reward\n",
      "0.6673189823874756\n",
      "logistic evaluation:  0.13742142655632292\n",
      "average error per step:  0.24790645244389278\n",
      "iteration:  516\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "135\n",
      "average reward\n",
      "0.666015625\n",
      "logistic evaluation:  0.13724615912967403\n",
      "average error per step:  0.24751672708446443\n",
      "iteration:  517\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "673\n",
      "average reward\n",
      "0.6647173489278753\n",
      "logistic evaluation:  0.1369827042085599\n",
      "average error per step:  0.24703947327964448\n",
      "iteration:  518\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "289\n",
      "average reward\n",
      "0.6634241245136187\n",
      "logistic evaluation:  0.13671902701717592\n",
      "average error per step:  0.246562822253777\n",
      "iteration:  519\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "199\n",
      "average reward\n",
      "0.6640776699029126\n",
      "logistic evaluation:  0.1383791825099397\n",
      "average error per step:  0.24801453142718846\n",
      "iteration:  520\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "65\n",
      "average reward\n",
      "0.6627906976744186\n",
      "logistic evaluation:  0.1381136615936457\n",
      "average error per step:  0.24753766268429145\n",
      "iteration:  521\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "857\n",
      "average reward\n",
      "0.6615087040618955\n",
      "logistic evaluation:  0.1378565085765731\n",
      "average error per step:  0.24706998921787587\n",
      "iteration:  522\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "922\n",
      "average reward\n",
      "0.6602316602316602\n",
      "logistic evaluation:  0.13759357896247595\n",
      "average error per step:  0.24659733467991782\n",
      "iteration:  523\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "194\n",
      "average reward\n",
      "0.6608863198458574\n",
      "logistic evaluation:  0.1373309957965182\n",
      "average error per step:  0.24612582925988086\n",
      "iteration:  524\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "521\n",
      "average reward\n",
      "0.6615384615384615\n",
      "logistic evaluation:  0.13707106520103074\n",
      "average error per step:  0.24565777888565515\n",
      "iteration:  525\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "321\n",
      "average reward\n",
      "0.6621880998080614\n",
      "logistic evaluation:  0.1369529803984584\n",
      "average error per step:  0.2453326373240596\n",
      "iteration:  526\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "386\n",
      "average reward\n",
      "0.6628352490421456\n",
      "logistic evaluation:  0.13670282062076108\n",
      "average error per step:  0.24487595698228756\n",
      "iteration:  527\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "559\n",
      "average reward\n",
      "0.6615678776290631\n",
      "logistic evaluation:  0.137366579237123\n",
      "average error per step:  0.2453357129843323\n",
      "iteration:  528\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "251\n",
      "average reward\n",
      "0.6622137404580153\n",
      "logistic evaluation:  0.1383041081490715\n",
      "average error per step:  0.24607053052348668\n",
      "iteration:  529\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "562\n",
      "average reward\n",
      "0.6628571428571428\n",
      "logistic evaluation:  0.13804315700162245\n",
      "average error per step:  0.2456053688400795\n",
      "iteration:  530\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "269\n",
      "average reward\n",
      "0.6634980988593155\n",
      "logistic evaluation:  0.1377831896219358\n",
      "average error per step:  0.24514196338639635\n",
      "iteration:  531\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "741\n",
      "average reward\n",
      "0.6641366223908919\n",
      "logistic evaluation:  0.13752419866404603\n",
      "average error per step:  0.24468030243844568\n",
      "iteration:  532\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "759\n",
      "average reward\n",
      "0.6647727272727273\n",
      "logistic evaluation:  0.13914235076035927\n",
      "average error per step:  0.24610007492634148\n",
      "iteration:  533\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "212\n",
      "average reward\n",
      "0.665406427221172\n",
      "logistic evaluation:  0.1388817845604439\n",
      "average error per step:  0.24563834870697787\n",
      "iteration:  534\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "338\n",
      "average reward\n",
      "0.6660377358490566\n",
      "logistic evaluation:  0.13862219243977172\n",
      "average error per step:  0.24517835179928843\n",
      "iteration:  535\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "818\n",
      "average reward\n",
      "0.664783427495292\n",
      "logistic evaluation:  0.13914407640776133\n",
      "average error per step:  0.24550204086000418\n",
      "iteration:  536\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "183\n",
      "average reward\n",
      "0.6635338345864662\n",
      "logistic evaluation:  0.13910552696016254\n",
      "average error per step:  0.24526499045363703\n",
      "iteration:  537\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "824\n",
      "average reward\n",
      "0.6641651031894934\n",
      "logistic evaluation:  0.14003716981542538\n",
      "average error per step:  0.2460006783356444\n",
      "iteration:  538\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "91\n",
      "average reward\n",
      "0.6629213483146067\n",
      "logistic evaluation:  0.13977743434644385\n",
      "average error per step:  0.24554350189270524\n",
      "iteration:  539\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "267\n",
      "average reward\n",
      "0.6635514018691588\n",
      "logistic evaluation:  0.13955125102067173\n",
      "average error per step:  0.24512067246141914\n",
      "iteration:  540\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "179\n",
      "average reward\n",
      "0.664179104477612\n",
      "logistic evaluation:  0.14114170988953434\n",
      "average error per step:  0.24651857769588936\n",
      "iteration:  541\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "394\n",
      "average reward\n",
      "0.664804469273743\n",
      "logistic evaluation:  0.14088178835239165\n",
      "average error per step:  0.2460633940712356\n",
      "iteration:  542\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "138\n",
      "average reward\n",
      "0.6654275092936803\n",
      "logistic evaluation:  0.14062234027111722\n",
      "average error per step:  0.2456094053002931\n",
      "iteration:  543\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "975\n",
      "average reward\n",
      "0.6641929499072357\n",
      "logistic evaluation:  0.1406291325896535\n",
      "average error per step:  0.24542286378326647\n",
      "iteration:  544\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "844\n",
      "average reward\n",
      "0.6648148148148149\n",
      "logistic evaluation:  0.14053432556023793\n",
      "average error per step:  0.2451352469409409\n",
      "iteration:  545\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "628\n",
      "average reward\n",
      "0.6635859519408502\n",
      "logistic evaluation:  0.14029084250963167\n",
      "average error per step:  0.24469938883633224\n",
      "iteration:  546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "122\n",
      "average reward\n",
      "0.6642066420664207\n",
      "logistic evaluation:  0.14003466033772674\n",
      "average error per step:  0.24425151302248851\n",
      "iteration:  547\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "905\n",
      "average reward\n",
      "0.6629834254143646\n",
      "logistic evaluation:  0.1406719733420582\n",
      "average error per step:  0.24469946672210255\n",
      "iteration:  548\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "104\n",
      "average reward\n",
      "0.6617647058823529\n",
      "logistic evaluation:  0.14105510285219264\n",
      "average error per step:  0.24489346418137944\n",
      "iteration:  549\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "871\n",
      "average reward\n",
      "0.6623853211009174\n",
      "logistic evaluation:  0.14080014149868106\n",
      "average error per step:  0.24444889750421997\n",
      "iteration:  550\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "277\n",
      "average reward\n",
      "0.663003663003663\n",
      "logistic evaluation:  0.14062206899781443\n",
      "average error per step:  0.24408204895152355\n",
      "iteration:  551\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "883\n",
      "average reward\n",
      "0.6617915904936015\n",
      "logistic evaluation:  0.14038396985594698\n",
      "average error per step:  0.24365575002908338\n",
      "iteration:  552\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "680\n",
      "average reward\n",
      "0.6605839416058394\n",
      "logistic evaluation:  0.14013037025620295\n",
      "average error per step:  0.24321460445148993\n",
      "iteration:  553\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "284\n",
      "average reward\n",
      "0.6612021857923497\n",
      "logistic evaluation:  0.13987744381945894\n",
      "average error per step:  0.2427748115398236\n",
      "iteration:  554\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "441\n",
      "average reward\n",
      "0.6618181818181819\n",
      "logistic evaluation:  0.13980164311429522\n",
      "average error per step:  0.24251313868948748\n",
      "iteration:  555\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "600\n",
      "average reward\n",
      "0.662431941923775\n",
      "logistic evaluation:  0.14054181626990814\n",
      "average error per step:  0.24306957973263268\n",
      "iteration:  556\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "778\n",
      "average reward\n",
      "0.6630434782608695\n",
      "logistic evaluation:  0.14028949703066843\n",
      "average error per step:  0.24263240422954052\n",
      "iteration:  557\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "316\n",
      "average reward\n",
      "0.6636528028933092\n",
      "logistic evaluation:  0.14003883464518613\n",
      "average error per step:  0.24219755231159082\n",
      "iteration:  558\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "591\n",
      "average reward\n",
      "0.6642599277978339\n",
      "logistic evaluation:  0.13979530595256792\n",
      "average error per step:  0.24177050704843672\n",
      "iteration:  559\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "358\n",
      "average reward\n",
      "0.6648648648648648\n",
      "logistic evaluation:  0.13954567147765537\n",
      "average error per step:  0.2413380016691042\n",
      "iteration:  560\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "622\n",
      "average reward\n",
      "0.6654676258992805\n",
      "logistic evaluation:  0.1393077523830067\n",
      "average error per step:  0.24091788570073033\n",
      "iteration:  561\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "25\n",
      "average reward\n",
      "0.6660682226211849\n",
      "logistic evaluation:  0.1390598738200918\n",
      "average error per step:  0.24048844205424927\n",
      "iteration:  562\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "362\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.1390336419524378\n",
      "average error per step:  0.2402816856312539\n",
      "iteration:  563\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "664\n",
      "average reward\n",
      "0.667262969588551\n",
      "logistic evaluation:  0.13894665179169294\n",
      "average error per step:  0.24001470429139793\n",
      "iteration:  564\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "535\n",
      "average reward\n",
      "0.6678571428571428\n",
      "logistic evaluation:  0.14047050285223622\n",
      "average error per step:  0.2413620585408789\n",
      "iteration:  565\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "676\n",
      "average reward\n",
      "0.6684491978609626\n",
      "logistic evaluation:  0.14022317829254527\n",
      "average error per step:  0.24093572711349173\n",
      "iteration:  566\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "671\n",
      "average reward\n",
      "0.6672597864768683\n",
      "logistic evaluation:  0.13997602280006552\n",
      "average error per step:  0.24051019758512251\n",
      "iteration:  567\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "443\n",
      "average reward\n",
      "0.6660746003552398\n",
      "logistic evaluation:  0.13973357544115908\n",
      "average error per step:  0.24009001367922495\n",
      "iteration:  568\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "942\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.13948943697981334\n",
      "average error per step:  0.23966876152650698\n",
      "iteration:  569\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "231\n",
      "average reward\n",
      "0.6672566371681415\n",
      "logistic evaluation:  0.13924475643517853\n",
      "average error per step:  0.23924758888153594\n",
      "iteration:  570\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "147\n",
      "average reward\n",
      "0.6678445229681979\n",
      "logistic evaluation:  0.1390051113542111\n",
      "average error per step:  0.23883207980490656\n",
      "iteration:  571\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "598\n",
      "average reward\n",
      "0.6684303350970018\n",
      "logistic evaluation:  0.1387620957397431\n",
      "average error per step:  0.23841381027789013\n",
      "iteration:  572\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "19\n",
      "average reward\n",
      "0.6690140845070423\n",
      "logistic evaluation:  0.13851993358612139\n",
      "average error per step:  0.2379970084797024\n",
      "iteration:  573\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "774\n",
      "average reward\n",
      "0.6678383128295254\n",
      "logistic evaluation:  0.13879853504282344\n",
      "average error per step:  0.2381024886913139\n",
      "iteration:  574\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "501\n",
      "average reward\n",
      "0.6684210526315789\n",
      "logistic evaluation:  0.13917922993872034\n",
      "average error per step:  0.23831084341516795\n",
      "iteration:  575\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "906\n",
      "average reward\n",
      "0.6690017513134852\n",
      "logistic evaluation:  0.13894379307523874\n",
      "average error per step:  0.23790259429022562\n",
      "iteration:  576\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "756\n",
      "average reward\n",
      "0.6678321678321678\n",
      "logistic evaluation:  0.1387031888946315\n",
      "average error per step:  0.23748976891969542\n",
      "iteration:  577\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "460\n",
      "average reward\n",
      "0.6684118673647469\n",
      "logistic evaluation:  0.13846321797965086\n",
      "average error per step:  0.23707817486617055\n",
      "iteration:  578\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "822\n",
      "average reward\n",
      "0.6672473867595818\n",
      "logistic evaluation:  0.1385477447944419\n",
      "average error per step:  0.23699223380886517\n",
      "iteration:  579\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "89\n",
      "average reward\n",
      "0.6660869565217391\n",
      "logistic evaluation:  0.1383493190214797\n",
      "average error per step:  0.23662344030742735\n",
      "iteration:  580\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "145\n",
      "average reward\n",
      "0.6649305555555556\n",
      "logistic evaluation:  0.13811495650255953\n",
      "average error per step:  0.2362192355750505\n",
      "iteration:  581\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "963\n",
      "average reward\n",
      "0.6637781629116117\n",
      "logistic evaluation:  0.1378787899273574\n",
      "average error per step:  0.23581380833608298\n",
      "iteration:  582\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "749\n",
      "average reward\n",
      "0.6643598615916955\n",
      "logistic evaluation:  0.1376502557462662\n",
      "average error per step:  0.23541660825707109\n",
      "iteration:  583\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "707\n",
      "average reward\n",
      "0.6649395509499136\n",
      "logistic evaluation:  0.13741455325355267\n",
      "average error per step:  0.23501280618459167\n",
      "iteration:  584\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "140\n",
      "average reward\n",
      "0.6655172413793103\n",
      "logistic evaluation:  0.13742799350178178\n",
      "average error per step:  0.23485914915082964\n",
      "iteration:  585\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "451\n",
      "average reward\n",
      "0.6660929432013769\n",
      "logistic evaluation:  0.13719347480302616\n",
      "average error per step:  0.23445768058139405\n",
      "iteration:  586\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "804\n",
      "average reward\n",
      "0.6649484536082474\n",
      "logistic evaluation:  0.13696033335077956\n",
      "average error per step:  0.2340581614034979\n",
      "iteration:  587\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "696\n",
      "average reward\n",
      "0.6638078902229846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic evaluation:  0.13672875146688154\n",
      "average error per step:  0.2336607713255\n",
      "iteration:  588\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "528\n",
      "average reward\n",
      "0.6643835616438356\n",
      "logistic evaluation:  0.13650030477362354\n",
      "average error per step:  0.23326708574354835\n",
      "iteration:  589\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "363\n",
      "average reward\n",
      "0.6649572649572649\n",
      "logistic evaluation:  0.13796382815229152\n",
      "average error per step:  0.23456880393105964\n",
      "iteration:  590\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "3\n",
      "average reward\n",
      "0.6655290102389079\n",
      "logistic evaluation:  0.1377303868187005\n",
      "average error per step:  0.23417122968710868\n",
      "iteration:  591\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "317\n",
      "average reward\n",
      "0.666098807495741\n",
      "logistic evaluation:  0.13749807417631504\n",
      "average error per step:  0.23377534148548326\n",
      "iteration:  592\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "391\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.13802921568314827\n",
      "average error per step:  0.2341447496717044\n",
      "iteration:  593\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "502\n",
      "average reward\n",
      "0.66723259762309\n",
      "logistic evaluation:  0.1378750574969773\n",
      "average error per step:  0.233828247991141\n",
      "iteration:  594\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "532\n",
      "average reward\n",
      "0.6661016949152543\n",
      "logistic evaluation:  0.13764744303598825\n",
      "average error per step:  0.23343871298308938\n",
      "iteration:  595\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "159\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.13743927742152598\n",
      "average error per step:  0.23306920377944798\n",
      "iteration:  596\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "722\n",
      "average reward\n",
      "0.6672297297297297\n",
      "logistic evaluation:  0.13722886914897897\n",
      "average error per step:  0.23269798957631294\n",
      "iteration:  597\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "279\n",
      "average reward\n",
      "0.6677908937605397\n",
      "logistic evaluation:  0.1369994581198612\n",
      "average error per step:  0.23230827949952942\n",
      "iteration:  598\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "43\n",
      "average reward\n",
      "0.6683501683501684\n",
      "logistic evaluation:  0.13682539782352673\n",
      "average error per step:  0.2319745488324993\n",
      "iteration:  599\n",
      "estimator:  [ 0.02071734 -0.0423126  -0.07084983]\n",
      "action\n",
      "975\n",
      "average reward\n",
      "0.66890756302521\n",
      "logistic evaluation:  0.13660444764616284\n",
      "average error per step:  0.23159438312727837\n",
      "iteration:  600\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "970\n",
      "average reward\n",
      "0.6694630872483222\n",
      "logistic evaluation:  0.19878279105623947\n",
      "average error per step:  0.23186439962944078\n",
      "iteration:  601\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "375\n",
      "average reward\n",
      "0.6700167504187605\n",
      "logistic evaluation:  0.1985542818152591\n",
      "average error per step:  0.23158046589958492\n",
      "iteration:  602\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "381\n",
      "average reward\n",
      "0.6705685618729097\n",
      "logistic evaluation:  0.19854819948558752\n",
      "average error per step:  0.23151951269547144\n",
      "iteration:  603\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "839\n",
      "average reward\n",
      "0.671118530884808\n",
      "logistic evaluation:  0.1998748073646446\n",
      "average error per step:  0.2327936417928854\n",
      "iteration:  604\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "379\n",
      "average reward\n",
      "0.6716666666666666\n",
      "logistic evaluation:  0.1995528758044705\n",
      "average error per step:  0.2324166758519358\n",
      "iteration:  605\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "35\n",
      "average reward\n",
      "0.670549084858569\n",
      "logistic evaluation:  0.19990277024422676\n",
      "average error per step:  0.23271282829895198\n",
      "iteration:  606\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "85\n",
      "average reward\n",
      "0.6710963455149501\n",
      "logistic evaluation:  0.19959306839637442\n",
      "average error per step:  0.2323484733819535\n",
      "iteration:  607\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "482\n",
      "average reward\n",
      "0.6716417910447762\n",
      "logistic evaluation:  0.19949425151804157\n",
      "average error per step:  0.23219553093218095\n",
      "iteration:  608\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "890\n",
      "average reward\n",
      "0.6721854304635762\n",
      "logistic evaluation:  0.19920957960723407\n",
      "average error per step:  0.2318566058119574\n",
      "iteration:  609\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "45\n",
      "average reward\n",
      "0.6727272727272727\n",
      "logistic evaluation:  0.19890820232661618\n",
      "average error per step:  0.2315011260625623\n",
      "iteration:  610\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "999\n",
      "average reward\n",
      "0.6716171617161716\n",
      "logistic evaluation:  0.19864958558586848\n",
      "average error per step:  0.23118865433742655\n",
      "iteration:  611\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "78\n",
      "average reward\n",
      "0.6705107084019769\n",
      "logistic evaluation:  0.1984790801345816\n",
      "average error per step:  0.23096461439480936\n",
      "iteration:  612\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "178\n",
      "average reward\n",
      "0.6694078947368421\n",
      "logistic evaluation:  0.1981659578682297\n",
      "average error per step:  0.23059789955243365\n",
      "iteration:  613\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "7\n",
      "average reward\n",
      "0.6699507389162561\n",
      "logistic evaluation:  0.19791727877793386\n",
      "average error per step:  0.23029590786707338\n",
      "iteration:  614\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "417\n",
      "average reward\n",
      "0.6688524590163935\n",
      "logistic evaluation:  0.1976090111493079\n",
      "average error per step:  0.22993440425030773\n",
      "iteration:  615\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "881\n",
      "average reward\n",
      "0.6693944353518821\n",
      "logistic evaluation:  0.19782351313467592\n",
      "average error per step:  0.2300966934045934\n",
      "iteration:  616\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "737\n",
      "average reward\n",
      "0.6683006535947712\n",
      "logistic evaluation:  0.19758751473693353\n",
      "average error per step:  0.2298079203661568\n",
      "iteration:  617\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "12\n",
      "average reward\n",
      "0.6688417618270799\n",
      "logistic evaluation:  0.1972734873612471\n",
      "average error per step:  0.22944116295318528\n",
      "iteration:  618\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "687\n",
      "average reward\n",
      "0.6693811074918566\n",
      "logistic evaluation:  0.1970029071655848\n",
      "average error per step:  0.22911809367048805\n",
      "iteration:  619\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "268\n",
      "average reward\n",
      "0.6682926829268293\n",
      "logistic evaluation:  0.19698684671192626\n",
      "average error per step:  0.2290501249018722\n",
      "iteration:  620\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "577\n",
      "average reward\n",
      "0.6688311688311688\n",
      "logistic evaluation:  0.1971733070176494\n",
      "average error per step:  0.22918517098520144\n",
      "iteration:  621\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "82\n",
      "average reward\n",
      "0.6677471636952999\n",
      "logistic evaluation:  0.1971323988761657\n",
      "average error per step:  0.2290926480738159\n",
      "iteration:  622\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "3\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.1968271727105809\n",
      "average error per step:  0.22873554815362784\n",
      "iteration:  623\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "264\n",
      "average reward\n",
      "0.6672051696284329\n",
      "logistic evaluation:  0.19651902706181915\n",
      "average error per step:  0.22837569059300122\n",
      "iteration:  624\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "409\n",
      "average reward\n",
      "0.667741935483871\n",
      "logistic evaluation:  0.19684248212102937\n",
      "average error per step:  0.2286486116642756\n",
      "iteration:  625\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "932\n",
      "average reward\n",
      "0.6682769726247987\n",
      "logistic evaluation:  0.19652985279344637\n",
      "average error per step:  0.22828459232249929\n",
      "iteration:  626\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "999\n",
      "average reward\n",
      "0.6688102893890675\n",
      "logistic evaluation:  0.19658726993008674\n",
      "average error per step:  0.22829137475883227\n",
      "iteration:  627\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "170\n",
      "average reward\n",
      "0.6693418940609952\n",
      "logistic evaluation:  0.19627606736427683\n",
      "average error per step:  0.2279291110966993\n",
      "iteration:  628\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "866\n",
      "average reward\n",
      "0.6698717948717948\n",
      "logistic evaluation:  0.1959685354223454\n",
      "average error per step:  0.22757068651834375\n",
      "iteration:  629\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "454\n",
      "average reward\n",
      "0.6704\n",
      "logistic evaluation:  0.19583910737336266\n",
      "average error per step:  0.22739081080776322\n",
      "iteration:  630\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "368\n",
      "average reward\n",
      "0.6693290734824281\n",
      "logistic evaluation:  0.19593321932004626\n",
      "average error per step:  0.22743499006954568\n",
      "iteration:  631\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "680\n",
      "average reward\n",
      "0.6698564593301436\n",
      "logistic evaluation:  0.19624181661098666\n",
      "average error per step:  0.2276941528542126\n",
      "iteration:  632\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "361\n",
      "average reward\n",
      "0.6687898089171974\n",
      "logistic evaluation:  0.19602366189631054\n",
      "average error per step:  0.2274258866032107\n",
      "iteration:  633\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "476\n",
      "average reward\n",
      "0.6677265500794912\n",
      "logistic evaluation:  0.19591257703154527\n",
      "average error per step:  0.2272650176790905\n",
      "iteration:  634\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "668\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.19611950653023566\n",
      "average error per step:  0.22742282176587417\n",
      "iteration:  635\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "948\n",
      "average reward\n",
      "0.6671949286846276\n",
      "logistic evaluation:  0.1958787542219201\n",
      "average error per step:  0.22713239376063896\n",
      "iteration:  636\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "737\n",
      "average reward\n",
      "0.6677215189873418\n",
      "logistic evaluation:  0.19558931181482253\n",
      "average error per step:  0.2267933553127461\n",
      "iteration:  637\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "620\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.19549396472091513\n",
      "average error per step:  0.2266488725978154\n",
      "iteration:  638\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "526\n",
      "average reward\n",
      "0.6656151419558359\n",
      "logistic evaluation:  0.1952384824354003\n",
      "average error per step:  0.22634415772583907\n",
      "iteration:  639\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "255\n",
      "average reward\n",
      "0.6661417322834645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic evaluation:  0.19515783936640274\n",
      "average error per step:  0.22621470977677982\n",
      "iteration:  640\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "992\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.19560591633644403\n",
      "average error per step:  0.22661496050707056\n",
      "iteration:  641\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "757\n",
      "average reward\n",
      "0.6671899529042387\n",
      "logistic evaluation:  0.19685820275828164\n",
      "average error per step:  0.2278208245299241\n",
      "iteration:  642\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "487\n",
      "average reward\n",
      "0.6661442006269592\n",
      "logistic evaluation:  0.19718595022027877\n",
      "average error per step:  0.22810085411916478\n",
      "iteration:  643\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "802\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.19843223108350508\n",
      "average error per step:  0.22930099404454404\n",
      "iteration:  644\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "783\n",
      "average reward\n",
      "0.6671875\n",
      "logistic evaluation:  0.19967306878510202\n",
      "average error per step:  0.2304958256510176\n",
      "iteration:  645\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "333\n",
      "average reward\n",
      "0.6661466458658346\n",
      "logistic evaluation:  0.1994310170043791\n",
      "average error per step:  0.23020561137626888\n",
      "iteration:  646\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "709\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.19912632813628367\n",
      "average error per step:  0.2298528121626007\n",
      "iteration:  647\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "854\n",
      "average reward\n",
      "0.6671850699844479\n",
      "logistic evaluation:  0.19953830163704783\n",
      "average error per step:  0.23021793170582924\n",
      "iteration:  648\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "272\n",
      "average reward\n",
      "0.6677018633540373\n",
      "logistic evaluation:  0.1992317335620569\n",
      "average error per step:  0.22986354542382634\n",
      "iteration:  649\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "216\n",
      "average reward\n",
      "0.6682170542635659\n",
      "logistic evaluation:  0.19892525153480908\n",
      "average error per step:  0.22950939268180345\n",
      "iteration:  650\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "549\n",
      "average reward\n",
      "0.6687306501547987\n",
      "logistic evaluation:  0.19861969146846126\n",
      "average error per step:  0.22915630999820433\n",
      "iteration:  651\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "37\n",
      "average reward\n",
      "0.6692426584234931\n",
      "logistic evaluation:  0.19838551707699625\n",
      "average error per step:  0.22887486864372672\n",
      "iteration:  652\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "134\n",
      "average reward\n",
      "0.6697530864197531\n",
      "logistic evaluation:  0.19808182591150503\n",
      "average error per step:  0.22852394888508792\n",
      "iteration:  653\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "392\n",
      "average reward\n",
      "0.6702619414483821\n",
      "logistic evaluation:  0.1978223185367513\n",
      "average error per step:  0.22821742523108712\n",
      "iteration:  654\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "171\n",
      "average reward\n",
      "0.6707692307692308\n",
      "logistic evaluation:  0.1975841386028247\n",
      "average error per step:  0.22793240540934973\n",
      "iteration:  655\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "977\n",
      "average reward\n",
      "0.6712749615975423\n",
      "logistic evaluation:  0.1972938595202494\n",
      "average error per step:  0.22759534992083685\n",
      "iteration:  656\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "893\n",
      "average reward\n",
      "0.6717791411042945\n",
      "logistic evaluation:  0.19699356733130396\n",
      "average error per step:  0.22724840867306592\n",
      "iteration:  657\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "18\n",
      "average reward\n",
      "0.6722817764165391\n",
      "logistic evaluation:  0.19701274834251567\n",
      "average error per step:  0.22722156889229808\n",
      "iteration:  658\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "742\n",
      "average reward\n",
      "0.672782874617737\n",
      "logistic evaluation:  0.19671722419122178\n",
      "average error per step:  0.2268796855545284\n",
      "iteration:  659\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "970\n",
      "average reward\n",
      "0.6717557251908397\n",
      "logistic evaluation:  0.19654366052828307\n",
      "average error per step:  0.22666008846969857\n",
      "iteration:  660\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "25\n",
      "average reward\n",
      "0.6722560975609756\n",
      "logistic evaluation:  0.19658394824426173\n",
      "average error per step:  0.22665480627624476\n",
      "iteration:  661\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "227\n",
      "average reward\n",
      "0.6727549467275494\n",
      "logistic evaluation:  0.19660317578469713\n",
      "average error per step:  0.2266285699278881\n",
      "iteration:  662\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "660\n",
      "average reward\n",
      "0.6717325227963525\n",
      "logistic evaluation:  0.1963256879754615\n",
      "average error per step:  0.22630530737250074\n",
      "iteration:  663\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "345\n",
      "average reward\n",
      "0.6707132018209409\n",
      "logistic evaluation:  0.19638776265629782\n",
      "average error per step:  0.22632225755150268\n",
      "iteration:  664\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "70\n",
      "average reward\n",
      "0.6696969696969697\n",
      "logistic evaluation:  0.19658835947736694\n",
      "average error per step:  0.2264780744055927\n",
      "iteration:  665\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "226\n",
      "average reward\n",
      "0.670196671709531\n",
      "logistic evaluation:  0.19671183214083235\n",
      "average error per step:  0.22655678580249455\n",
      "iteration:  666\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "892\n",
      "average reward\n",
      "0.6691842900302115\n",
      "logistic evaluation:  0.19644461153511\n",
      "average error per step:  0.22624435172189625\n",
      "iteration:  667\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "423\n",
      "average reward\n",
      "0.6681749622926093\n",
      "logistic evaluation:  0.19623610925933074\n",
      "average error per step:  0.22599085957735754\n",
      "iteration:  668\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "527\n",
      "average reward\n",
      "0.6686746987951807\n",
      "logistic evaluation:  0.19596938441295825\n",
      "average error per step:  0.22567919240289464\n",
      "iteration:  669\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "536\n",
      "average reward\n",
      "0.6676691729323309\n",
      "logistic evaluation:  0.1957878643771787\n",
      "average error per step:  0.22545299175721115\n",
      "iteration:  670\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "981\n",
      "average reward\n",
      "0.6681681681681682\n",
      "logistic evaluation:  0.19587108077150095\n",
      "average error per step:  0.2254920560455846\n",
      "iteration:  671\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "187\n",
      "average reward\n",
      "0.6671664167916042\n",
      "logistic evaluation:  0.19606384768798715\n",
      "average error per step:  0.22564096572159745\n",
      "iteration:  672\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "189\n",
      "average reward\n",
      "0.6676646706586826\n",
      "logistic evaluation:  0.1959632531684573\n",
      "average error per step:  0.22549620793933972\n",
      "iteration:  673\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "898\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.1963429309174664\n",
      "average error per step:  0.22583256729752882\n",
      "iteration:  674\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "610\n",
      "average reward\n",
      "0.6671641791044776\n",
      "logistic evaluation:  0.1961426872932906\n",
      "average error per step:  0.2255882734062844\n",
      "iteration:  675\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "561\n",
      "average reward\n",
      "0.6661698956780924\n",
      "logistic evaluation:  0.19612556531789435\n",
      "average error per step:  0.22552750297446092\n",
      "iteration:  676\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "270\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.1963616898330652\n",
      "average error per step:  0.2257204827956356\n",
      "iteration:  677\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "722\n",
      "average reward\n",
      "0.6656760772659732\n",
      "logistic evaluation:  0.19643631375347156\n",
      "average error per step:  0.22575185092720568\n",
      "iteration:  678\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "735\n",
      "average reward\n",
      "0.6661721068249258\n",
      "logistic evaluation:  0.1963524234499617\n",
      "average error per step:  0.22562459863626627\n",
      "iteration:  679\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "950\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.1960656246090779\n",
      "average error per step:  0.2252942666966679\n",
      "iteration:  680\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "996\n",
      "average reward\n",
      "0.6671597633136095\n",
      "logistic evaluation:  0.19606666688007834\n",
      "average error per step:  0.22525232720323218\n",
      "iteration:  681\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "165\n",
      "average reward\n",
      "0.6676514032496307\n",
      "logistic evaluation:  0.1961132613702088\n",
      "average error per step:  0.225256133050436\n",
      "iteration:  682\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "2\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.19606393919626397\n",
      "average error per step:  0.22516400707318596\n",
      "iteration:  683\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "611\n",
      "average reward\n",
      "0.6656848306332842\n",
      "logistic evaluation:  0.19587671134884538\n",
      "average error per step:  0.22493389885135398\n",
      "iteration:  684\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "783\n",
      "average reward\n",
      "0.6661764705882353\n",
      "logistic evaluation:  0.19589552388952752\n",
      "average error per step:  0.22491025762747205\n",
      "iteration:  685\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "45\n",
      "average reward\n",
      "0.6651982378854625\n",
      "logistic evaluation:  0.19574906756626131\n",
      "average error per step:  0.2247212302238245\n",
      "iteration:  686\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "684\n",
      "average reward\n",
      "0.6656891495601173\n",
      "logistic evaluation:  0.19569636690492287\n",
      "average error per step:  0.22462621926610282\n",
      "iteration:  687\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "302\n",
      "average reward\n",
      "0.664714494875549\n",
      "logistic evaluation:  0.1954282158426652\n",
      "average error per step:  0.22431556747105996\n",
      "iteration:  688\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "772\n",
      "average reward\n",
      "0.6652046783625731\n",
      "logistic evaluation:  0.19659566977111828\n",
      "average error per step:  0.22544273085053057\n",
      "iteration:  689\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "692\n",
      "average reward\n",
      "0.6656934306569343\n",
      "logistic evaluation:  0.19645420201350988\n",
      "average error per step:  0.22525918975643883\n",
      "iteration:  690\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "980\n",
      "average reward\n",
      "0.6661807580174927\n",
      "logistic evaluation:  0.19627784384890137\n",
      "average error per step:  0.22504082964123967\n",
      "iteration:  691\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "494\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.195994221200744\n",
      "average error per step:  0.22471517138028854\n",
      "iteration:  692\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "371\n",
      "average reward\n",
      "0.6671511627906976\n",
      "logistic evaluation:  0.19571140700851022\n",
      "average error per step:  0.22439044423376028\n",
      "iteration:  693\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "40\n",
      "average reward\n",
      "0.6661828737300436\n",
      "logistic evaluation:  0.1955924331975395\n",
      "average error per step:  0.22422991485130872\n",
      "iteration:  694\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "540\n",
      "average reward\n",
      "0.6666666666666666\n",
      "logistic evaluation:  0.19674984148227204\n",
      "average error per step:  0.22534772648853543\n",
      "iteration:  695\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "728\n",
      "average reward\n",
      "0.6657018813314037\n",
      "logistic evaluation:  0.19647689673844848\n",
      "average error per step:  0.22503324098248154\n",
      "iteration:  696\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "787\n",
      "average reward\n",
      "0.6647398843930635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic evaluation:  0.19662783645783674\n",
      "average error per step:  0.22514336833904702\n",
      "iteration:  697\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "189\n",
      "average reward\n",
      "0.6637806637806638\n",
      "logistic evaluation:  0.1970332070079308\n",
      "average error per step:  0.2255084086720233\n",
      "iteration:  698\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "737\n",
      "average reward\n",
      "0.6628242074927954\n",
      "logistic evaluation:  0.19743519552068278\n",
      "average error per step:  0.22587017768169312\n",
      "iteration:  699\n",
      "estimator:  [ 0.0094739  -0.01889786 -0.03252139]\n",
      "action\n",
      "579\n",
      "average reward\n",
      "0.6633093525179856\n",
      "logistic evaluation:  0.19857523562530152\n",
      "average error per step:  0.22697116922829128\n",
      "iteration:  700\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "560\n",
      "average reward\n",
      "0.6623563218390804\n",
      "logistic evaluation:  0.17186742015449297\n",
      "average error per step:  0.22693486341046729\n",
      "iteration:  701\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "105\n",
      "average reward\n",
      "0.6614060258249641\n",
      "logistic evaluation:  0.17185082615443315\n",
      "average error per step:  0.2268396901846499\n",
      "iteration:  702\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "734\n",
      "average reward\n",
      "0.66189111747851\n",
      "logistic evaluation:  0.171609901699563\n",
      "average error per step:  0.22652009081740782\n",
      "iteration:  703\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "16\n",
      "average reward\n",
      "0.6623748211731044\n",
      "logistic evaluation:  0.17136743582828745\n",
      "average error per step:  0.22619917166734263\n",
      "iteration:  704\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "443\n",
      "average reward\n",
      "0.6628571428571428\n",
      "logistic evaluation:  0.1711382930590774\n",
      "average error per step:  0.2258918174228368\n",
      "iteration:  705\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "680\n",
      "average reward\n",
      "0.6633380884450785\n",
      "logistic evaluation:  0.17127835219746654\n",
      "average error per step:  0.2259544106531048\n",
      "iteration:  706\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "98\n",
      "average reward\n",
      "0.6623931623931624\n",
      "logistic evaluation:  0.17152693061284666\n",
      "average error per step:  0.22612589632055258\n",
      "iteration:  707\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "584\n",
      "average reward\n",
      "0.662873399715505\n",
      "logistic evaluation:  0.17128466216622132\n",
      "average error per step:  0.22580605894301586\n",
      "iteration:  708\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "707\n",
      "average reward\n",
      "0.6619318181818182\n",
      "logistic evaluation:  0.1716502572102701\n",
      "average error per step:  0.22609516274167946\n",
      "iteration:  709\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "996\n",
      "average reward\n",
      "0.6609929078014184\n",
      "logistic evaluation:  0.17141598456956555\n",
      "average error per step:  0.22578376855207205\n",
      "iteration:  710\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "111\n",
      "average reward\n",
      "0.660056657223796\n",
      "logistic evaluation:  0.1718422289503809\n",
      "average error per step:  0.22613403893344836\n",
      "iteration:  711\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "652\n",
      "average reward\n",
      "0.6591230551626591\n",
      "logistic evaluation:  0.17243278806191334\n",
      "average error per step:  0.22664906885950747\n",
      "iteration:  712\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "511\n",
      "average reward\n",
      "0.6581920903954802\n",
      "logistic evaluation:  0.17219326349706623\n",
      "average error per step:  0.2263330614219603\n",
      "iteration:  713\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "236\n",
      "average reward\n",
      "0.6572637517630465\n",
      "logistic evaluation:  0.17276414087218114\n",
      "average error per step:  0.22682880707119896\n",
      "iteration:  714\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "988\n",
      "average reward\n",
      "0.6577464788732394\n",
      "logistic evaluation:  0.17294719681132134\n",
      "average error per step:  0.22693639857019923\n",
      "iteration:  715\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "468\n",
      "average reward\n",
      "0.6568213783403657\n",
      "logistic evaluation:  0.17280659528828668\n",
      "average error per step:  0.22672009102858848\n",
      "iteration:  716\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "966\n",
      "average reward\n",
      "0.6558988764044944\n",
      "logistic evaluation:  0.1726862865215015\n",
      "average error per step:  0.2265243160543912\n",
      "iteration:  717\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "857\n",
      "average reward\n",
      "0.6549789621318373\n",
      "logistic evaluation:  0.1724524846434709\n",
      "average error per step:  0.2262151001855504\n",
      "iteration:  718\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "685\n",
      "average reward\n",
      "0.6554621848739496\n",
      "logistic evaluation:  0.1722127595238246\n",
      "average error per step:  0.2259001628922805\n",
      "iteration:  719\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "397\n",
      "average reward\n",
      "0.6545454545454545\n",
      "logistic evaluation:  0.17199192441848002\n",
      "average error per step:  0.22560435109921156\n",
      "iteration:  720\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "466\n",
      "average reward\n",
      "0.6550279329608939\n",
      "logistic evaluation:  0.17175408269809897\n",
      "average error per step:  0.22529171733938458\n",
      "iteration:  721\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "736\n",
      "average reward\n",
      "0.6555090655509066\n",
      "logistic evaluation:  0.17290014388969496\n",
      "average error per step:  0.2263651133805649\n",
      "iteration:  722\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "373\n",
      "average reward\n",
      "0.6559888579387186\n",
      "logistic evaluation:  0.17266169241034057\n",
      "average error per step:  0.22605228043172262\n",
      "iteration:  723\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "632\n",
      "average reward\n",
      "0.6564673157162726\n",
      "logistic evaluation:  0.17242320942302394\n",
      "average error per step:  0.22573962168920725\n",
      "iteration:  724\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "467\n",
      "average reward\n",
      "0.6569444444444444\n",
      "logistic evaluation:  0.17230262933266055\n",
      "average error per step:  0.22554523359835138\n",
      "iteration:  725\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "551\n",
      "average reward\n",
      "0.6574202496532594\n",
      "logistic evaluation:  0.1721453449510366\n",
      "average error per step:  0.22531429419790355\n",
      "iteration:  726\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "345\n",
      "average reward\n",
      "0.6565096952908587\n",
      "logistic evaluation:  0.17207165166641214\n",
      "average error per step:  0.22516726394009529\n",
      "iteration:  727\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "353\n",
      "average reward\n",
      "0.6556016597510373\n",
      "logistic evaluation:  0.17183997963162223\n",
      "average error per step:  0.22486223938218505\n",
      "iteration:  728\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "174\n",
      "average reward\n",
      "0.6546961325966851\n",
      "logistic evaluation:  0.17172752634731106\n",
      "average error per step:  0.2246767988546941\n",
      "iteration:  729\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "80\n",
      "average reward\n",
      "0.6551724137931034\n",
      "logistic evaluation:  0.17149244762284038\n",
      "average error per step:  0.22436876491591362\n",
      "iteration:  730\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "236\n",
      "average reward\n",
      "0.6556473829201102\n",
      "logistic evaluation:  0.17132026295354286\n",
      "average error per step:  0.22412391106584573\n",
      "iteration:  731\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "831\n",
      "average reward\n",
      "0.6547455295735901\n",
      "logistic evaluation:  0.17186837653962483\n",
      "average error per step:  0.22460053965257581\n",
      "iteration:  732\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "130\n",
      "average reward\n",
      "0.6552197802197802\n",
      "logistic evaluation:  0.17299814912454956\n",
      "average error per step:  0.2256598171684732\n",
      "iteration:  733\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "524\n",
      "average reward\n",
      "0.654320987654321\n",
      "logistic evaluation:  0.1731827546562599\n",
      "average error per step:  0.2257728305275884\n",
      "iteration:  734\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "242\n",
      "average reward\n",
      "0.6534246575342466\n",
      "logistic evaluation:  0.1730431000816965\n",
      "average error per step:  0.2255613370832077\n",
      "iteration:  735\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "300\n",
      "average reward\n",
      "0.652530779753762\n",
      "logistic evaluation:  0.17286000841143698\n",
      "average error per step:  0.22530654292495939\n",
      "iteration:  736\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "185\n",
      "average reward\n",
      "0.6530054644808743\n",
      "logistic evaluation:  0.1726365146213512\n",
      "average error per step:  0.22501148659641765\n",
      "iteration:  737\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "721\n",
      "average reward\n",
      "0.6534788540245566\n",
      "logistic evaluation:  0.1737576010052957\n",
      "average error per step:  0.2260630290379047\n",
      "iteration:  738\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "277\n",
      "average reward\n",
      "0.6539509536784741\n",
      "logistic evaluation:  0.17355924084932375\n",
      "average error per step:  0.2257935255375038\n",
      "iteration:  739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "985\n",
      "average reward\n",
      "0.654421768707483\n",
      "logistic evaluation:  0.1746760269010885\n",
      "average error per step:  0.22684114041384712\n",
      "iteration:  740\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "479\n",
      "average reward\n",
      "0.6535326086956522\n",
      "logistic evaluation:  0.1746562067476931\n",
      "average error per step:  0.2267508000798218\n",
      "iteration:  741\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "330\n",
      "average reward\n",
      "0.6540027137042063\n",
      "logistic evaluation:  0.17442917823777365\n",
      "average error per step:  0.22645316209373226\n",
      "iteration:  742\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "35\n",
      "average reward\n",
      "0.6544715447154471\n",
      "logistic evaluation:  0.17421542590768388\n",
      "average error per step:  0.2261690085019362\n",
      "iteration:  743\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "233\n",
      "average reward\n",
      "0.6535859269282814\n",
      "logistic evaluation:  0.17398676267901622\n",
      "average error per step:  0.22587011344847324\n",
      "iteration:  744\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "38\n",
      "average reward\n",
      "0.654054054054054\n",
      "logistic evaluation:  0.17375938387319084\n",
      "average error per step:  0.22557269333945526\n",
      "iteration:  745\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "727\n",
      "average reward\n",
      "0.6545209176788124\n",
      "logistic evaluation:  0.17486649036931576\n",
      "average error per step:  0.22661173781817062\n",
      "iteration:  746\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "358\n",
      "average reward\n",
      "0.6549865229110512\n",
      "logistic evaluation:  0.17464283093636154\n",
      "average error per step:  0.2263184149711657\n",
      "iteration:  747\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "18\n",
      "average reward\n",
      "0.6554508748317631\n",
      "logistic evaluation:  0.17440941098572404\n",
      "average error per step:  0.22601550505535356\n",
      "iteration:  748\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "577\n",
      "average reward\n",
      "0.6559139784946236\n",
      "logistic evaluation:  0.17418224318955092\n",
      "average error per step:  0.22571904145454705\n",
      "iteration:  749\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "769\n",
      "average reward\n",
      "0.6563758389261745\n",
      "logistic evaluation:  0.1739500005052178\n",
      "average error per step:  0.22541768122555525\n",
      "iteration:  750\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "137\n",
      "average reward\n",
      "0.6554959785522788\n",
      "logistic evaluation:  0.17420201241919\n",
      "average error per step:  0.225601405581119\n",
      "iteration:  751\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "164\n",
      "average reward\n",
      "0.6559571619812584\n",
      "logistic evaluation:  0.17397196258477043\n",
      "average error per step:  0.22530260815282943\n",
      "iteration:  752\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "303\n",
      "average reward\n",
      "0.6550802139037433\n",
      "logistic evaluation:  0.17378537463853316\n",
      "average error per step:  0.22504751324713168\n",
      "iteration:  753\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "22\n",
      "average reward\n",
      "0.6542056074766355\n",
      "logistic evaluation:  0.17364404460550228\n",
      "average error per step:  0.2248379183155063\n",
      "iteration:  754\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "476\n",
      "average reward\n",
      "0.6533333333333333\n",
      "logistic evaluation:  0.1742940308721851\n",
      "average error per step:  0.22542087024870994\n",
      "iteration:  755\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "354\n",
      "average reward\n",
      "0.6524633821571239\n",
      "logistic evaluation:  0.17413131733155496\n",
      "average error per step:  0.22519022352540807\n",
      "iteration:  756\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "335\n",
      "average reward\n",
      "0.6529255319148937\n",
      "logistic evaluation:  0.17393338908841952\n",
      "average error per step:  0.22492449523672106\n",
      "iteration:  757\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "296\n",
      "average reward\n",
      "0.6533864541832669\n",
      "logistic evaluation:  0.17377608691556445\n",
      "average error per step:  0.224699625813772\n",
      "iteration:  758\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "804\n",
      "average reward\n",
      "0.6538461538461539\n",
      "logistic evaluation:  0.17354820641315485\n",
      "average error per step:  0.22440426322772042\n",
      "iteration:  759\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "680\n",
      "average reward\n",
      "0.6543046357615894\n",
      "logistic evaluation:  0.17332023502472388\n",
      "average error per step:  0.22410898745430527\n",
      "iteration:  760\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "178\n",
      "average reward\n",
      "0.6547619047619048\n",
      "logistic evaluation:  0.17343163018849528\n",
      "average error per step:  0.22415370188483216\n",
      "iteration:  761\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "117\n",
      "average reward\n",
      "0.655217965653897\n",
      "logistic evaluation:  0.1732049373730626\n",
      "average error per step:  0.22386005931314223\n",
      "iteration:  762\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "465\n",
      "average reward\n",
      "0.6556728232189973\n",
      "logistic evaluation:  0.17298298860125735\n",
      "average error per step:  0.2235713427320038\n",
      "iteration:  763\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "234\n",
      "average reward\n",
      "0.6561264822134387\n",
      "logistic evaluation:  0.17278467022255878\n",
      "average error per step:  0.22330646252826009\n",
      "iteration:  764\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "501\n",
      "average reward\n",
      "0.6552631578947369\n",
      "logistic evaluation:  0.17329342283238633\n",
      "average error per step:  0.22374975304424485\n",
      "iteration:  765\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "707\n",
      "average reward\n",
      "0.6544021024967148\n",
      "logistic evaluation:  0.17308334221691013\n",
      "average error per step:  0.22347344182638\n",
      "iteration:  766\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "200\n",
      "average reward\n",
      "0.6548556430446194\n",
      "logistic evaluation:  0.17286319935819539\n",
      "average error per step:  0.2231872281550436\n",
      "iteration:  767\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "559\n",
      "average reward\n",
      "0.653997378768021\n",
      "logistic evaluation:  0.17264472183041735\n",
      "average error per step:  0.22290285426960635\n",
      "iteration:  768\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "374\n",
      "average reward\n",
      "0.6544502617801047\n",
      "logistic evaluation:  0.1724215822433263\n",
      "average error per step:  0.2226139838595644\n",
      "iteration:  769\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "131\n",
      "average reward\n",
      "0.6535947712418301\n",
      "logistic evaluation:  0.17228380326924525\n",
      "average error per step:  0.22241075601605512\n",
      "iteration:  770\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "752\n",
      "average reward\n",
      "0.6540469973890339\n",
      "logistic evaluation:  0.17206253513414405\n",
      "average error per step:  0.22212410058110726\n",
      "iteration:  771\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "32\n",
      "average reward\n",
      "0.6544980443285529\n",
      "logistic evaluation:  0.17184856095987697\n",
      "average error per step:  0.22184491818424457\n",
      "iteration:  772\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "427\n",
      "average reward\n",
      "0.6536458333333334\n",
      "logistic evaluation:  0.17163230425553622\n",
      "average error per step:  0.22156361923388218\n",
      "iteration:  773\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "20\n",
      "average reward\n",
      "0.6527958387516255\n",
      "logistic evaluation:  0.17148994583537888\n",
      "average error per step:  0.22135648245227788\n",
      "iteration:  774\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "671\n",
      "average reward\n",
      "0.6519480519480519\n",
      "logistic evaluation:  0.1713082652253576\n",
      "average error per step:  0.22111014006289365\n",
      "iteration:  775\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "493\n",
      "average reward\n",
      "0.6511024643320363\n",
      "logistic evaluation:  0.17111706709440833\n",
      "average error per step:  0.2208544347410173\n",
      "iteration:  776\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "743\n",
      "average reward\n",
      "0.6502590673575129\n",
      "logistic evaluation:  0.1711248795637829\n",
      "average error per step:  0.22079816273207067\n",
      "iteration:  777\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "876\n",
      "average reward\n",
      "0.6494178525226391\n",
      "logistic evaluation:  0.17146833329696\n",
      "average error per step:  0.22107812891127726\n",
      "iteration:  778\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "744\n",
      "average reward\n",
      "0.648578811369509\n",
      "logistic evaluation:  0.1712572009022859\n",
      "average error per step:  0.22080295933407232\n",
      "iteration:  779\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "645\n",
      "average reward\n",
      "0.6490322580645161\n",
      "logistic evaluation:  0.1710376404865181\n",
      "average error per step:  0.22051951532543218\n",
      "iteration:  780\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "194\n",
      "average reward\n",
      "0.6494845360824743\n",
      "logistic evaluation:  0.1708225310643343\n",
      "average error per step:  0.22024069182086234\n",
      "iteration:  781\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "249\n",
      "average reward\n",
      "0.6499356499356499\n",
      "logistic evaluation:  0.1718825138727638\n",
      "average error per step:  0.22123875634766815\n",
      "iteration:  782\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "758\n",
      "average reward\n",
      "0.6503856041131105\n",
      "logistic evaluation:  0.17166299980306754\n",
      "average error per step:  0.22095584616985858\n",
      "iteration:  783\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "946\n",
      "average reward\n",
      "0.6508344030808729\n",
      "logistic evaluation:  0.17144420448473913\n",
      "average error per step:  0.22067381759267307\n",
      "iteration:  784\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "577\n",
      "average reward\n",
      "0.6512820512820513\n",
      "logistic evaluation:  0.17249887613116974\n",
      "average error per step:  0.22166704160968848\n",
      "iteration:  785\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "495\n",
      "average reward\n",
      "0.6504481434058899\n",
      "logistic evaluation:  0.17229295027904598\n",
      "average error per step:  0.22139821882593336\n",
      "iteration:  786\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "748\n",
      "average reward\n",
      "0.6508951406649617\n",
      "logistic evaluation:  0.17214617420373793\n",
      "average error per step:  0.22118878111624593\n",
      "iteration:  787\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "216\n",
      "average reward\n",
      "0.6500638569604087\n",
      "logistic evaluation:  0.1721440410898986\n",
      "average error per step:  0.22112432940008592\n",
      "iteration:  788\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "24\n",
      "average reward\n",
      "0.6505102040816326\n",
      "logistic evaluation:  0.1731921759718923\n",
      "average error per step:  0.2221116366762063\n",
      "iteration:  789\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "504\n",
      "average reward\n",
      "0.6509554140127388\n",
      "logistic evaluation:  0.1729746267980581\n",
      "average error per step:  0.22183180992331236\n",
      "iteration:  790\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "962\n",
      "average reward\n",
      "0.6513994910941476\n",
      "logistic evaluation:  0.17321245007332609\n",
      "average error per step:  0.22200808970509933\n",
      "iteration:  791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "444\n",
      "average reward\n",
      "0.650571791613723\n",
      "logistic evaluation:  0.17299607026440936\n",
      "average error per step:  0.22172974779828036\n",
      "iteration:  792\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "175\n",
      "average reward\n",
      "0.649746192893401\n",
      "logistic evaluation:  0.17279680140294418\n",
      "average error per step:  0.22146869491358873\n",
      "iteration:  793\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "249\n",
      "average reward\n",
      "0.6501901140684411\n",
      "logistic evaluation:  0.17328616092022095\n",
      "average error per step:  0.22189729461498484\n",
      "iteration:  794\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "731\n",
      "average reward\n",
      "0.6506329113924051\n",
      "logistic evaluation:  0.1731421276194922\n",
      "average error per step:  0.2216918568218184\n",
      "iteration:  795\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "102\n",
      "average reward\n",
      "0.6510745891276865\n",
      "logistic evaluation:  0.17418039351315562\n",
      "average error per step:  0.22267035986855271\n",
      "iteration:  796\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "355\n",
      "average reward\n",
      "0.6502525252525253\n",
      "logistic evaluation:  0.17450256108029852\n",
      "average error per step:  0.22293201512566013\n",
      "iteration:  797\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "437\n",
      "average reward\n",
      "0.6506935687263556\n",
      "logistic evaluation:  0.17429466087248485\n",
      "average error per step:  0.22266308937926027\n",
      "iteration:  798\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "94\n",
      "average reward\n",
      "0.6511335012594458\n",
      "logistic evaluation:  0.17462140450996172\n",
      "average error per step:  0.222929630404119\n",
      "iteration:  799\n",
      "estimator:  [ 0.01058692 -0.02647629 -0.04324704]\n",
      "action\n",
      "916\n",
      "average reward\n",
      "0.6515723270440251\n",
      "logistic evaluation:  0.1744793184850569\n",
      "average error per step:  0.22272690569095502\n",
      "iteration:  800\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "802\n",
      "average reward\n",
      "0.6507537688442211\n",
      "logistic evaluation:  0.18574699711407722\n",
      "average error per step:  0.22273148938673873\n",
      "iteration:  801\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "646\n",
      "average reward\n",
      "0.6511919698870765\n",
      "logistic evaluation:  0.18676183330344204\n",
      "average error per step:  0.22370141963842155\n",
      "iteration:  802\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "384\n",
      "average reward\n",
      "0.650375939849624\n",
      "logistic evaluation:  0.18700974347708285\n",
      "average error per step:  0.2239035795924098\n",
      "iteration:  803\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "843\n",
      "average reward\n",
      "0.6508135168961201\n",
      "logistic evaluation:  0.18677714489537764\n",
      "average error per step:  0.22362474634732102\n",
      "iteration:  804\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "194\n",
      "average reward\n",
      "0.65\n",
      "logistic evaluation:  0.18659490647078092\n",
      "average error per step:  0.22339645090795246\n",
      "iteration:  805\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "547\n",
      "average reward\n",
      "0.6504369538077404\n",
      "logistic evaluation:  0.1863774611904473\n",
      "average error per step:  0.2231330193049884\n",
      "iteration:  806\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "328\n",
      "average reward\n",
      "0.6508728179551122\n",
      "logistic evaluation:  0.1863702443688025\n",
      "average error per step:  0.2230801911000481\n",
      "iteration:  807\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "162\n",
      "average reward\n",
      "0.651307596513076\n",
      "logistic evaluation:  0.18643976688293257\n",
      "average error per step:  0.22310431036236014\n",
      "iteration:  808\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "541\n",
      "average reward\n",
      "0.650497512437811\n",
      "logistic evaluation:  0.18637517073749818\n",
      "average error per step:  0.2229942573609544\n",
      "iteration:  809\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "905\n",
      "average reward\n",
      "0.6509316770186335\n",
      "logistic evaluation:  0.1865956323834795\n",
      "average error per step:  0.2231697268870625\n",
      "iteration:  810\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "434\n",
      "average reward\n",
      "0.6501240694789082\n",
      "logistic evaluation:  0.186499596052235\n",
      "average error per step:  0.22302841878935523\n",
      "iteration:  811\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "720\n",
      "average reward\n",
      "0.6505576208178439\n",
      "logistic evaluation:  0.18629964158289491\n",
      "average error per step:  0.22278317606205403\n",
      "iteration:  812\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "613\n",
      "average reward\n",
      "0.650990099009901\n",
      "logistic evaluation:  0.18641830128574108\n",
      "average error per step:  0.22285705143635792\n",
      "iteration:  813\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "499\n",
      "average reward\n",
      "0.6514215080346106\n",
      "logistic evaluation:  0.18633209876047518\n",
      "average error per step:  0.22272592277003928\n",
      "iteration:  814\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "957\n",
      "average reward\n",
      "0.6506172839506172\n",
      "logistic evaluation:  0.1861137417021017\n",
      "average error per step:  0.22246258760224574\n",
      "iteration:  815\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "567\n",
      "average reward\n",
      "0.6510480887792849\n",
      "logistic evaluation:  0.18600845682375308\n",
      "average error per step:  0.22231257372907687\n",
      "iteration:  816\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "163\n",
      "average reward\n",
      "0.6514778325123153\n",
      "logistic evaluation:  0.18578078502160453\n",
      "average error per step:  0.2220401325780221\n",
      "iteration:  817\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "48\n",
      "average reward\n",
      "0.6506765067650676\n",
      "logistic evaluation:  0.18564634641076713\n",
      "average error per step:  0.2218611483292811\n",
      "iteration:  818\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "990\n",
      "average reward\n",
      "0.6511056511056511\n",
      "logistic evaluation:  0.18552141778251288\n",
      "average error per step:  0.22169179460255892\n",
      "iteration:  819\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "891\n",
      "average reward\n",
      "0.6503067484662577\n",
      "logistic evaluation:  0.1853472887695585\n",
      "average error per step:  0.22147328890360576\n",
      "iteration:  820\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "74\n",
      "average reward\n",
      "0.6495098039215687\n",
      "logistic evaluation:  0.18563488715679063\n",
      "average error per step:  0.22171718192285397\n",
      "iteration:  821\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "684\n",
      "average reward\n",
      "0.6487148102815178\n",
      "logistic evaluation:  0.18568914933353914\n",
      "average error per step:  0.2217275609904803\n",
      "iteration:  822\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "800\n",
      "average reward\n",
      "0.6491442542787286\n",
      "logistic evaluation:  0.1854679223580159\n",
      "average error per step:  0.2214622225324358\n",
      "iteration:  823\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "652\n",
      "average reward\n",
      "0.6495726495726496\n",
      "logistic evaluation:  0.18534029108769606\n",
      "average error per step:  0.22129070070142978\n",
      "iteration:  824\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "354\n",
      "average reward\n",
      "0.6487804878048781\n",
      "logistic evaluation:  0.18514399215771293\n",
      "average error per step:  0.22105053440670913\n",
      "iteration:  825\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "190\n",
      "average reward\n",
      "0.6492082825822169\n",
      "logistic evaluation:  0.18612565162831238\n",
      "average error per step:  0.221989860686062\n",
      "iteration:  826\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "86\n",
      "average reward\n",
      "0.648418491484185\n",
      "logistic evaluation:  0.1859855175050714\n",
      "average error per step:  0.22180613776962368\n",
      "iteration:  827\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "809\n",
      "average reward\n",
      "0.6488456865127582\n",
      "logistic evaluation:  0.18588924279471253\n",
      "average error per step:  0.22166643271467606\n",
      "iteration:  828\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "934\n",
      "average reward\n",
      "0.6480582524271845\n",
      "logistic evaluation:  0.18588415487634882\n",
      "average error per step:  0.2216181294849134\n",
      "iteration:  829\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "876\n",
      "average reward\n",
      "0.6484848484848484\n",
      "logistic evaluation:  0.18566041847982978\n",
      "average error per step:  0.22135101828621695\n",
      "iteration:  830\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "546\n",
      "average reward\n",
      "0.648910411622276\n",
      "logistic evaluation:  0.18570670192504465\n",
      "average error per step:  0.22135435677196053\n",
      "iteration:  831\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "270\n",
      "average reward\n",
      "0.6493349455864571\n",
      "logistic evaluation:  0.18548594058132903\n",
      "average error per step:  0.22109043247254018\n",
      "iteration:  832\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "408\n",
      "average reward\n",
      "0.6485507246376812\n",
      "logistic evaluation:  0.18538770341101532\n",
      "average error per step:  0.22094928336825828\n",
      "iteration:  833\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "198\n",
      "average reward\n",
      "0.6489746682750301\n",
      "logistic evaluation:  0.18559456137457103\n",
      "average error per step:  0.2211136986883642\n",
      "iteration:  834\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "59\n",
      "average reward\n",
      "0.6481927710843374\n",
      "logistic evaluation:  0.1857229269407082\n",
      "average error per step:  0.22119962927638667\n",
      "iteration:  835\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "520\n",
      "average reward\n",
      "0.6474127557160048\n",
      "logistic evaluation:  0.18577492654062397\n",
      "average error per step:  0.22120920408260691\n",
      "iteration:  836\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "865\n",
      "average reward\n",
      "0.6466346153846154\n",
      "logistic evaluation:  0.18557066938708675\n",
      "average error per step:  0.22096231710287886\n",
      "iteration:  837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "829\n",
      "average reward\n",
      "0.6470588235294118\n",
      "logistic evaluation:  0.18534922588017627\n",
      "average error per step:  0.22069832509988394\n",
      "iteration:  838\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "727\n",
      "average reward\n",
      "0.6474820143884892\n",
      "logistic evaluation:  0.1851291646114366\n",
      "average error per step:  0.22043581853223204\n",
      "iteration:  839\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "470\n",
      "average reward\n",
      "0.6479041916167665\n",
      "logistic evaluation:  0.18492206198258884\n",
      "average error per step:  0.2201863872305003\n",
      "iteration:  840\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "596\n",
      "average reward\n",
      "0.6483253588516746\n",
      "logistic evaluation:  0.18470217863479746\n",
      "average error per step:  0.21992426077723787\n",
      "iteration:  841\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "394\n",
      "average reward\n",
      "0.6487455197132617\n",
      "logistic evaluation:  0.1844828186086809\n",
      "average error per step:  0.21966275872713967\n",
      "iteration:  842\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "246\n",
      "average reward\n",
      "0.649164677804296\n",
      "logistic evaluation:  0.1843295259964068\n",
      "average error per step:  0.21946750265556542\n",
      "iteration:  843\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "69\n",
      "average reward\n",
      "0.6495828367103695\n",
      "logistic evaluation:  0.1841111267649423\n",
      "average error per step:  0.21920716229018558\n",
      "iteration:  844\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "979\n",
      "average reward\n",
      "0.6488095238095238\n",
      "logistic evaluation:  0.1840920549942811\n",
      "average error per step:  0.21914648494215958\n",
      "iteration:  845\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "16\n",
      "average reward\n",
      "0.6492271105826397\n",
      "logistic evaluation:  0.18393471368597272\n",
      "average error per step:  0.21894747289863675\n",
      "iteration:  846\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "889\n",
      "average reward\n",
      "0.649643705463183\n",
      "logistic evaluation:  0.1837198373776201\n",
      "average error per step:  0.21869095635917182\n",
      "iteration:  847\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "151\n",
      "average reward\n",
      "0.6488730723606169\n",
      "logistic evaluation:  0.1835119120718415\n",
      "average error per step:  0.21844149735293594\n",
      "iteration:  848\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "36\n",
      "average reward\n",
      "0.6492890995260664\n",
      "logistic evaluation:  0.18329576177649604\n",
      "average error per step:  0.2181839016146937\n",
      "iteration:  849\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "97\n",
      "average reward\n",
      "0.6497041420118344\n",
      "logistic evaluation:  0.18334697470253683\n",
      "average error per step:  0.21819408164684503\n",
      "iteration:  850\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "209\n",
      "average reward\n",
      "0.6501182033096927\n",
      "logistic evaluation:  0.18313597132497905\n",
      "average error per step:  0.2179418334336145\n",
      "iteration:  851\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "780\n",
      "average reward\n",
      "0.6505312868949232\n",
      "logistic evaluation:  0.18409465805711706\n",
      "average error per step:  0.21886074675167905\n",
      "iteration:  852\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "442\n",
      "average reward\n",
      "0.6497641509433962\n",
      "logistic evaluation:  0.1839736662106541\n",
      "average error per step:  0.21869880762758578\n",
      "iteration:  853\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "104\n",
      "average reward\n",
      "0.6501766784452296\n",
      "logistic evaluation:  0.1839378901257252\n",
      "average error per step:  0.218622280173956\n",
      "iteration:  854\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "325\n",
      "average reward\n",
      "0.6505882352941177\n",
      "logistic evaluation:  0.18372276589127864\n",
      "average error per step:  0.21836628999772645\n",
      "iteration:  855\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "662\n",
      "average reward\n",
      "0.6509988249118684\n",
      "logistic evaluation:  0.18371412133537\n",
      "average error per step:  0.2183171165895811\n",
      "iteration:  856\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "692\n",
      "average reward\n",
      "0.6514084507042254\n",
      "logistic evaluation:  0.18374613126239583\n",
      "average error per step:  0.2183087398515051\n",
      "iteration:  857\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "578\n",
      "average reward\n",
      "0.6506447831184057\n",
      "logistic evaluation:  0.18354891204938678\n",
      "average error per step:  0.21807096074607818\n",
      "iteration:  858\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "258\n",
      "average reward\n",
      "0.6498829039812647\n",
      "logistic evaluation:  0.18340246061968662\n",
      "average error per step:  0.21788410313907453\n",
      "iteration:  859\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "761\n",
      "average reward\n",
      "0.6502923976608187\n",
      "logistic evaluation:  0.18361783617379276\n",
      "average error per step:  0.21805958781196383\n",
      "iteration:  860\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "317\n",
      "average reward\n",
      "0.6507009345794392\n",
      "logistic evaluation:  0.18340655539754494\n",
      "average error per step:  0.21780801281197829\n",
      "iteration:  861\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "440\n",
      "average reward\n",
      "0.6499416569428238\n",
      "logistic evaluation:  0.18320149275099107\n",
      "average error per step:  0.21756275676233386\n",
      "iteration:  862\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "57\n",
      "average reward\n",
      "0.6503496503496503\n",
      "logistic evaluation:  0.18347263200520114\n",
      "average error per step:  0.21779434830800898\n",
      "iteration:  863\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "98\n",
      "average reward\n",
      "0.6507566938300349\n",
      "logistic evaluation:  0.18326028543097903\n",
      "average error per step:  0.21754198543844847\n",
      "iteration:  864\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "584\n",
      "average reward\n",
      "0.6511627906976745\n",
      "logistic evaluation:  0.18327523938762863\n",
      "average error per step:  0.21751727880939112\n",
      "iteration:  865\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "409\n",
      "average reward\n",
      "0.6504065040650406\n",
      "logistic evaluation:  0.18316573951193776\n",
      "average error per step:  0.21736806617150664\n",
      "iteration:  866\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "80\n",
      "average reward\n",
      "0.6508120649651972\n",
      "logistic evaluation:  0.18410707356150627\n",
      "average error per step:  0.21827099260836152\n",
      "iteration:  867\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "674\n",
      "average reward\n",
      "0.6512166859791425\n",
      "logistic evaluation:  0.1850458549445232\n",
      "average error per step:  0.21917145203328867\n",
      "iteration:  868\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "166\n",
      "average reward\n",
      "0.6516203703703703\n",
      "logistic evaluation:  0.18598348795539704\n",
      "average error per step:  0.22007085006250596\n",
      "iteration:  869\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "292\n",
      "average reward\n",
      "0.6520231213872832\n",
      "logistic evaluation:  0.1858400289169915\n",
      "average error per step:  0.21988799997560154\n",
      "iteration:  870\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "790\n",
      "average reward\n",
      "0.6524249422632794\n",
      "logistic evaluation:  0.18563214850155174\n",
      "average error per step:  0.2196407450182376\n",
      "iteration:  871\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "390\n",
      "average reward\n",
      "0.6528258362168397\n",
      "logistic evaluation:  0.18542336050126326\n",
      "average error per step:  0.21939267184628786\n",
      "iteration:  872\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "852\n",
      "average reward\n",
      "0.652073732718894\n",
      "logistic evaluation:  0.18521939047950722\n",
      "average error per step:  0.21914951228167998\n",
      "iteration:  873\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "738\n",
      "average reward\n",
      "0.6513233601841196\n",
      "logistic evaluation:  0.1850225265973537\n",
      "average error per step:  0.21891355677789492\n",
      "iteration:  874\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "173\n",
      "average reward\n",
      "0.6505747126436782\n",
      "logistic evaluation:  0.18481952124250015\n",
      "average error per step:  0.21867154222906496\n",
      "iteration:  875\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "557\n",
      "average reward\n",
      "0.6509758897818599\n",
      "logistic evaluation:  0.18575003406744764\n",
      "average error per step:  0.21956443047325633\n",
      "iteration:  876\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "878\n",
      "average reward\n",
      "0.6513761467889908\n",
      "logistic evaluation:  0.1855382356779954\n",
      "average error per step:  0.21931378939568164\n",
      "iteration:  877\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "32\n",
      "average reward\n",
      "0.6517754868270332\n",
      "logistic evaluation:  0.18575831912601126\n",
      "average error per step:  0.21949561119002628\n",
      "iteration:  878\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "103\n",
      "average reward\n",
      "0.6510297482837528\n",
      "logistic evaluation:  0.1855634687405384\n",
      "average error per step:  0.21926211371748108\n",
      "iteration:  879\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "854\n",
      "average reward\n",
      "0.6502857142857142\n",
      "logistic evaluation:  0.18545474591330213\n",
      "average error per step:  0.2191149297209568\n",
      "iteration:  880\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "828\n",
      "average reward\n",
      "0.6506849315068494\n",
      "logistic evaluation:  0.18530671098671334\n",
      "average error per step:  0.21892847636398818\n",
      "iteration:  881\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "698\n",
      "average reward\n",
      "0.6499429874572406\n",
      "logistic evaluation:  0.18511112952082664\n",
      "average error per step:  0.21869450971439755\n",
      "iteration:  882\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "980\n",
      "average reward\n",
      "0.6503416856492027\n",
      "logistic evaluation:  0.1849606807678008\n",
      "average error per step:  0.21850581398977692\n",
      "iteration:  883\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "962\n",
      "average reward\n",
      "0.6507394766780432\n",
      "logistic evaluation:  0.18501716527967377\n",
      "average error per step:  0.21852437251217072\n",
      "iteration:  884\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "234\n",
      "average reward\n",
      "0.6511363636363636\n",
      "logistic evaluation:  0.18484527871762302\n",
      "average error per step:  0.21831438742772796\n",
      "iteration:  885\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "51\n",
      "average reward\n",
      "0.6515323496027242\n",
      "logistic evaluation:  0.18468182662689234\n",
      "average error per step:  0.21811293244343702\n",
      "iteration:  886\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "702\n",
      "average reward\n",
      "0.6519274376417233\n",
      "logistic evaluation:  0.1848255895886582\n",
      "average error per step:  0.21821912504080695\n",
      "iteration:  887\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "172\n",
      "average reward\n",
      "0.652321630804077\n",
      "logistic evaluation:  0.1846251950943294\n",
      "average error per step:  0.21798085689377636\n",
      "iteration:  888\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "621\n",
      "average reward\n",
      "0.6527149321266968\n",
      "logistic evaluation:  0.18492328109316641\n",
      "average error per step:  0.21824171589283795\n",
      "iteration:  889\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "843\n",
      "average reward\n",
      "0.6519774011299435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic evaluation:  0.18476269102780893\n",
      "average error per step:  0.21804346663190674\n",
      "iteration:  890\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "378\n",
      "average reward\n",
      "0.6512415349887133\n",
      "logistic evaluation:  0.18514745951730294\n",
      "average error per step:  0.218391273315654\n",
      "iteration:  891\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "400\n",
      "average reward\n",
      "0.6516347237880497\n",
      "logistic evaluation:  0.18606045294924575\n",
      "average error per step:  0.2192679807539196\n",
      "iteration:  892\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "603\n",
      "average reward\n",
      "0.652027027027027\n",
      "logistic evaluation:  0.18697191527140203\n",
      "average error per step:  0.22014323672463806\n",
      "iteration:  893\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "597\n",
      "average reward\n",
      "0.6512935883014623\n",
      "logistic evaluation:  0.18676852186831067\n",
      "average error per step:  0.21990246962069976\n",
      "iteration:  894\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "982\n",
      "average reward\n",
      "0.650561797752809\n",
      "logistic evaluation:  0.186638951719541\n",
      "average error per step:  0.21973569195749926\n",
      "iteration:  895\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "750\n",
      "average reward\n",
      "0.6509539842873177\n",
      "logistic evaluation:  0.1864472796477568\n",
      "average error per step:  0.2195068261289444\n",
      "iteration:  896\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "844\n",
      "average reward\n",
      "0.6502242152466368\n",
      "logistic evaluation:  0.1862601397208177\n",
      "average error per step:  0.21928258052521052\n",
      "iteration:  897\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "453\n",
      "average reward\n",
      "0.6506159014557671\n",
      "logistic evaluation:  0.18716522995762888\n",
      "average error per step:  0.22015186546595972\n",
      "iteration:  898\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "104\n",
      "average reward\n",
      "0.6498881431767338\n",
      "logistic evaluation:  0.18705828464181828\n",
      "average error per step:  0.22000806761025588\n",
      "iteration:  899\n",
      "estimator:  [ 0.01303255 -0.02207324 -0.03631994]\n",
      "action\n",
      "70\n",
      "average reward\n",
      "0.6502793296089385\n",
      "logistic evaluation:  0.1868732762049852\n",
      "average error per step:  0.2197862017858752\n",
      "iteration:  900\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "816\n",
      "average reward\n",
      "0.6506696428571429\n",
      "logistic evaluation:  0.17045690033874472\n",
      "average error per step:  0.21954351715596923\n",
      "iteration:  901\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "337\n",
      "average reward\n",
      "0.6510590858416946\n",
      "logistic evaluation:  0.17064115888918116\n",
      "average error per step:  0.21967350005905076\n",
      "iteration:  902\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "45\n",
      "average reward\n",
      "0.6503340757238307\n",
      "logistic evaluation:  0.17050013595127025\n",
      "average error per step:  0.2194779611964084\n",
      "iteration:  903\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "209\n",
      "average reward\n",
      "0.6496106785317018\n",
      "logistic evaluation:  0.1703143430297196\n",
      "average error per step:  0.21923772351498322\n",
      "iteration:  904\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "691\n",
      "average reward\n",
      "0.6488888888888888\n",
      "logistic evaluation:  0.1701470722657948\n",
      "average error per step:  0.2190161489333049\n",
      "iteration:  905\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "42\n",
      "average reward\n",
      "0.6492785793562708\n",
      "logistic evaluation:  0.17106119879090778\n",
      "average error per step:  0.2198772865632329\n",
      "iteration:  906\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "297\n",
      "average reward\n",
      "0.6496674057649667\n",
      "logistic evaluation:  0.1709811174503037\n",
      "average error per step:  0.21974323594104722\n",
      "iteration:  907\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "690\n",
      "average reward\n",
      "0.6489479512735327\n",
      "logistic evaluation:  0.17123749924853074\n",
      "average error per step:  0.2199461384264931\n",
      "iteration:  908\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "167\n",
      "average reward\n",
      "0.6482300884955752\n",
      "logistic evaluation:  0.17115354278348152\n",
      "average error per step:  0.21980844562262997\n",
      "iteration:  909\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "855\n",
      "average reward\n",
      "0.6475138121546962\n",
      "logistic evaluation:  0.17147940281494695\n",
      "average error per step:  0.22008113839028057\n",
      "iteration:  910\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "499\n",
      "average reward\n",
      "0.6479028697571744\n",
      "logistic evaluation:  0.1717074452702097\n",
      "average error per step:  0.2202560229410158\n",
      "iteration:  911\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "692\n",
      "average reward\n",
      "0.6482910694597575\n",
      "logistic evaluation:  0.17152297767970498\n",
      "average error per step:  0.22001806133814958\n",
      "iteration:  912\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "592\n",
      "average reward\n",
      "0.6486784140969163\n",
      "logistic evaluation:  0.17242939217798747\n",
      "average error per step:  0.22087229527814242\n",
      "iteration:  913\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "798\n",
      "average reward\n",
      "0.6490649064906491\n",
      "logistic evaluation:  0.17224079446688964\n",
      "average error per step:  0.22063043195826995\n",
      "iteration:  914\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "774\n",
      "average reward\n",
      "0.6483516483516484\n",
      "logistic evaluation:  0.17217176785195967\n",
      "average error per step:  0.22050838711127618\n",
      "iteration:  915\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "951\n",
      "average reward\n",
      "0.6487376509330406\n",
      "logistic evaluation:  0.17198514220320982\n",
      "average error per step:  0.22026873059377433\n",
      "iteration:  916\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "405\n",
      "average reward\n",
      "0.6491228070175439\n",
      "logistic evaluation:  0.17180619729989122\n",
      "average error per step:  0.22003687899472008\n",
      "iteration:  917\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "197\n",
      "average reward\n",
      "0.6484118291347207\n",
      "logistic evaluation:  0.17168917585918303\n",
      "average error per step:  0.21986713377741915\n",
      "iteration:  918\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "269\n",
      "average reward\n",
      "0.6487964989059081\n",
      "logistic evaluation:  0.171599903240999\n",
      "average error per step:  0.21972528247673356\n",
      "iteration:  919\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "39\n",
      "average reward\n",
      "0.6491803278688525\n",
      "logistic evaluation:  0.1724999898854015\n",
      "average error per step:  0.2205739814251716\n",
      "iteration:  920\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "789\n",
      "average reward\n",
      "0.648471615720524\n",
      "logistic evaluation:  0.1723156859581566\n",
      "average error per step:  0.22033722282894083\n",
      "iteration:  921\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "939\n",
      "average reward\n",
      "0.6477644492911668\n",
      "logistic evaluation:  0.17256678567578382\n",
      "average error per step:  0.22053645453662976\n",
      "iteration:  922\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "705\n",
      "average reward\n",
      "0.6481481481481481\n",
      "logistic evaluation:  0.17238042168463436\n",
      "average error per step:  0.22029786057492498\n",
      "iteration:  923\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "212\n",
      "average reward\n",
      "0.6474428726877041\n",
      "logistic evaluation:  0.1726783767997407\n",
      "average error per step:  0.22054422361660211\n",
      "iteration:  924\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "62\n",
      "average reward\n",
      "0.6478260869565218\n",
      "logistic evaluation:  0.17290288806626225\n",
      "average error per step:  0.22071717499616442\n",
      "iteration:  925\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "365\n",
      "average reward\n",
      "0.6471226927252985\n",
      "logistic evaluation:  0.17281669635542388\n",
      "average error per step:  0.2205791989840928\n",
      "iteration:  926\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "179\n",
      "average reward\n",
      "0.6475054229934925\n",
      "logistic evaluation:  0.17289768536534858\n",
      "average error per step:  0.2206086960786625\n",
      "iteration:  927\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "795\n",
      "average reward\n",
      "0.6468039003250271\n",
      "logistic evaluation:  0.17279140631688097\n",
      "average error per step:  0.2204508341933429\n",
      "iteration:  928\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "366\n",
      "average reward\n",
      "0.6471861471861472\n",
      "logistic evaluation:  0.17262994628285525\n",
      "average error per step:  0.22023784303010327\n",
      "iteration:  929\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "440\n",
      "average reward\n",
      "0.6464864864864864\n",
      "logistic evaluation:  0.1726936030488689\n",
      "average error per step:  0.22025032192746116\n",
      "iteration:  930\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "48\n",
      "average reward\n",
      "0.6468682505399568\n",
      "logistic evaluation:  0.17252534098650363\n",
      "average error per step:  0.2200307426812884\n",
      "iteration:  931\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "916\n",
      "average reward\n",
      "0.6472491909385113\n",
      "logistic evaluation:  0.17341292088432866\n",
      "average error per step:  0.2208682497307816\n",
      "iteration:  932\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "343\n",
      "average reward\n",
      "0.6476293103448276\n",
      "logistic evaluation:  0.17322877604851192\n",
      "average error per step:  0.22063298957985508\n",
      "iteration:  933\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "639\n",
      "average reward\n",
      "0.6480086114101185\n",
      "logistic evaluation:  0.17308755081378843\n",
      "average error per step:  0.2204408046036889\n",
      "iteration:  934\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "717\n",
      "average reward\n",
      "0.6483870967741936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic evaluation:  0.17299713490272495\n",
      "average error per step:  0.2202995924723888\n",
      "iteration:  935\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "200\n",
      "average reward\n",
      "0.6487647690655209\n",
      "logistic evaluation:  0.17282298613325367\n",
      "average error per step:  0.22007466658383823\n",
      "iteration:  936\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "225\n",
      "average reward\n",
      "0.648068669527897\n",
      "logistic evaluation:  0.17264382945600074\n",
      "average error per step:  0.21984483593529489\n",
      "iteration:  937\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "469\n",
      "average reward\n",
      "0.6484458735262594\n",
      "logistic evaluation:  0.17274918720770863\n",
      "average error per step:  0.21989993152187196\n",
      "iteration:  938\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "849\n",
      "average reward\n",
      "0.6488222698072805\n",
      "logistic evaluation:  0.1725662419492483\n",
      "average error per step:  0.21966652390779048\n",
      "iteration:  939\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "842\n",
      "average reward\n",
      "0.6491978609625668\n",
      "logistic evaluation:  0.17284534395096948\n",
      "average error per step:  0.21989576309805606\n",
      "iteration:  940\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "824\n",
      "average reward\n",
      "0.6485042735042735\n",
      "logistic evaluation:  0.17275677893654742\n",
      "average error per step:  0.21975705022814304\n",
      "iteration:  941\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "107\n",
      "average reward\n",
      "0.6488794023479189\n",
      "logistic evaluation:  0.17257802105893383\n",
      "average error per step:  0.2195281552313273\n",
      "iteration:  942\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "273\n",
      "average reward\n",
      "0.6481876332622601\n",
      "logistic evaluation:  0.17244189947858052\n",
      "average error per step:  0.21934204824147\n",
      "iteration:  943\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "852\n",
      "average reward\n",
      "0.6474973375931843\n",
      "logistic evaluation:  0.17235242449634652\n",
      "average error per step:  0.21920274332949571\n",
      "iteration:  944\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "849\n",
      "average reward\n",
      "0.6478723404255319\n",
      "logistic evaluation:  0.17217781725855563\n",
      "average error per step:  0.21897832155137542\n",
      "iteration:  945\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "264\n",
      "average reward\n",
      "0.6482465462274176\n",
      "logistic evaluation:  0.17199581116817292\n",
      "average error per step:  0.21874659851878825\n",
      "iteration:  946\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "518\n",
      "average reward\n",
      "0.648619957537155\n",
      "logistic evaluation:  0.17220475569225652\n",
      "average error per step:  0.2189063444775161\n",
      "iteration:  947\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "20\n",
      "average reward\n",
      "0.647932131495228\n",
      "logistic evaluation:  0.17214909640340414\n",
      "average error per step:  0.21880131111466786\n",
      "iteration:  948\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "618\n",
      "average reward\n",
      "0.6483050847457628\n",
      "logistic evaluation:  0.1719682247105095\n",
      "average error per step:  0.21857103743189538\n",
      "iteration:  949\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "906\n",
      "average reward\n",
      "0.6486772486772486\n",
      "logistic evaluation:  0.17178720552944748\n",
      "average error per step:  0.21834072021932394\n",
      "iteration:  950\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "810\n",
      "average reward\n",
      "0.6479915433403806\n",
      "logistic evaluation:  0.1716901964790153\n",
      "average error per step:  0.21819460535442828\n",
      "iteration:  951\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "625\n",
      "average reward\n",
      "0.6473072861668426\n",
      "logistic evaluation:  0.17157132132340389\n",
      "average error per step:  0.2180267046635582\n",
      "iteration:  952\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "352\n",
      "average reward\n",
      "0.6476793248945147\n",
      "logistic evaluation:  0.1713912884588633\n",
      "average error per step:  0.21779768501728997\n",
      "iteration:  953\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "167\n",
      "average reward\n",
      "0.6480505795574288\n",
      "logistic evaluation:  0.17129508359394335\n",
      "average error per step:  0.21765268413828467\n",
      "iteration:  954\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "469\n",
      "average reward\n",
      "0.6484210526315789\n",
      "logistic evaluation:  0.17111571701484768\n",
      "average error per step:  0.21742453667121894\n",
      "iteration:  955\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "43\n",
      "average reward\n",
      "0.647739221871714\n",
      "logistic evaluation:  0.1712814894369285\n",
      "average error per step:  0.21754199176635286\n",
      "iteration:  956\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "732\n",
      "average reward\n",
      "0.648109243697479\n",
      "logistic evaluation:  0.17156560915297805\n",
      "average error per step:  0.21777801903197\n",
      "iteration:  957\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "53\n",
      "average reward\n",
      "0.6484784889821616\n",
      "logistic evaluation:  0.1724299134855222\n",
      "average error per step:  0.21859493767428798\n",
      "iteration:  958\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "733\n",
      "average reward\n",
      "0.6477987421383647\n",
      "logistic evaluation:  0.17225582545806925\n",
      "average error per step:  0.21837247896602477\n",
      "iteration:  959\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "644\n",
      "average reward\n",
      "0.6471204188481675\n",
      "logistic evaluation:  0.17219920653006365\n",
      "average error per step:  0.21826771272578147\n",
      "iteration:  960\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "978\n",
      "average reward\n",
      "0.6464435146443515\n",
      "logistic evaluation:  0.17228799017788973\n",
      "average error per step:  0.21830860082928683\n",
      "iteration:  961\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "576\n",
      "average reward\n",
      "0.6468129571577848\n",
      "logistic evaluation:  0.17214753964054907\n",
      "average error per step:  0.21812011588904426\n",
      "iteration:  962\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "286\n",
      "average reward\n",
      "0.6471816283924844\n",
      "logistic evaluation:  0.17201962289700096\n",
      "average error per step:  0.21794427763510943\n",
      "iteration:  963\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "263\n",
      "average reward\n",
      "0.6475495307612096\n",
      "logistic evaluation:  0.17287793357859413\n",
      "average error per step:  0.2187557904516387\n",
      "iteration:  964\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "961\n",
      "average reward\n",
      "0.6479166666666667\n",
      "logistic evaluation:  0.17272014144098294\n",
      "average error per step:  0.21855024349140234\n",
      "iteration:  965\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "637\n",
      "average reward\n",
      "0.6482830385015609\n",
      "logistic evaluation:  0.17357585257195798\n",
      "average error per step:  0.21935934903593238\n",
      "iteration:  966\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "65\n",
      "average reward\n",
      "0.6476091476091476\n",
      "logistic evaluation:  0.17361027688164124\n",
      "average error per step:  0.21934641405767125\n",
      "iteration:  967\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "792\n",
      "average reward\n",
      "0.6479750778816199\n",
      "logistic evaluation:  0.17350938164405144\n",
      "average error per step:  0.21919811754561025\n",
      "iteration:  968\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "358\n",
      "average reward\n",
      "0.6483402489626556\n",
      "logistic evaluation:  0.17333180666851966\n",
      "average error per step:  0.21897316001751949\n",
      "iteration:  969\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "41\n",
      "average reward\n",
      "0.6476683937823834\n",
      "logistic evaluation:  0.1731587184707401\n",
      "average error per step:  0.21875279169430467\n",
      "iteration:  970\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "154\n",
      "average reward\n",
      "0.6469979296066253\n",
      "logistic evaluation:  0.17315099928041114\n",
      "average error per step:  0.21869806034684797\n",
      "iteration:  971\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "169\n",
      "average reward\n",
      "0.6463288521199586\n",
      "logistic evaluation:  0.17297741601090016\n",
      "average error per step:  0.2184773909348695\n",
      "iteration:  972\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "486\n",
      "average reward\n",
      "0.6466942148760331\n",
      "logistic evaluation:  0.17279963868222\n",
      "average error per step:  0.21825262003391294\n",
      "iteration:  973\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "802\n",
      "average reward\n",
      "0.6460268317853457\n",
      "logistic evaluation:  0.1730744424410362\n",
      "average error per step:  0.21848099195553194\n",
      "iteration:  974\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "545\n",
      "average reward\n",
      "0.6453608247422681\n",
      "logistic evaluation:  0.1733109528043625\n",
      "average error per step:  0.21867112650864146\n",
      "iteration:  975\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "623\n",
      "average reward\n",
      "0.6457260556127703\n",
      "logistic evaluation:  0.17313338011881538\n",
      "average error per step:  0.21844684844218168\n",
      "iteration:  976\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "713\n",
      "average reward\n",
      "0.6450617283950617\n",
      "logistic evaluation:  0.17309913391138326\n",
      "average error per step:  0.2183661394124844\n",
      "iteration:  977\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "156\n",
      "average reward\n",
      "0.645426515930113\n",
      "logistic evaluation:  0.17394455672309325\n",
      "average error per step:  0.21916609489288488\n",
      "iteration:  978\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "41\n",
      "average reward\n",
      "0.6447638603696099\n",
      "logistic evaluation:  0.1737686084365151\n",
      "average error per step:  0.2189437279084986\n",
      "iteration:  979\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "509\n",
      "average reward\n",
      "0.6451282051282051\n",
      "logistic evaluation:  0.17405054618059523\n",
      "average error per step:  0.21917980949146748\n",
      "iteration:  980\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "902\n",
      "average reward\n",
      "0.6454918032786885\n",
      "logistic evaluation:  0.17388095773856407\n",
      "average error per step:  0.2189639977313211\n",
      "iteration:  981\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "220\n",
      "average reward\n",
      "0.6448311156601843\n",
      "logistic evaluation:  0.17374704761889348\n",
      "average error per step:  0.21878399490001704\n",
      "iteration:  982\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "298\n",
      "average reward\n",
      "0.6451942740286298\n",
      "logistic evaluation:  0.17458741874592684\n",
      "average error per step:  0.21957935933035583\n",
      "iteration:  983\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "877\n",
      "average reward\n",
      "0.644535240040858\n",
      "logistic evaluation:  0.17447182427062094\n",
      "average error per step:  0.21941787723037065\n",
      "iteration:  984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "493\n",
      "average reward\n",
      "0.6448979591836734\n",
      "logistic evaluation:  0.17429469559253433\n",
      "average error per step:  0.21919489166037565\n",
      "iteration:  985\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "993\n",
      "average reward\n",
      "0.6442405708460754\n",
      "logistic evaluation:  0.17448084406335143\n",
      "average error per step:  0.21933564515901305\n",
      "iteration:  986\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "193\n",
      "average reward\n",
      "0.6446028513238289\n",
      "logistic evaluation:  0.1743047414165724\n",
      "average error per step:  0.21911387222446277\n",
      "iteration:  987\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "473\n",
      "average reward\n",
      "0.6439471007121058\n",
      "logistic evaluation:  0.17418047066571263\n",
      "average error per step:  0.21894407624406018\n",
      "iteration:  988\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "430\n",
      "average reward\n",
      "0.6443089430894309\n",
      "logistic evaluation:  0.17501498422904765\n",
      "average error per step:  0.2197341271636553\n",
      "iteration:  989\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "675\n",
      "average reward\n",
      "0.6446700507614214\n",
      "logistic evaluation:  0.1748632555444992\n",
      "average error per step:  0.21953702853813703\n",
      "iteration:  990\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "951\n",
      "average reward\n",
      "0.6440162271805274\n",
      "logistic evaluation:  0.174992263216248\n",
      "average error per step:  0.2196210414974395\n",
      "iteration:  991\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "884\n",
      "average reward\n",
      "0.6433637284701115\n",
      "logistic evaluation:  0.17495488357713823\n",
      "average error per step:  0.219538590054172\n",
      "iteration:  992\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "845\n",
      "average reward\n",
      "0.6437246963562753\n",
      "logistic evaluation:  0.1748856027764814\n",
      "average error per step:  0.2194242961615014\n",
      "iteration:  993\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "302\n",
      "average reward\n",
      "0.6440849342770475\n",
      "logistic evaluation:  0.1747911267036752\n",
      "average error per step:  0.21928487228460872\n",
      "iteration:  994\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "868\n",
      "average reward\n",
      "0.6434343434343435\n",
      "logistic evaluation:  0.17482762429026436\n",
      "average error per step:  0.21927664426959392\n",
      "iteration:  995\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "824\n",
      "average reward\n",
      "0.6427850655903128\n",
      "logistic evaluation:  0.17465754140465126\n",
      "average error per step:  0.21906171806451857\n",
      "iteration:  996\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "54\n",
      "average reward\n",
      "0.6431451612903226\n",
      "logistic evaluation:  0.17451636744888485\n",
      "average error per step:  0.2188758198611461\n",
      "iteration:  997\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "224\n",
      "average reward\n",
      "0.6435045317220544\n",
      "logistic evaluation:  0.1747196310001278\n",
      "average error per step:  0.21903479435635995\n",
      "iteration:  998\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "543\n",
      "average reward\n",
      "0.6438631790744467\n",
      "logistic evaluation:  0.17467057349910584\n",
      "average error per step:  0.21894128372822652\n",
      "iteration:  999\n",
      "estimator:  [ 0.01506109 -0.02583264 -0.0440754 ]\n",
      "action\n",
      "86\n",
      "average reward\n",
      "0.6432160804020101\n",
      "logistic evaluation:  0.17450357754885404\n",
      "average error per step:  0.21872980558960695\n"
     ]
    }
   ],
   "source": [
    "mean_reward = contextual_bandit(data, mode='robust-logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def max_reward(data):\n",
    "    est = data['reg']\n",
    "    cov = data['cov']\n",
    "    lab = data['label']\n",
    "    \n",
    "    (N,d,k) = cov.shape\n",
    "    cum_reward = 0\n",
    "    for i in range(N):\n",
    "        values = []\n",
    "        for j in range(k):\n",
    "            values.append(expit(np.inner(est,cov[i,:,j])))\n",
    "        cum_reward += max(values)\n",
    "    return cum_reward/N\n",
    "\n",
    "print(max_reward(data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 6 3]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "a[:2] = np.array([5,6])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.52697291  1.76998695 -0.58336886]\n",
      "(2, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "b = np.random.normal(0,1,(2,3,4))\n",
    "print(b[0,:,0])\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
