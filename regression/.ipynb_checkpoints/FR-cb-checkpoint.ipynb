{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "# mosek only needed if we don't use MW\n",
    "#import mosek\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cProfile\n",
    "#from baselines import *\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "from scipy.special import expit,logit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of corruptions\n",
      "100\n",
      "[[-0.01053842 -0.00529271]]\n",
      "[[-0.90421277 -0.42708226]]\n",
      "score\n",
      "0.741\n"
     ]
    }
   ],
   "source": [
    "#synthetic example with N datapoints, in d dimensions, with k actions, random regressors\n",
    "#returns a dictionary of covariates x, labels y, regressors ell.  \n",
    "def synthetic_example(N,d,k):\n",
    "    #covariates\n",
    "    x = np.random.normal(0,1,(N,d))\n",
    "    #regressors\n",
    "    ell = np.random.normal(0,1,(k,d))\n",
    "    #labels\n",
    "    y = np.zeros((N,k))\n",
    "    for i in range(N):\n",
    "        for j in range(k):\n",
    "            feature = x[i,:]\n",
    "            regressor = ell[j,:]\n",
    "            y[i,j] = np.inner(feature,regressor) + np.random.normal(0,1)\n",
    "    data = {'cov': x, 'label': y, 'reg': ell}\n",
    "    return data\n",
    "\n",
    "from scipy.special import logit, expit\n",
    "\n",
    "def logistic_synthetic_example(N,d,k,eta,corrupt=False):\n",
    "    #covariates, scaling the covariates to be of large norm amplifies the effect of corruptions\n",
    "    #good parameters: scale x by 100, d = 100, N = 1000\n",
    "    x = np.random.normal(0,1,(N,d))*100\n",
    "    #regressors\n",
    "    ell = np.random.normal(0,1,(k,d))\n",
    "    ell = ell/np.linalg.norm(ell)\n",
    "    #labels\n",
    "    y = np.zeros((N,k))\n",
    "    prob_list = np.zeros((N,k))\n",
    "    for i in range(N):\n",
    "        for j in range(k):\n",
    "            feature = x[i,:]\n",
    "            regressor = ell[j,:]\n",
    "            prob = expit(np.inner(feature,regressor))\n",
    "            prob_list[i,j] = prob\n",
    "            y[i,j] = np.random.binomial(1,prob)\n",
    "            #deterministic labels\n",
    "            #if prob > 0.5:\n",
    "            #    y[i,j] = 1\n",
    "            #else:\n",
    "            #    y[i,j] = 0\n",
    "    if corrupt:\n",
    "        corr = int(eta*N)\n",
    "        print('number of corruptions')\n",
    "        print(corr)\n",
    "        poison = False\n",
    "        if poison:\n",
    "            print('TODO: poisoning')\n",
    "        else: \n",
    "            select = np.zeros((corr,k))\n",
    "            for j in range(k):\n",
    "                order = np.argsort(prob_list[:,j])\n",
    "                select[:,j] = order[:corr]\n",
    "            for i in range(corr):\n",
    "                for j in range(k):\n",
    "                    index = int(select[i,j])\n",
    "                    y[index,j] = 1 - y[index,j]\n",
    "    data = {'cov': x, 'label': y, 'reg': ell}\n",
    "    return data\n",
    "\n",
    "#data = synthetic_example(1000,100,10)    \n",
    "#print(data)\n",
    "\n",
    "import pandas as pd, numpy as np, re\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "def parse_data(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        infoline = f.readline()\n",
    "        infoline = re.sub(r\"^b'\", \"\", str(infoline))\n",
    "        n_features = int(re.sub(r\"^\\d+\\s(\\d+)\\s\\d+.*$\", r\"\\1\", infoline))\n",
    "        features, labels = load_svmlight_file(f, n_features=n_features, multilabel=True)\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    labels = mlb.fit_transform(labels)\n",
    "    features = np.array(features.todense())\n",
    "    features = np.ascontiguousarray(features)\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "data_mode = 'logistic_synth'\n",
    "#data_mode = 'synthetic'\n",
    "#data_mode = 'real'\n",
    "N = 1000\n",
    "d = 2\n",
    "k = 1\n",
    "eta = 0.1\n",
    "\n",
    "if data_mode == 'logistic_synth':\n",
    "    data = logistic_synthetic_example(N,d,k,eta,corrupt=True)\n",
    "    #data = logistic_synthetic_example(N,d,k,eta,corrupt=False)\n",
    "if data_mode == 'synthetic':\n",
    "    data = synthetic_example(1000,10,10)    \n",
    "elif data_mode == 'real': \n",
    "    x, y = parse_data(\"Bibtex_data.txt\")\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    data = {'cov': x, 'label': y}\n",
    "\n",
    "x = data['cov']\n",
    "y = data['label']\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', random_state=0, fit_intercept ='False')\n",
    "#a = np.zeros((2,3)).reshape(-1,1)\n",
    "#b = np.ones(2)\n",
    "\n",
    "#a = np.zeros(10,2).reshape(-1, 1)\n",
    "#b = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
    "lab = y[:,0]\n",
    "model.fit(x, lab)\n",
    "print(model.coef_)\n",
    "print(data['reg'])\n",
    "print('score')\n",
    "print(model.score(x,lab))\n",
    "\n",
    "vanilla = model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first length of a: 1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "non robust performance:  [0.37888619]\n",
      "robust performance:  [0.19828245]\n",
      "vanilla:  [[-0.01053842 -0.00529271]]\n",
      "reg:  [-0.04817483 -0.02246682]\n"
     ]
    }
   ],
   "source": [
    "#logistic regression version of scram\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "def logistic_reg_oracle(x,y,mode='robust-logistic'):\n",
    "    if mode == 'robust-logistic':\n",
    "        lr = 0.1\n",
    "        #lam = 0.2\n",
    "        #BUG FIX for lam > 0\n",
    "        lam = 0.0\n",
    "        MW_steps = 30\n",
    "        #eta = 0.1\n",
    "        AM_steps = 30\n",
    "        params = (AM_steps,lr,lam,MW_steps,eta)\n",
    "        #print('enerting logistic scram')\n",
    "        regressor = logistic_scram(x,y,params)\n",
    "    return regressor\n",
    "\n",
    "def logistic_scram(x,y,params):\n",
    "    AM_steps = params[0]\n",
    "    altmin_params = params[1:]\n",
    "    N,d = x.shape\n",
    "    w = [0.]*d\n",
    "    a = [1.]*N\n",
    "    print('first length of a:', len(a))\n",
    "    #TODO: fix isotropic step, for now identity covariance\n",
    "    #iso_x, Sig_sqrt = isotropic(x)\n",
    "    iso_x = x\n",
    "    Sig_sqrt = np.eye(d)\n",
    "    for i in range(AM_steps):\n",
    "        #print('AM step: ',i)\n",
    "        #print('entering logistic altmin step')\n",
    "        w,a = logistic_altmin_step(iso_x,y,a,altmin_params)\n",
    "    final_w = np.matmul(Sig_sqrt,w)    \n",
    "    return final_w\n",
    "\n",
    "def logistic_altmin_step(Xs,Ys,a,params):\n",
    "    N,d = Xs.shape\n",
    "    w = weighted_logistic_reg(Xs,Ys,a)\n",
    "    a = logistic_get_weights(Xs,Ys,w,params)\n",
    "    return w, a\n",
    "\n",
    "def weighted_logistic_reg(x,y,a):\n",
    "    n,d = x.shape\n",
    "    hard_weights = np.zeros(n)\n",
    "    m = min(int(n*(1 - eta))+1,n) \n",
    "    prob = a*m\n",
    "    print(\"length of a: \", len(a))\n",
    "    for i in range(len(a)):\n",
    "        ind = np.random.binomial(1,prob[i])\n",
    "        hard_weights[i] = ind\n",
    "    \n",
    "    N_train = int(np.sum(hard_weights))\n",
    "    #print('N_train: ',N_train)\n",
    "    x_train = np.zeros((N_train,d)) \n",
    "    y_train = np.zeros(N_train)\n",
    "    \n",
    "    hold = 0\n",
    "    for i in range(len(a)):\n",
    "        if hard_weights[i] == 1:\n",
    "            x_train[hold,:] = x[i,:]\n",
    "            y_train[hold] = y[i]\n",
    "            hold = hold + 1\n",
    "    model = LogisticRegression(solver='liblinear', random_state=0, fit_intercept ='False')\n",
    "    #lab = y[:,0]\n",
    "    model.fit(x_train, y_train)\n",
    "    #print('regressor shape: ', model.coef_.shape)\n",
    "    regressor = model.coef_[0,:]\n",
    "    #print('regressor shape: ', regressor.shape)\n",
    "    return regressor\n",
    "\n",
    "def logistic_get_weights(X,y,w,params):\n",
    "    n,d = X.shape\n",
    "    lr,lam,steps,eta = params\n",
    "    a = np.ones(n)/float(n)\n",
    "    #Sig = np.cov(X.T)\n",
    "    Sig = np.matmul(X.T,X)\n",
    "    Xw = np.matmul(X,w)\n",
    "    pred = expit(Xw)\n",
    "    resids = np.absolute(y - pred)\n",
    "\n",
    "    #print(\"begin MW\")\n",
    "    for j in range(steps):\n",
    "        #if j % 10 == 0:\n",
    "        #    print(j)\n",
    "        if lam > 0:\n",
    "            v = v_step(a,X,Sig,eta)\n",
    "        else:\n",
    "            v = np.zeros(d)\n",
    "        a = a_step(a,X,resids,v,lr=lr,lam=lam,eta=eta,n=n)\n",
    "    return a\n",
    "\n",
    "def outerprod(a,X):\n",
    "    \"\"\" Compute X^T diag(a) X \"\"\"\n",
    "    left = np.multiply(X.T,a)\n",
    "    return np.dot(left,X)\n",
    "\n",
    "def cap(a,m):\n",
    "    if np.max(a) <= 1./m:\n",
    "        return a\n",
    "    ## BUG FIX: use -a to get descending order\n",
    "    sort_ids = np.argsort(-a)\n",
    "    # Faster code\n",
    "    Z = np.sum(a)\n",
    "    for i in range(1,m):\n",
    "        Z -= a[sort_ids[i - 1]]\n",
    "        aprime_next = (m - i) * a[sort_ids[i]]/float(m * Z)\n",
    "        if aprime_next <= 1.0/m:\n",
    "            aprime = np.copy(a)\n",
    "            aprime[sort_ids[:i]] = 1./m\n",
    "            aprime[sort_ids[i:]] *= (m - i)/float(m * Z)\n",
    "            return aprime\n",
    "\n",
    "def v_step(a,X,Sig,eta,tol=0):\n",
    "    \"\"\" Compute top eigenvector of X^T diag(1/n-a) X\"\"\"\n",
    "    # Bug fix: this was formerly 1 and not 1/n\n",
    "    n = a.shape[0]\n",
    "    #m = int(n*(1 - eta)) \n",
    "    M = outerprod(1./n-a,X)\n",
    "    # this method is slower sometimes and faster sometimes vs other one, depending on d?\n",
    "    d = M.shape[0]\n",
    "\n",
    "    # Want top eigenvalue algebraically\n",
    "    eigenvalue, v = eigh(M, eigvals=(d-1,d-1)) \n",
    "    \n",
    "    ## Don't regularize if constraint is satisfied\n",
    "    if eigenvalue > 0:\n",
    "        return v[:,0]\n",
    "    else:\n",
    "        return np.zeros(shape=v[:,0].shape)\n",
    "    \n",
    "# @jit(nopython=True)\n",
    "def a_step(a,X,resids_sq,v,lr,lam,eta,n):\n",
    "    \"\"\" Step to minimize \\sum_i a_i resids_sq[i]^2 + \\lambda sigma_{max}(X^T diag(1/n - a) X)\"\"\"\n",
    "    m = min(int(n*(1 - eta))+1,n) \n",
    "    \n",
    "    Xv_squared = np.dot(X,v)**2\n",
    "    penalties = resids_sq - lam * Xv_squared\n",
    "\n",
    "    a *= np.exp(-lr * penalties)\n",
    "    a /= np.sum(a)\n",
    "    a = cap(a,m)\n",
    "    return a\n",
    "\n",
    "def logistic_eval(x,y,reg):\n",
    "    n,d = x.shape\n",
    "    error = 0\n",
    "    for i in range(n):\n",
    "        error = error + np.absolute(y[i] - expit(np.inner(reg,x[i,:])))\n",
    "        \n",
    "    error = error/n\n",
    "    return error \n",
    "    \n",
    "reg = logistic_reg_oracle(x,y[:,0])\n",
    "print('non robust performance: ', logistic_eval(x,y,vanilla))\n",
    "print('robust performance: ',logistic_eval(x,y,reg))\n",
    "print('vanilla: ', vanilla)\n",
    "print('reg: ', reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init dv_out:  (5, 5)\n",
      "init dr_out:  (5, 5)\n",
      "number of corruptions\n",
      "50\n",
      "first length of a: 1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "TIME:  3.644667\n",
      "corruption level:  0.05\n",
      "non robust performance:  [0.25984503]\n",
      "robust performance:  [0.12090022]\n",
      "number of corruptions\n",
      "100\n",
      "first length of a: 1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "TIME:  4.263446\n",
      "corruption level:  0.1\n",
      "non robust performance:  [0.35900346]\n",
      "robust performance:  [0.22500155]\n",
      "number of corruptions\n",
      "150\n",
      "first length of a: 1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "TIME:  4.266987\n",
      "corruption level:  0.15\n",
      "non robust performance:  [0.41427405]\n",
      "robust performance:  [0.33782825]\n",
      "number of corruptions\n",
      "200\n",
      "first length of a: 1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "TIME:  4.280716999999999\n",
      "corruption level:  0.2\n",
      "non robust performance:  [0.429516]\n",
      "robust performance:  [0.38568884]\n",
      "number of corruptions\n",
      "250\n",
      "first length of a: 1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "TIME:  4.149550000000001\n",
      "corruption level:  0.25\n",
      "non robust performance:  [0.4506488]\n",
      "robust performance:  [0.42358479]\n",
      "dv_out:  (5, 5)\n",
      "dr_out:  (5, 5)\n",
      "number of corruptions\n",
      "50\n",
      "first length of a: 1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:41: DeprecationWarning: setting an array element with a sequence. This was supported in some cases where the elements are arrays with a single element. For example `np.array([1, np.array([2])], dtype=int)`. In the future this will raise the same ValueError as `np.array([1, [2]], dtype=int)`.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:42: DeprecationWarning: setting an array element with a sequence. This was supported in some cases where the elements are arrays with a single element. For example `np.array([1, np.array([2])], dtype=int)`. In the future this will raise the same ValueError as `np.array([1, [2]], dtype=int)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "TIME:  7.966384999999999\n",
      "corruption level:  0.05\n",
      "non robust performance:  [0.24930694]\n",
      "robust performance:  [0.10200361]\n",
      "number of corruptions\n",
      "100\n",
      "first length of a: 1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "TIME:  7.126123\n",
      "corruption level:  0.1\n",
      "non robust performance:  [0.35126795]\n",
      "robust performance:  [0.19998097]\n",
      "number of corruptions\n",
      "150\n",
      "first length of a: 1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "TIME:  7.187290000000004\n",
      "corruption level:  0.15\n",
      "non robust performance:  [0.37730209]\n",
      "robust performance:  [0.31300075]\n",
      "number of corruptions\n",
      "200\n",
      "first length of a: 1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "TIME:  7.584523999999995\n",
      "corruption level:  0.2\n",
      "non robust performance:  [0.40534157]\n",
      "robust performance:  [0.3712365]\n",
      "number of corruptions\n",
      "250\n",
      "first length of a: 1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n",
      "length of a:  1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1b2b4624ca72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdr_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdv_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mrob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnrob\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'robust: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'non robust: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-1b2b4624ca72>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_reg_oracle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TIME: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mv_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvanilla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-a84c03cf0970>\u001b[0m in \u001b[0;36mlogistic_reg_oracle\u001b[0;34m(x, y, mode)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAM_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMW_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#print('enerting logistic scram')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mregressor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_scram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-a84c03cf0970>\u001b[0m in \u001b[0;36mlogistic_scram\u001b[0;34m(x, y, params)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#print('AM step: ',i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m#print('entering logistic altmin step')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_altmin_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miso_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maltmin_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mfinal_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSig_sqrt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfinal_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-a84c03cf0970>\u001b[0m in \u001b[0;36mlogistic_altmin_step\u001b[0;34m(Xs, Ys, a, params)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted_logistic_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_get_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-a84c03cf0970>\u001b[0m in \u001b[0;36mlogistic_get_weights\u001b[0;34m(X, y, w, params)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-a84c03cf0970>\u001b[0m in \u001b[0;36ma_step\u001b[0;34m(a, X, resids_sq, v, lr, lam, eta, n)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;31m#print('m: ', m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;31m#print('a step a shape: ', a.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     \u001b[0;31m#print('cap step a shape: ', a.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-a84c03cf0970>\u001b[0m in \u001b[0;36mcap\u001b[0;34m(a, m)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;31m#print('m: ', m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;31m#print('a: ', a)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;31m#sorted_a = np.sort(a)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#plot experiments for logistic regression\n",
    "d_list = [50,100,150,200,250]\n",
    "eta_list = [0.05,0.1,0.15,0.2,0.25]\n",
    "\n",
    "def run_experiment():\n",
    "    N = 1000\n",
    "    k = 1\n",
    "    dv_out = np.zeros((len(d_list),len(eta_list)))\n",
    "    dr_out = np.zeros((len(d_list),len(eta_list)))\n",
    "    print(\"init dv_out: \", dv_out.shape)\n",
    "    print('init dr_out: ', dr_out.shape)\n",
    "    index = 0\n",
    "    for d in d_list: \n",
    "        results_robust = []\n",
    "        results_vanilla = []\n",
    "        for eta in eta_list: \n",
    "            data = logistic_synthetic_example(N,d,k,eta,corrupt=True)\n",
    "            #data = logistic_synthetic_example(N,d,k,eta,corrupt=False)\n",
    "            x = data['cov']\n",
    "            y = data['label']\n",
    "            #run vanilla logistic regression\n",
    "            from sklearn.linear_model import LogisticRegression\n",
    "            model = LogisticRegression(solver='liblinear', random_state=0, fit_intercept ='False')\n",
    "            lab = y[:,0]\n",
    "            model.fit(x, lab)\n",
    "            vanilla = model.coef_\n",
    "            #run robust logistic regression\n",
    "            import time\n",
    "            start = time.process_time()\n",
    "            reg = logistic_reg_oracle(x,lab)\n",
    "            print('TIME: ',time.process_time() - start)\n",
    "            v_out = logistic_eval(x,y,vanilla)\n",
    "            r_out = logistic_eval(x,y,reg)\n",
    "            results_robust.append(r_out)\n",
    "            results_vanilla.append(v_out)\n",
    "            print('corruption level: ',eta)\n",
    "            print('non robust performance: ', v_out)\n",
    "            print('robust performance: ', r_out)\n",
    "        print(\"dv_out: \", dv_out.shape)\n",
    "        print('dr_out: ', dr_out.shape)\n",
    "        dv_out[index,:] = results_vanilla\n",
    "        dr_out[index,:] = results_robust\n",
    "        index = index + 1\n",
    "    return (dr_out,dv_out)  \n",
    "\n",
    "(rob,nrob) = run_experiment()\n",
    "print('robust: ', rob)\n",
    "print('non robust: ', nrob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(2,2)\n",
    " \n",
    "# Accessing each axes object to plot the data through returned array\n",
    "for i in range(2):\n",
    "    for j in range(2): \n",
    "        ax[i,j].plot(eta_list,rob[i,:],label='robust')\n",
    "        ax[i,j].plot(eta_list,nrob[i,:],label='logistic')\n",
    "        ax[i,j].set(xlabel = 'fraction corrupted', ylabel='fraction misclassified')\n",
    "        ax[i,j].legend(loc='lower right', shadow=True)\n",
    "        ax[i,j].set_title('Logistic Regression vs. Logistic SCRAM dim=' + str(d_list[i]))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(d_list)):\n",
    "    plt.plot(eta_list,rob[i,:],label='robust')\n",
    "    plt.plot(eta_list,nrob[i,:],label='logistic')\n",
    "    plt.xlabel('fraction corrupted')\n",
    "    plt.ylabel('fraction misclassified')\n",
    "    plt.legend(loc='lower right', shadow=True)\n",
    "    plt.title('Logistic Regression vs. Logistic SCRAM dim=' + str(d_list[i]))\n",
    "    plt.savefig('sample' + str(i) + '.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Reward\n",
      "0.586\n"
     ]
    }
   ],
   "source": [
    "from mw2 import MW_no_alt_min, get_weights, altmin_step\n",
    "\n",
    "def isotropic(Xs,fake=False):\n",
    "    if fake:\n",
    "        return Xs, np.eye(Xs.shape[1])\n",
    "    Sig = np.matmul(Xs.T,Xs)\n",
    "    Sig_sqrt = np.linalg.inv(sqrtm(Sig))\n",
    "    new_Xs = np.matmul(Xs,Sig_sqrt)\n",
    "    return new_Xs, Sig_sqrt\n",
    "\n",
    "def scram(x,y,params):\n",
    "    AM_steps = params[0]\n",
    "    altmin_params = params[1:]\n",
    "    N,d = x.shape\n",
    "    w = [0.]*d\n",
    "    a = [1.]*N\n",
    "    #iso_x, Sig_sqrt = isotropic(x)\n",
    "    iso_x = x\n",
    "    Sig_sqrt = np.eye(d)\n",
    "    AM_steps = 1\n",
    "    for i in range(AM_steps):\n",
    "        #print('AM step: ',i)\n",
    "        w,a = altmin_step(iso_x,y,a,altmin_params,init=False)\n",
    "    final_w = np.matmul(Sig_sqrt,w)    \n",
    "    return final_w\n",
    "\n",
    "#regression oracle \n",
    "def regression_oracle(x,y,mode='ols'):\n",
    "    if mode == 'ols':\n",
    "        model = LinearRegression()\n",
    "        model.fit(x,y)\n",
    "        regressor = model.coef_\n",
    "    if mode == 'scram':\n",
    "        lr = 0.5\n",
    "        lam = 0.2\n",
    "        MW_steps = 10\n",
    "        eta = 0.1\n",
    "        AM_steps = 10\n",
    "        params = (AM_steps,lr,lam,MW_steps,eta)\n",
    "        regressor = scram(x,y,params)\n",
    "    return regressor\n",
    "\n",
    "\n",
    "reg = regression_oracle(x,y[:,0])\n",
    "\n",
    "def optimal_reward(y):\n",
    "    a,b = y.shape\n",
    "    cumsum = 0\n",
    "    for i in range(a):\n",
    "        cumsum = cumsum + np.amax(y[i,:])\n",
    "    return cumsum/a\n",
    "\n",
    "max_reward = optimal_reward(y)\n",
    "print('Optimal Reward')\n",
    "print(max_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0\n",
      "first length of a: 1\n",
      "length of a:  1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2834a6efc122>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mmean_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontextual_bandit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-2834a6efc122>\u001b[0m in \u001b[0;36mcontextual_bandit\u001b[0;34m(cov_label)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#bug, ols can run on one datapoint but scram can't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mestimators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_reg_oracle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;31m#estimators[action,:] = regression_oracle(data_x,data_y,mode='ols')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m#estimators[action,:] = regression_oracle(data_x,data_y,mode='scram')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-d2057a1bd1a7>\u001b[0m in \u001b[0;36mlogistic_reg_oracle\u001b[0;34m(x, y, mode)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAM_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMW_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#print('enerting logistic scram')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mregressor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_scram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-d2057a1bd1a7>\u001b[0m in \u001b[0;36mlogistic_scram\u001b[0;34m(x, y, params)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#print('AM step: ',i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m#print('entering logistic altmin step')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_altmin_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miso_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maltmin_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mfinal_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSig_sqrt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfinal_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-d2057a1bd1a7>\u001b[0m in \u001b[0;36mlogistic_altmin_step\u001b[0;34m(Xs, Ys, a, params)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlogistic_altmin_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted_logistic_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_get_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-d2057a1bd1a7>\u001b[0m in \u001b[0;36mweighted_logistic_reg\u001b[0;34m(x, y, a)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_intercept\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'False'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m#lab = y[:,0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;31m#print('regressor shape: ', model.coef_.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mregressor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1542\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1544\u001b[0;31m                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1545\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    897\u001b[0m             raise ValueError(\"This solver needs samples of at least 2 classes\"\n\u001b[1;32m    898\u001b[0m                              \u001b[0;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m                              \" class: %r\" % classes_[0])\n\u001b[0m\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0mclass_weight_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1.0"
     ]
    }
   ],
   "source": [
    "#contextual bandits takes covariates and labels\n",
    "def contextual_bandit(cov_label):\n",
    "    cov = cov_label['cov']\n",
    "    labels = cov_label['label']\n",
    "    (N,d) = cov.shape\n",
    "    (N,k) = labels.shape\n",
    "    estimators = np.zeros((k,d))\n",
    "    action_list = []\n",
    "    mu = k\n",
    "    delta = 0.1\n",
    "    gamma = np.sqrt(k*N/(d*np.log(N/d) + 1./(2*delta)))\n",
    "    params = (mu,gamma)\n",
    "    rewards = []\n",
    "    mean_reward = []\n",
    "    for i in range(N):\n",
    "        print('iteration: ',i)\n",
    "        covariate = cov[i,:]\n",
    "        values = np.zeros(k)\n",
    "        for j in range(k):\n",
    "            est = estimators[j,:]\n",
    "            values[j] = np.inner(est,covariate)\n",
    "        action = select_action(values,params)\n",
    "        action_list.append(action)\n",
    "        bandit_feedback = labels[i,action]\n",
    "        rewards.append(bandit_feedback)\n",
    "        (data_x,data_y) = get_data(cov_label,action_list,action) \n",
    "        \n",
    "        #bug, ols can run on one datapoint but scram can't\n",
    "        estimators[action,:] = logistic_reg_oracle(data_x,data_y)\n",
    "        #estimators[action,:] = regression_oracle(data_x,data_y,mode='ols')\n",
    "        #estimators[action,:] = regression_oracle(data_x,data_y,mode='scram')\n",
    "        print('action')\n",
    "        print(action)\n",
    "        print('average reward')\n",
    "        #print(rewards)\n",
    "        avg_reward = sum(rewards)/len(rewards)\n",
    "        mean_reward.append(avg_reward)\n",
    "        print(avg_reward)\n",
    "    return mean_reward\n",
    "\n",
    "def get_data(cov_label,action_list,action):\n",
    "    cov = cov_label['cov']\n",
    "    labels = cov_label['label']\n",
    "    (N,d) = cov.shape\n",
    "    (N,k) = labels.shape\n",
    "    length = len(action_list)\n",
    "    count = 0\n",
    "    for i in range(length):\n",
    "        if action_list[i] == action:\n",
    "            count = count + 1\n",
    "    \n",
    "    data_x = np.zeros((count,d))\n",
    "    data_y = np.zeros(count)\n",
    "    counter = 0\n",
    "    for i in range(len(action_list)):\n",
    "        if action_list[i] == action:\n",
    "            data_x[counter] = cov[i,:]\n",
    "            data_y[counter] = labels[i,action]\n",
    "            counter = counter + 1\n",
    "    return (data_x,data_y) \n",
    "\n",
    "\n",
    "def select_action(values,params):\n",
    "    (mu,gamma) = params\n",
    "    k = mu\n",
    "    max_value = np.amax(values)\n",
    "    max_index = np.where(values == max_value)[0][0]\n",
    "    prob = np.zeros(len(values))\n",
    "    for i in range(k): \n",
    "        if i == max_index:\n",
    "            next\n",
    "        else: \n",
    "            prob[i] = 1./(mu + gamma*(max_value - values[i]))\n",
    "    prob[max_index] = 1 - np.sum(prob)\n",
    "    prob = prob/np.sum(prob)\n",
    "    #print('probability')\n",
    "    #print(prob)\n",
    "    #TODO roulette wheel\n",
    "    draw = np.random.rand()\n",
    "    sums = 0\n",
    "    action = 0\n",
    "    for i in range(k):\n",
    "        sums = sums + prob[i]\n",
    "        if sums >= draw:\n",
    "            action = i\n",
    "            break\n",
    "    return action\n",
    "\n",
    "mean_reward = contextual_bandit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
