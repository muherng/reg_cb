{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "# mosek only needed if we don't use MW\n",
    "#import mosek\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cProfile\n",
    "#from baselines import *\n",
    "from scipy.linalg import sqrtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of corruptions\n",
      "100\n",
      "[[0.01199511]]\n",
      "[[1.]]\n",
      "score\n",
      "0.714\n"
     ]
    }
   ],
   "source": [
    "#synthetic example with N datapoints, in d dimensions, with k actions, random regressors\n",
    "#returns a dictionary of covariates x, labels y, regressors ell.  \n",
    "def synthetic_example(N,d,k):\n",
    "    #covariates\n",
    "    x = np.random.normal(0,1,(N,d))\n",
    "    #regressors\n",
    "    ell = np.random.normal(0,1,(k,d))\n",
    "    #labels\n",
    "    y = np.zeros((N,k))\n",
    "    for i in range(N):\n",
    "        for j in range(k):\n",
    "            feature = x[i,:]\n",
    "            regressor = ell[j,:]\n",
    "            y[i,j] = np.inner(feature,regressor) + np.random.normal(0,1)\n",
    "    data = {'cov': x, 'label': y, 'reg': ell}\n",
    "    return data\n",
    "\n",
    "from scipy.special import logit, expit\n",
    "\n",
    "def logistic_synthetic_example(N,d,k,eta,corrupt=False):\n",
    "    #covariates, scaling the covariates to be of large norm amplifies the effect of corruptions\n",
    "    #good parameters: scale x by 100, d = 100, N = 1000\n",
    "    x = np.random.normal(0,1,(N,d))*100\n",
    "    #regressors\n",
    "    ell = np.random.normal(0,1,(k,d))\n",
    "    ell = ell/np.linalg.norm(ell)\n",
    "    #labels\n",
    "    y = np.zeros((N,k))\n",
    "    prob_list = np.zeros((N,k))\n",
    "    for i in range(N):\n",
    "        for j in range(k):\n",
    "            feature = x[i,:]\n",
    "            regressor = ell[j,:]\n",
    "            prob = expit(np.inner(feature,regressor))\n",
    "            prob_list[i,j] = prob\n",
    "            y[i,j] = np.random.binomial(1,prob)\n",
    "            #deterministic labels\n",
    "            #if prob > 0.5:\n",
    "            #    y[i,j] = 1\n",
    "            #else:\n",
    "            #    y[i,j] = 0\n",
    "    if corrupt:\n",
    "        corr = int(eta*N)\n",
    "        print('number of corruptions')\n",
    "        print(corr)\n",
    "        poison = False\n",
    "        if poison:\n",
    "            print('TODO: poisoning')\n",
    "        else: \n",
    "            select = np.zeros((corr,k))\n",
    "            for j in range(k):\n",
    "                order = np.argsort(prob_list[:,j])\n",
    "                select[:,j] = order[:corr]\n",
    "            for i in range(corr):\n",
    "                for j in range(k):\n",
    "                    index = int(select[i,j])\n",
    "                    y[index,j] = 1 - y[index,j]\n",
    "    data = {'cov': x, 'label': y, 'reg': ell}\n",
    "    return data\n",
    "\n",
    "#data = synthetic_example(1000,100,10)    \n",
    "#print(data)\n",
    "\n",
    "import pandas as pd, numpy as np, re\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "def parse_data(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        infoline = f.readline()\n",
    "        infoline = re.sub(r\"^b'\", \"\", str(infoline))\n",
    "        n_features = int(re.sub(r\"^\\d+\\s(\\d+)\\s\\d+.*$\", r\"\\1\", infoline))\n",
    "        features, labels = load_svmlight_file(f, n_features=n_features, multilabel=True)\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    labels = mlb.fit_transform(labels)\n",
    "    features = np.array(features.todense())\n",
    "    features = np.ascontiguousarray(features)\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "data_mode = 'logistic_synth'\n",
    "#data_mode = 'synthetic'\n",
    "#data_mode = 'real'\n",
    "N = 1000\n",
    "d = 1\n",
    "k = 1\n",
    "eta = 0.1\n",
    "\n",
    "if data_mode == 'logistic_synth':\n",
    "    data = logistic_synthetic_example(N,d,k,eta,corrupt=True)\n",
    "    #data = logistic_synthetic_example(N,d,k,eta,corrupt=False)\n",
    "if data_mode == 'synthetic':\n",
    "    data = synthetic_example(1000,10,10)    \n",
    "elif data_mode == 'real': \n",
    "    x, y = parse_data(\"Bibtex_data.txt\")\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    data = {'cov': x, 'label': y}\n",
    "\n",
    "x = data['cov']\n",
    "y = data['label']\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', random_state=0, fit_intercept ='False')\n",
    "#a = np.zeros((2,3)).reshape(-1,1)\n",
    "#b = np.ones(2)\n",
    "\n",
    "#a = np.zeros(10,2).reshape(-1, 1)\n",
    "#b = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
    "lab = y[:,0]\n",
    "model.fit(x, lab)\n",
    "print(model.coef_)\n",
    "print(data['reg'])\n",
    "print('score')\n",
    "print(model.score(x,lab))\n",
    "\n",
    "vanilla = model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #logistic regression experiments\n",
    "# #implement the weighted logistic regression\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.layers import InputLayer\n",
    "# from scipy.special import expit,logit\n",
    "\n",
    "# #line of code to enable the numpy operations in the custom loss\n",
    "# #to be replaced\n",
    "# #tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# x_train = data['cov']\n",
    "# y_train = y[:,0]\n",
    "\n",
    "\n",
    "# ANN_model = Sequential()\n",
    "# ANN_model.add(InputLayer(input_shape=(d, )))\n",
    "# # No hidden layers\n",
    "# ANN_model.add(Dense(1, activation='sigmoid',use_bias=False))\n",
    "# ANN_model.summary()\n",
    "\n",
    "# b_size = 10\n",
    "\n",
    "# def custom_loss_function(y_true, y_pred):\n",
    "#     dim = y_true.shape[0]\n",
    "#     arg1 = y_true[:,0]\n",
    "#     arg2 = tf.math.log(y_pred[:,0])\n",
    "#     arg3 = tf.subtract(tf.ones(dim),arg1)\n",
    "#     arg4 = tf.subtract(tf.ones(dim),arg2)\n",
    "#     inp1 = tf.multiply(arg1,arg2)\n",
    "#     inp2 = tf.multiply(arg3,arg4)\n",
    "#     loss_vec = tf.math.scalar_mul(-1.0,tf.add(inp1,inp2))\n",
    "#     output = tf.reduce_mean(loss_vec, axis=-1)\n",
    "#     return output\n",
    "\n",
    "# opt=tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "# #loss=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "# #ANN_model.compile(optimizer=opt,\n",
    "# #                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "# #                  metrics=['accuracy'])\n",
    "\n",
    "# ANN_model.compile(optimizer=opt,\n",
    "#                   loss=custom_loss_function,\n",
    "#                   metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# history = ANN_model.fit(x_train, y_train, \n",
    "#                         epochs=10, batch_size=b_size,\n",
    "#                         validation_split=0.2, \n",
    "#                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arg = tf.constant(x_train[0,:])\n",
    "#arg = tf.ones((1,100))\n",
    "#print(arg.shape)\n",
    "#print('prediction: ',ANN_model.predict(arg))\n",
    "\n",
    "#g = ANN_model.get_layer(index=0).get_weights()\n",
    "from scipy.special import expit,logit \n",
    "#arg = np.ones(100)\n",
    "#h = g[0][:,0]\n",
    "#print(h.shape)\n",
    "#print(np.inner(arg,arg))\n",
    "#print(arg.shape)\n",
    "\n",
    "#print(np.inner(h,h))\n",
    "#print('prediction: ', expit(np.inner(h,arg)))\n",
    "\n",
    "#b = ANN_model.get_layer(index=0).name\n",
    "#print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non robust performance:  [0.37440813]\n",
      "robust performance:  [0.19983483]\n",
      "vanilla:  [[0.01199511]]\n",
      "reg:  [0.05288764]\n"
     ]
    }
   ],
   "source": [
    "#logistic regression version of scram\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "def logistic_reg_oracle(x,y,mode='robust-logistic'):\n",
    "    if mode == 'robust-logistic':\n",
    "        lr = 0.1\n",
    "        #lam = 0.2\n",
    "        lam = 0.0\n",
    "        MW_steps = 30\n",
    "        #eta = 0.1\n",
    "        AM_steps = 100\n",
    "        params = (AM_steps,lr,lam,MW_steps,eta)\n",
    "        #print('enerting logistic scram')\n",
    "        regressor = logistic_scram(x,y,params)\n",
    "    return regressor\n",
    "\n",
    "def logistic_scram(x,y,params):\n",
    "    AM_steps = params[0]\n",
    "    altmin_params = params[1:]\n",
    "    N,d = x.shape\n",
    "    w = [0.]*d\n",
    "    a = [1.]*N\n",
    "    #TODO: fix isotropic step, for now identity covariance\n",
    "    #iso_x, Sig_sqrt = isotropic(x)\n",
    "    iso_x = x\n",
    "    Sig_sqrt = np.eye(d)\n",
    "    for i in range(AM_steps):\n",
    "        #print('AM step: ',i)\n",
    "        #print('entering logistic altmin step')\n",
    "        w,a = logistic_altmin_step(iso_x,y,a,altmin_params)\n",
    "    final_w = np.matmul(Sig_sqrt,w)    \n",
    "    return final_w\n",
    "\n",
    "def logistic_altmin_step(Xs,Ys,a,params):\n",
    "    N,d = Xs.shape\n",
    "    w = weighted_logistic_reg(Xs,Ys,a)\n",
    "    a = logistic_get_weights(Xs,Ys,w,params)\n",
    "    return w, a\n",
    "\n",
    "def weighted_logistic_reg(x,y,a):\n",
    "    n,d = x.shape\n",
    "    hard_weights = np.zeros(n)\n",
    "    m = min(int(n*(1 - eta))+1,n) \n",
    "    prob = a*m\n",
    "    for i in range(N):\n",
    "        ind = np.random.binomial(1,prob[i])\n",
    "        hard_weights[i] = ind\n",
    "    \n",
    "    N_train = int(np.sum(hard_weights))\n",
    "    #print('N_train: ',N_train)\n",
    "    x_train = np.zeros((N_train,d)) \n",
    "    y_train = np.zeros(N_train)\n",
    "    \n",
    "    hold = 0\n",
    "    for i in range(N):\n",
    "        if hard_weights[i] == 1:\n",
    "            x_train[hold,:] = x[i,:]\n",
    "            y_train[hold] = y[i]\n",
    "            hold = hold + 1\n",
    "    model = LogisticRegression(solver='liblinear', random_state=0, fit_intercept ='False')\n",
    "    #lab = y[:,0]\n",
    "    model.fit(x_train, y_train)\n",
    "    #print('regressor shape: ', model.coef_.shape)\n",
    "    regressor = model.coef_[0,:]\n",
    "    #print('regressor shape: ', regressor.shape)\n",
    "    return regressor\n",
    "\n",
    "def logistic_get_weights(X,y,w,params):\n",
    "    n,d = X.shape\n",
    "    lr,lam,steps,eta = params\n",
    "    a = np.ones(n)/float(n)\n",
    "    #Sig = np.cov(X.T)\n",
    "    Sig = np.matmul(X.T,X)\n",
    "    #print('y: ', y.shape)\n",
    "    #print('X: ', X.shape)\n",
    "    #print('w: ', w.shape)\n",
    "    #print('Xw:', np.matmul(X,w).shape)\n",
    "    Xw = np.matmul(X,w)\n",
    "    pred = expit(Xw)\n",
    "    resids = np.absolute(y - pred)\n",
    "\n",
    "    #print(\"begin MW\")\n",
    "    for j in range(steps):\n",
    "        #if j % 10 == 0:\n",
    "        #    print(j)\n",
    "        if lam > 0:\n",
    "            v = v_step(a,X,Sig,eta)\n",
    "        else:\n",
    "            v = np.zeros(d)\n",
    "        a = a_step(a,X,resids,v,lr=lr,lam=lam,eta=eta,n=n)\n",
    "    return a\n",
    "\n",
    "def outerprod(a,X):\n",
    "    \"\"\" Compute X^T diag(a) X \"\"\"\n",
    "    left = np.multiply(X.T,a)\n",
    "    return np.dot(left,X)\n",
    "\n",
    "def cap(a,m):\n",
    "    if np.max(a) <= 1./m:\n",
    "        return a\n",
    "    #sorted_a = np.sort(a)\n",
    "    ## BUG FIX: use -a to get descending order\n",
    "    sort_ids = np.argsort(-a)\n",
    "\n",
    "    # Faster code\n",
    "    Z = np.sum(a)\n",
    "    for i in range(1,m + 1):\n",
    "        Z -= a[sort_ids[i - 1]]\n",
    "        aprime_next = (m - i) * a[sort_ids[i]]/float(m * Z)\n",
    "        if aprime_next <= 1.0/m:\n",
    "            aprime = np.copy(a)\n",
    "            aprime[sort_ids[:i]] = 1./m\n",
    "            aprime[sort_ids[i:]] *= (m - i)/float(m * Z)\n",
    "            return aprime\n",
    "\n",
    "def v_step(a,X,Sig,eta,tol=0):\n",
    "    \"\"\" Compute top eigenvector of X^T diag(1/n-a) X\"\"\"\n",
    "    # Bug fix: this was formerly 1 and not 1/n\n",
    "    n = a.shape[0]\n",
    "    #m = int(n*(1 - eta)) \n",
    "    M = outerprod(1./n-a,X)\n",
    "\n",
    "    # this method is slower sometimes and faster sometimes vs other one, depending on d?\n",
    "    d = M.shape[0]\n",
    "\n",
    "    # Want top eigenvalue algebraically\n",
    "    eigenvalue, v = eigh(M, eigvals=(d-1,d-1)) \n",
    "    #eigenvalue, v = largest_eigsh(M, 1, which='LA',tol=tol)\n",
    "    #print(eigenvalue)\n",
    "    #print(np.sum(v ** 2))\n",
    "    \n",
    "    ## Don't regularize if constraint is satisfied\n",
    "    if eigenvalue > 0:\n",
    "        return v[:,0]\n",
    "    else:\n",
    "        return np.zeros(shape=v[:,0].shape)\n",
    "    \n",
    "# @jit(nopython=True)\n",
    "def a_step(a,X,resids_sq,v,lr,lam,eta,n):\n",
    "    \"\"\" Step to minimize \\sum_i a_i resids_sq[i]^2 + \\lambda sigma_{max}(X^T diag(1/n - a) X)\"\"\"\n",
    "    m = min(int(n*(1 - eta))+1,n) \n",
    "    \n",
    "    Xv_squared = np.dot(X,v)**2\n",
    "    penalties = resids_sq - lam * Xv_squared\n",
    "\n",
    "    #print(\"OBJ: \",np.dot(a,resids_sq), np.dot(a,-lam * Xv_squared) + lam * (1/n) * np.sum(Xv_squared))\n",
    "\n",
    "    #print(\"BEFORE: \",np.dot(a,penalties) + lam * (1/n) * np.sum(Xv_squared))\n",
    "\n",
    "    # multiplicative update\n",
    "    #print('residuals: ',resids_sq.shape)\n",
    "    #print('penalties: ', penalties.shape)\n",
    "    a *= np.exp(-lr * penalties)\n",
    "    a /= np.sum(a)\n",
    "    #print(\"MIDDLE:: \",np.dot(a,penalties) + lam * (1/n) * np.sum(Xv_squared))\n",
    "    # project back to sliced simplex\n",
    "    #print('a: ', a)\n",
    "    #print('m: ', m)\n",
    "    a = cap(a,m)\n",
    "    return a\n",
    "\n",
    "def logistic_eval(x,y,reg):\n",
    "    n,d = x.shape\n",
    "    error = 0\n",
    "    for i in range(n):\n",
    "        error = error + np.absolute(y[i] - expit(np.inner(reg,x[i,:])))\n",
    "        \n",
    "    error = error/n\n",
    "    return error \n",
    "    \n",
    "reg = logistic_reg_oracle(x,y[:,0])\n",
    "print('non robust performance: ', logistic_eval(x,y,vanilla))\n",
    "print('robust performance: ',logistic_eval(x,y,reg))\n",
    "print('vanilla: ', vanilla)\n",
    "print('reg: ', reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of corruptions\n",
      "50\n",
      "corruption level:  0.05\n",
      "non robust performance:  [0.27196645]\n",
      "robust performance:  [0.10967226]\n",
      "number of corruptions\n",
      "100\n",
      "corruption level:  0.1\n",
      "non robust performance:  [0.38265477]\n",
      "robust performance:  [0.18533537]\n",
      "number of corruptions\n",
      "150\n",
      "corruption level:  0.15\n",
      "non robust performance:  [0.42906523]\n",
      "robust performance:  [0.32104217]\n",
      "number of corruptions\n",
      "200\n",
      "corruption level:  0.2\n",
      "non robust performance:  [0.46198642]\n",
      "robust performance:  [0.42228936]\n",
      "number of corruptions\n",
      "250\n",
      "corruption level:  0.25\n",
      "non robust performance:  [0.48364935]\n",
      "robust performance:  [0.46821579]\n",
      "robust:  [array([0.10967226]), array([0.18533537]), array([0.32104217]), array([0.42228936]), array([0.46821579])]\n",
      "non robust:  [array([0.27196645]), array([0.38265477]), array([0.42906523]), array([0.46198642]), array([0.48364935])]\n"
     ]
    }
   ],
   "source": [
    "#plot experiments for logistic regression\n",
    "def run_experiment():\n",
    "    N = 1000\n",
    "    d = 1\n",
    "    k = 1\n",
    "    eta_list = [0.05,0.1,0.15,0.2,0.25]\n",
    "    results_robust = []\n",
    "    results_vanilla = []\n",
    "    for eta in eta_list: \n",
    "        data = logistic_synthetic_example(N,d,k,eta,corrupt=True)\n",
    "        #data = logistic_synthetic_example(N,d,k,eta,corrupt=False)\n",
    "        x = data['cov']\n",
    "        y = data['label']\n",
    "        #run vanilla logistic regression\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        model = LogisticRegression(solver='liblinear', random_state=0, fit_intercept ='False')\n",
    "        lab = y[:,0]\n",
    "        model.fit(x, lab)\n",
    "        vanilla = model.coef_\n",
    "        #run robust logistic regression\n",
    "        reg = logistic_reg_oracle(x,lab)\n",
    "        v_out = logistic_eval(x,y,vanilla)\n",
    "        r_out = logistic_eval(x,y,reg)\n",
    "        results_robust.append(r_out)\n",
    "        results_vanilla.append(v_out)\n",
    "        print('corruption level: ',eta)\n",
    "        print('non robust performance: ', v_out)\n",
    "        print('robust performance: ', r_out)\n",
    "    return (results_robust,results_vanilla)  \n",
    "\n",
    "(rob,nrob) = run_experiment()\n",
    "print('robust: ', rob)\n",
    "print('non robust: ', nrob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Logistic Regression vs. Logistic SCRAM')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "eta_list = [0.05,0.1,0.15,0.2,0.25]\n",
    "plt.plot(eta_list,rob,label='robust')\n",
    "plt.plot(eta_list,nrob,label='logistic')\n",
    "plt.ylabel('fraction misclassified')\n",
    "plt.xlabel('fraction corrupted')\n",
    "plt.legend()\n",
    "plt.title('Logistic Regression vs. Logistic SCRAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mw2 import MW_no_alt_min, get_weights, altmin_step\n",
    "\n",
    "def isotropic(Xs,fake=False):\n",
    "    if fake:\n",
    "        return Xs, np.eye(Xs.shape[1])\n",
    "    Sig = np.matmul(Xs.T,Xs)\n",
    "    Sig_sqrt = np.linalg.inv(sqrtm(Sig))\n",
    "    new_Xs = np.matmul(Xs,Sig_sqrt)\n",
    "    return new_Xs, Sig_sqrt\n",
    "\n",
    "def scram(x,y,params):\n",
    "    AM_steps = params[0]\n",
    "    altmin_params = params[1:]\n",
    "    N,d = x.shape\n",
    "    w = [0.]*d\n",
    "    a = [1.]*N\n",
    "    #iso_x, Sig_sqrt = isotropic(x)\n",
    "    iso_x = x\n",
    "    Sig_sqrt = np.eye(d)\n",
    "    AM_steps = 1\n",
    "    for i in range(AM_steps):\n",
    "        #print('AM step: ',i)\n",
    "        w,a = altmin_step(iso_x,y,a,altmin_params,init=False)\n",
    "    final_w = np.matmul(Sig_sqrt,w)    \n",
    "    return final_w\n",
    "\n",
    "#regression oracle \n",
    "def regression_oracle(x,y,mode='ols'):\n",
    "    if mode == 'ols':\n",
    "        model = LinearRegression()\n",
    "        model.fit(x,y)\n",
    "        regressor = model.coef_\n",
    "    if mode == 'scram':\n",
    "        lr = 0.5\n",
    "        lam = 0.2\n",
    "        MW_steps = 10\n",
    "        eta = 0.1\n",
    "        AM_steps = 10\n",
    "        params = (AM_steps,lr,lam,MW_steps,eta)\n",
    "        regressor = scram(x,y,params)\n",
    "    return regressor\n",
    "\n",
    "\n",
    "reg = regression_oracle(x,y[:,0])\n",
    "\n",
    "def optimal_reward(y):\n",
    "    a,b = y.shape\n",
    "    cumsum = 0\n",
    "    for i in range(a):\n",
    "        cumsum = cumsum + np.amax(y[i,:])\n",
    "    return cumsum/a\n",
    "\n",
    "max_reward = optimal_reward(y)\n",
    "print('Optimal Reward')\n",
    "print(max_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contextual bandits takes covariates and labels\n",
    "def contextual_bandit(cov_label):\n",
    "    cov = cov_label['cov']\n",
    "    labels = cov_label['label']\n",
    "    (N,d) = cov.shape\n",
    "    (N,k) = labels.shape\n",
    "    estimators = np.zeros((k,d))\n",
    "    action_list = []\n",
    "    mu = k\n",
    "    delta = 0.1\n",
    "    gamma = np.sqrt(k*N/(d*np.log(N/d) + 1./(2*delta)))\n",
    "    params = (mu,gamma)\n",
    "    rewards = []\n",
    "    mean_reward = []\n",
    "    for i in range(N):\n",
    "        print('iteration: ',i)\n",
    "        covariate = cov[i,:]\n",
    "        values = np.zeros(k)\n",
    "        for j in range(k):\n",
    "            est = estimators[j,:]\n",
    "            values[j] = np.inner(est,covariate)\n",
    "        action = select_action(values,params)\n",
    "        action_list.append(action)\n",
    "        bandit_feedback = labels[i,action]\n",
    "        rewards.append(bandit_feedback)\n",
    "        (data_x,data_y) = get_data(cov_label,action_list,action) \n",
    "        \n",
    "        #bug, ols can run on one datapoint but scram can't\n",
    "        #estimators[action,:] = regression_oracle(data_x,data_y,mode='ols')\n",
    "        estimators[action,:] = regression_oracle(data_x,data_y,mode='scram')\n",
    "        print('action')\n",
    "        print(action)\n",
    "        print('average reward')\n",
    "        #print(rewards)\n",
    "        avg_reward = sum(rewards)/len(rewards)\n",
    "        mean_reward.append(avg_reward)\n",
    "        print(avg_reward)\n",
    "    return mean_reward\n",
    "\n",
    "def get_data(cov_label,action_list,action):\n",
    "    cov = cov_label['cov']\n",
    "    labels = cov_label['label']\n",
    "    (N,d) = cov.shape\n",
    "    (N,k) = labels.shape\n",
    "    length = len(action_list)\n",
    "    count = 0\n",
    "    for i in range(length):\n",
    "        if action_list[i] == action:\n",
    "            count = count + 1\n",
    "    \n",
    "    data_x = np.zeros((count,d))\n",
    "    data_y = np.zeros(count)\n",
    "    counter = 0\n",
    "    for i in range(len(action_list)):\n",
    "        if action_list[i] == action:\n",
    "            data_x[counter] = cov[i,:]\n",
    "            data_y[counter] = labels[i,action]\n",
    "            counter = counter + 1\n",
    "    return (data_x,data_y) \n",
    "\n",
    "\n",
    "def select_action(values,params):\n",
    "    (mu,gamma) = params\n",
    "    k = mu\n",
    "    max_value = np.amax(values)\n",
    "    max_index = np.where(values == max_value)[0][0]\n",
    "    prob = np.zeros(len(values))\n",
    "    for i in range(k): \n",
    "        if i == max_index:\n",
    "            next\n",
    "        else: \n",
    "            prob[i] = 1./(mu + gamma*(max_value - values[i]))\n",
    "    prob[max_index] = 1 - np.sum(prob)\n",
    "    prob = prob/np.sum(prob)\n",
    "    #print('probability')\n",
    "    #print(prob)\n",
    "    #TODO roulette wheel\n",
    "    draw = np.random.rand()\n",
    "    sums = 0\n",
    "    action = 0\n",
    "    for i in range(k):\n",
    "        sums = sums + prob[i]\n",
    "        if sums >= draw:\n",
    "            action = i\n",
    "            break\n",
    "    return action\n",
    "\n",
    "mean_reward = contextual_bandit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "domain = range(len(mean_reward))\n",
    "plt.scatter(domain, mean_reward)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[2,3],[1,4]])\n",
    "b = np.sort(a,axis=0)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([3,2,1])\n",
    "order = a.argsort()\n",
    "print(order)\n",
    "b = a[order]\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((2,3))\n",
    "a.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([0.5,0.5,0.5])\n",
    "y = tf.constant([1.,0.,1.])\n",
    "weights = tf.constant([0.4,0.2,0.4])\n",
    "t = tf.ones(3)\n",
    "\n",
    "\n",
    "arg1 = tf.multiply(y,tf.math.log(x))\n",
    "arg2 = tf.multiply(tf.subtract(t,y),tf.math.log(tf.math.subtract(t,x)))\n",
    "q = tf.reduce_sum(tf.multiply(tf.add(arg1,arg2),weights))\n",
    "print(q)\n",
    "\n",
    "print(tf.math.scalar_mul(-1.0,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.ones(2)\n",
    "b = tf.ones(32)\n",
    "c = b.numpy()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.empty((0,2))\n",
    "b = np.zeros((2,2))\n",
    "c = np.array([b[0,:]])\n",
    "print(c)\n",
    "d = np.append(a,c,axis=0)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones(3)\n",
    "b = np.ones(3)\n",
    "c = np.ones((3,3))\n",
    "d = np.matmul(c,b)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=5\n",
    "a = a/10\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "a.append(1)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
